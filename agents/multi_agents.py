import os
import sys
import asyncio
import re

from typing import Dict, Any, List, AsyncIterable, TypedDict, Annotated, Optional
from langchain_mcp_adapters.client import MultiServerMCPClient
from typing_extensions import AsyncGenerator
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from utils.logger import log

from langchain_core.messages import AIMessage, HumanMessage, SystemMessage
from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langchain_mcp_adapters.client import MultiServerMCPClient
from pydantic import BaseModel, Field

from config.llm import gemini
from agents.filesystem_agent import FilesystemAgent
from agents.metadata_agent import MetadataAgent
from agents.text_extraction_agent import TextExtractionAgent
from agents.file_classification_agent import FileClassificationAgent
from agents.rag_agent import RAGAgent

# Global MemorySaver instance shared by all agents
memory = MemorySaver()

# Setup MCP client for filesystem access
mcp_client = MultiServerMCPClient({
    "document_search": {
        "command": "cmd",
        "args": [
            "/c",
            "npx",
            "-y",
            "@modelcontextprotocol/server-filesystem",
            "C:\\Users\\dhuu3\\Desktop\\local-classify-docs-ai-agent\\data",
        ],
        "transport": "stdio",
    }
})

# Define the state for our multi-agent system
class AgentState(TypedDict):
    messages: Annotated[List[Any], add_messages]  # Messages in the conversation
    current_agents: List[str]  # Which agents are currently active or have been used
    task_complete: bool  # Whether the task is complete
    require_user_input: bool  # Whether user input is needed
    feedback_on_work: Optional[str]  # Feedback from evaluator
    success_criteria_met: bool  # Whether success criteria have been met
    used_tools: List[str]  # Tools that have been used

class MultiAgentSystem:
    """
    Multi-Agent System that orchestrates specialized agents using a worker-evaluator pattern.
    
    This system can use multiple specialized agents in sequence (FilesystemAgent, MetadataAgent,
    TextExtractionAgent, FileClassificationAgent) based on the user's query and includes
    an evaluator component to assess if the task has been completed successfully.
    """
    def __init__(self):
        """
        Initialize the MultiAgentSystem.
        """
        self.model = gemini
        self.graph = None
        self.agents = {}
        self.session_id = None
        self.all_tools = []
        
    async def initialize(self):
        """
        Asynchronously initialize all specialized agents and create the workflow graph.
        
        Returns:
            MultiAgentSystem: The initialized multi-agent system.
        """
        try:
            # Initialize specialized agents
            print("Initializing specialized agents...")
            
           
            mcp_client = MultiServerMCPClient({
                "document_search": {
                    "command": "cmd",
                    "args": [
                        "/c",
                        "npx",
                        "-y",
                        "@modelcontextprotocol/server-filesystem",
                        "C:\\Users\\dhuu3\\Desktop\\local-classify-docs-ai-agent\\data",
                    ],
                    "transport": "stdio"
                }
            })
            print("Using provided MCP client for FilesystemAgent")
            
            self.agents["filesystem"] = await FilesystemAgent.create(mcp_client=mcp_client)
            self.agents["metadata"] = MetadataAgent()
            self.agents["text_extraction"] = TextExtractionAgent()
            self.agents["file_classification"] = FileClassificationAgent()
            self.agents["rag"] = RAGAgent()
            
            # Build RAG index for data directory
            data_dir = "C:\\Users\\dhuu3\\Desktop\\local-classify-docs-ai-agent\\data"
            await self.agents["rag"].build_index(data_dir)
            print("All specialized agents initialized successfully")
            
            # Collect tools from all agents
            # This would require each agent to expose its tools
            # For now, we'll use a placeholder approach
            self.all_tools = []
            
            # Build the graph
            await self.build_graph()
            
            return self
            
        except Exception as e:
            print(f"Error initializing multi-agent system: {e}")
            import traceback
            traceback.print_exc()
            raise
    
    async def build_graph(self):
        """
        Build the state graph for the multi-agent system using a worker-evaluator pattern.
        """
        # Create a state graph with our AgentState
        graph_builder = StateGraph(AgentState)
        
        # Add nodes for each component
        graph_builder.add_node("worker", self.worker)
        graph_builder.add_node("router", self.route_query)
        graph_builder.add_node("filesystem_agent", self.run_filesystem_agent)
        graph_builder.add_node("metadata_agent", self.run_metadata_agent)
        graph_builder.add_node("text_extraction_agent", self.run_text_extraction_agent)
        graph_builder.add_node("file_classification_agent", self.run_file_classification_agent)
        graph_builder.add_node("rag_agent", self.run_rag_agent)
        graph_builder.add_node("evaluator", self.evaluator)
        
        # Add edges
        graph_builder.add_edge(START, "worker")
        
        # Worker can route to specific agents or directly to evaluator
        graph_builder.add_conditional_edges(
            "worker", 
            self.worker_router,
            {
                "router": "router",
                "evaluator": "evaluator"
            }
        )
        
        # Router determines which agent to use
        graph_builder.add_conditional_edges(
            "router",
            self.determine_agent,
            {
                "filesystem": "filesystem_agent",
                "metadata": "metadata_agent",
                "text_extraction": "text_extraction_agent",
                "file_classification": "file_classification_agent",
                "rag": "rag_agent",
                "evaluator": "evaluator"
            }
        )
        
        # Connect all agent nodes back to worker
        graph_builder.add_edge("filesystem_agent", "worker")
        graph_builder.add_edge("metadata_agent", "worker")
        graph_builder.add_edge("text_extraction_agent", "worker")
        graph_builder.add_edge("file_classification_agent", "worker")
        graph_builder.add_edge("rag_agent", "worker")
        
        # Evaluator can either end or route back to worker
        graph_builder.add_conditional_edges(
            "evaluator",
            self.route_based_on_evaluation,
            {"complete": END, "continue": "worker"}
        )
        
        # Compile the graph
        self.graph = graph_builder.compile(checkpointer=memory)
        log("Multi-agent graph built successfully")
    
    async def worker(self, state: AgentState) -> AgentState:
        """
        Worker node that processes the user's query and determines next steps.
        """
        # Create or update system message with task information
        system_message = f"""
        B·∫°n l√† m·ªôt tr·ª£ l√Ω AI th√¥ng minh c√≥ th·ªÉ s·ª≠ d·ª•ng nhi·ªÅu c√¥ng c·ª• v√† t√°c t·ª≠ chuy√™n bi·ªát ƒë·ªÉ ho√†n th√†nh nhi·ªám v·ª•.
        B·∫°n c√≥ th·ªÉ ti·∫øp t·ª•c l√†m vi·ªác v·ªõi m·ªôt nhi·ªám v·ª• cho ƒë·∫øn khi ho√†n th√†nh ho·∫∑c c·∫ßn th√™m th√¥ng tin t·ª´ ng∆∞·ªùi d√πng.
        
        B·∫°n c√≥ quy·ªÅn truy c·∫≠p v√†o c√°c t√°c t·ª≠ chuy√™n bi·ªát sau:
        1. Filesystem Agent: S·ª≠ d·ª•ng khi c·∫ßn t√¨m ki·∫øm, li·ªát k√™ ho·∫∑c qu·∫£n l√Ω t·ªáp v√† th∆∞ m·ª•c theo t√™n file.
        2. RAG Agent: S·ª≠ d·ª•ng khi c·∫ßn t√¨m ki·∫øm t√†i li·ªáu theo n·ªôi dung ho·∫∑c ng·ªØ nghƒ©a.
        3. Metadata Agent: S·ª≠ d·ª•ng khi c·∫ßn t·∫°o ho·∫∑c qu·∫£n l√Ω metadata cho t√†i li·ªáu.
        4. Text Extraction Agent: S·ª≠ d·ª•ng khi c·∫ßn tr√≠ch xu·∫•t vƒÉn b·∫£n t·ª´ c√°c t·ªáp PDF, Word ho·∫∑c PowerPoint.
        5. File Classification Agent: S·ª≠ d·ª•ng khi c·∫ßn ph√¢n lo·∫°i n·ªôi dung t√†i li·ªáu.
        
        B·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng nhi·ªÅu t√°c t·ª≠ trong c√πng m·ªôt nhi·ªám v·ª• n·∫øu c·∫ßn thi·∫øt.
        V√≠ d·ª•: T√¨m t·ªáp v·ªõi Filesystem Agent, sau ƒë√≥ tr√≠ch xu·∫•t n·ªôi dung v·ªõi Text Extraction Agent.
        
        H√£y ph√¢n t√≠ch y√™u c·∫ßu c·ªßa ng∆∞·ªùi d√πng v√† quy·∫øt ƒë·ªãnh s·ª≠ d·ª•ng t√°c t·ª≠ n√†o ho·∫∑c k·∫øt h·ª£p c√°c t√°c t·ª≠ ƒë·ªÉ ho√†n th√†nh nhi·ªám v·ª•.
        """
        
        # Add feedback if available
        if state.get("feedback_on_work"):
            system_message += f"""
        
Tr∆∞·ªõc ƒë√≥, b·∫°n ƒë√£ th·ª≠ gi·∫£i quy·∫øt nhi·ªám v·ª• nh∆∞ng ch∆∞a ho√†n th√†nh. ƒê√¢y l√† ph·∫£n h·ªìi:
{state['feedback_on_work']}

H√£y ƒëi·ªÅu ch·ªânh c√°ch ti·∫øp c·∫≠n c·ªßa b·∫°n d·ª±a tr√™n ph·∫£n h·ªìi n√†y.
        """
        
        # Add system message if not already present
        found_system_message = False
        messages = state["messages"]
        for i, message in enumerate(messages):
            if isinstance(message, SystemMessage):
                messages[i] = SystemMessage(content=system_message)
                found_system_message = True
                break
        
        if not found_system_message:
            state["messages"] = [SystemMessage(content=system_message)] + state["messages"]
        
        # Analyze the query to determine next steps
        last_message = state["messages"][-1]
        if not isinstance(last_message, HumanMessage):
            # If the last message is not from a human, we're in a continuation
            # Just return the state for routing
            return state
            
        # S·ª≠ d·ª•ng LLM ƒë·ªÉ l·∫≠p k·∫ø ho·∫°ch s·ª≠ d·ª•ng agent
        query = last_message.content
        
        try:
            # T·∫°o prompt cho LLM
            planning_prompt = f"""
            B·∫°n l√† m·ªôt h·ªá th·ªëng ƒëi·ªÅu ph·ªëi c√°c agent AI chuy√™n bi·ªát. D·ª±a tr√™n y√™u c·∫ßu c·ªßa ng∆∞·ªùi d√πng, h√£y l·∫≠p k·∫ø ho·∫°ch s·ª≠ d·ª•ng c√°c agent ph√π h·ª£p.
            
            Y√™u c·∫ßu c·ªßa ng∆∞·ªùi d√πng: "{query}"
            
            C√°c agent c√≥ s·∫µn:
            1. filesystem - T√¨m ki·∫øm, li·ªát k√™ v√† qu·∫£n l√Ω t·ªáp v√† th∆∞ m·ª•c
            2. metadata - T·∫°o v√† qu·∫£n l√Ω metadata cho t√†i li·ªáu
            3. text_extraction - Tr√≠ch xu·∫•t vƒÉn b·∫£n t·ª´ t·ªáp PDF, Word ho·∫∑c PowerPoint
            4. file_classification - Ph√¢n lo·∫°i n·ªôi dung t√†i li·ªáu
            
            H√£y l·∫≠p k·∫ø ho·∫°ch s·ª≠ d·ª•ng c√°c agent. ƒê·∫ßu ti√™n, tr·∫£ l·ªùi v·ªõi danh s√°ch c√°c agent c·∫ßn s·ª≠ d·ª•ng theo th·ª© t·ª±, ch·ªâ li·ªát k√™ t√™n c√°c agent (filesystem, metadata, text_extraction, file_classification), c√°ch nhau b·∫±ng d·∫•u ph·∫©y.
            
            Sau ƒë√≥, vi·∫øt m·ªôt ƒëo·∫°n vƒÉn ng·∫Øn gi·∫£i th√≠ch k·∫ø ho·∫°ch c·ªßa b·∫°n b·∫±ng ti·∫øng Vi·ªát.
            """
            
            # S·ª≠ d·ª•ng LLM ƒë·ªÉ l·∫≠p k·∫ø ho·∫°ch
            from config.llm import gemini
            response = await gemini.ainvoke(planning_prompt)
            plan_response = response.content.strip()
            
            # T√°ch ph·∫ßn danh s√°ch agent v√† ph·∫ßn gi·∫£i th√≠ch
            parts = plan_response.split('\n', 1)
            agent_list = parts[0].strip().lower()
            plan_message = parts[1].strip() if len(parts) > 1 else f"T√¥i s·∫Ω gi√∫p b·∫°n v·ªõi y√™u c·∫ßu: '{query}'."
            
            # X·ª≠ l√Ω danh s√°ch agent
            needed_agents = []
            valid_agents = ["filesystem", "metadata", "text_extraction", "file_classification"]
            
            for agent in valid_agents:
                if agent in agent_list:
                    needed_agents.append(agent)
            
            if not needed_agents:
                # M·∫∑c ƒë·ªãnh s·ª≠ d·ª•ng filesystem n·∫øu kh√¥ng c√≥ agent n√†o ƒë∆∞·ª£c ch·ªçn
                needed_agents.append("filesystem")
                plan_message += "\nT√¥i s·∫Ω b·∫Øt ƒë·∫ßu v·ªõi Filesystem Agent ƒë·ªÉ t√¨m ki·∫øm th√¥ng tin."
            
            print(f"K·∫ø ho·∫°ch agent: {needed_agents}")
            
        except Exception as e:
            print(f"L·ªói khi l·∫≠p k·∫ø ho·∫°ch s·ª≠ d·ª•ng agent: {e}")
            # S·ª≠ d·ª•ng m·∫∑c ƒë·ªãnh n·∫øu c√≥ l·ªói
            needed_agents = ["filesystem"]
            plan_message = f"T√¥i s·∫Ω gi√∫p b·∫°n v·ªõi y√™u c·∫ßu: '{query}'. T√¥i s·∫Ω b·∫Øt ƒë·∫ßu v·ªõi Filesystem Agent ƒë·ªÉ t√¨m ki·∫øm th√¥ng tin."
        
        # Update state with the plan
        state["current_agents"] = needed_agents
        state["messages"].append(AIMessage(content=plan_message))
        
        return state
        
    def worker_router(self, state: AgentState) -> str:
        """
        Route from worker node to either router or evaluator.
        """
        # N·∫øu kh√¥ng c√≤n agent n√†o trong k·∫ø ho·∫°ch, chuy·ªÉn sang evaluator
        if not state["current_agents"]:
            log("Kh√¥ng c√≤n agent n√†o trong k·∫ø ho·∫°ch, chuy·ªÉn sang evaluator")
            return "evaluator"
            
        # N·∫øu ƒë√£ s·ª≠ d·ª•ng qu√° nhi·ªÅu agent, chuy·ªÉn sang evaluator ƒë·ªÉ tr√°nh v√≤ng l·∫∑p v√¥ h·∫°n
        if len(state.get("used_tools", [])) >= 3:
            log("ƒê√£ s·ª≠ d·ª•ng qu√° nhi·ªÅu agent, chuy·ªÉn sang evaluator")
            return "evaluator"
            
        # Ki·ªÉm tra xem c√≥ ƒëang l·∫∑p l·∫°i agent kh√¥ng
        if len(state.get("used_tools", [])) >= 2:
            last_two_tools = state["used_tools"][-2:]
            if last_two_tools[0] == last_two_tools[1]:
                log("Ph√°t hi·ªán l·∫∑p l·∫°i agent, chuy·ªÉn sang evaluator")
                return "evaluator"
                
        # Ti·∫øp t·ª•c v·ªõi router
        return "router"
    
    def determine_agent(self, state: AgentState) -> str:
        """
        Determine which agent to use next based on the current_agents list.
        """
        if not state["current_agents"]:
            log("Kh√¥ng c√≤n agent n√†o trong danh s√°ch, chuy·ªÉn sang evaluator")
            return "evaluator"
        
        # Ki·ªÉm tra xem agent ti·∫øp theo ƒë√£ ƒë∆∞·ª£c s·ª≠ d·ª•ng ch∆∞a
        next_agent = state["current_agents"][0]
        used_tools = state.get("used_tools", [])
        
        # N·∫øu agent ti·∫øp theo ƒë√£ ƒë∆∞·ª£c s·ª≠ d·ª•ng, b·ªè qua v√† ki·ªÉm tra agent ti·∫øp theo
        if next_agent in used_tools:
            log(f"Agent {next_agent} ƒë√£ ƒë∆∞·ª£c s·ª≠ d·ª•ng, b·ªè qua")
            # X√≥a agent n√†y kh·ªèi danh s√°ch
            state["current_agents"] = state["current_agents"][1:]
            # G·ªçi ƒë·ªá quy ƒë·ªÉ t√¨m agent ti·∫øp theo
            return self.determine_agent(state)
        
        # L·∫•y agent ti·∫øp theo t·ª´ danh s√°ch
        log(f"S·ª≠ d·ª•ng agent {next_agent} ti·∫øp theo")
        
        # X√≥a n√≥ kh·ªèi danh s√°ch ƒë·ªÉ kh√¥ng s·ª≠ d·ª•ng l·∫°i
        state["current_agents"] = state["current_agents"][1:]
        
        # Ki·ªÉm tra n·∫øu l√† RAG agent
        if next_agent == "rag":
            return "run_rag_agent"
        
        return next_agent
        
    async def _validate_agent_sequence(self, state: AgentState) -> AgentState:
        """
        Validate and fix the agent sequence to ensure proper workflow, especially for metadata operations.
        
        Args:
            state: Current agent state with planned agents
            
        Returns:
            Updated state with corrected agent sequence
        """
        current_agents = state.get("current_agents", [])
        log(f"Validating agent sequence: {current_agents}")
        
        # If no agents or only one agent, no need to validate sequence
        if len(current_agents) <= 1:
            return state
            
        # Check if metadata agent is included in the plan
        if "metadata" in current_agents:
            log("Ph√°t hi·ªán metadata agent trong k·∫ø ho·∫°ch, ki·ªÉm tra th·ª© t·ª±")
            
            # Define the correct sequence for metadata operations
            metadata_workflow = []
            
            # Step 1: First agent should be filesystem or rag (search agent)
            if "filesystem" in current_agents or "rag" in current_agents:
                search_agent = "rag" if "rag" in current_agents else "filesystem"
                metadata_workflow.append(search_agent)
                log(f"S·ª≠ d·ª•ng {search_agent} l√†m agent t√¨m ki·∫øm trong workflow metadata")
            else:
                # If no search agent is specified, add rag as default
                metadata_workflow.append("rag")
                log("Th√™m rag agent v√†o ƒë·∫ßu workflow v√¨ kh√¥ng t√¨m th·∫•y agent t√¨m ki·∫øm")
                # Also add it to current_agents to ensure it's included in the final sequence
                current_agents.append("rag")
                
            # Step 2: Add text_extraction agent
            metadata_workflow.append("text_extraction")
            
            # Step 3: Add file_classification agent
            metadata_workflow.append("file_classification")
            
            # Step 4: Finally add metadata agent
            metadata_workflow.append("metadata")
            
            # Create a new agent sequence with correct order
            # Remove any agents that are already in the metadata workflow
            new_agents = [agent for agent in current_agents if agent not in metadata_workflow]
            
            # Add the metadata workflow agents in correct order
            new_agents.extend([agent for agent in metadata_workflow if agent in current_agents])
            
            # If metadata is in the plan but required agents are missing, add them
            if "metadata" in new_agents:
                metadata_index = new_agents.index("metadata")
                missing_agents = []
                
                # Check for missing required agents
                if "text_extraction" not in new_agents:
                    missing_agents.append("text_extraction")
                    log("Th√™m text_extraction agent v√†o workflow v√¨ c·∫ßn thi·∫øt cho metadata")
                    
                if "file_classification" not in new_agents:
                    missing_agents.append("file_classification")
                    log("Th√™m file_classification agent v√†o workflow v√¨ c·∫ßn thi·∫øt cho metadata")
                
                # Insert missing agents in the correct order before metadata
                for agent in reversed(missing_agents):
                    new_agents.insert(metadata_index, agent)
            
            # Update the state with the corrected sequence
            if new_agents != current_agents:
                log(f"ƒê√£ ƒëi·ªÅu ch·ªânh th·ª© t·ª± agent: {current_agents} -> {new_agents}")
                state["chain_of_thought"].append(f"X√°c ƒë·ªãnh c√°c agent c·∫ßn ƒë·ªÉ x·ª≠ l√Ω t√°c v·ª•: {', '.join(new_agents)}")
                state["current_agents"] = new_agents
        
        return state
        
    async def evaluator(self, state: AgentState) -> AgentState:
        """
        Evaluator node that assesses if the task has been completed successfully.
        """
        # Format the conversation history
        conversation = "L·ªãch s·ª≠ h·ªôi tho·∫°i:\n\n"
        for message in state["messages"]:
            if isinstance(message, HumanMessage):
                conversation += f"Ng∆∞·ªùi d√πng: {message.content}\n"
            elif isinstance(message, AIMessage):
                conversation += f"Tr·ª£ l√Ω: {message.content}\n"
            elif isinstance(message, SystemMessage):
                # Skip system messages in the conversation history
                pass
        
        # Get the original query
        original_query = ""
        for message in state["messages"]:
            if isinstance(message, HumanMessage):
                original_query = message.content
                break
        
        # Get the last response
        last_response = ""
        for message in reversed(state["messages"]):
            if isinstance(message, AIMessage):
                last_response = message.content
                break
        
        # Create evaluator prompt
        evaluator_prompt = f"""
        B·∫°n l√† m·ªôt ƒë√°nh gi√° vi√™n x√°c ƒë·ªãnh xem m·ªôt nhi·ªám v·ª• ƒë√£ ƒë∆∞·ª£c ho√†n th√†nh th√†nh c√¥ng hay ch∆∞a.
        ƒê√°nh gi√° ph·∫£n h·ªìi cu·ªëi c√πng c·ªßa Tr·ª£ l√Ω d·ª±a tr√™n y√™u c·∫ßu ban ƒë·∫ßu c·ªßa ng∆∞·ªùi d√πng.
        
        Y√™u c·∫ßu ban ƒë·∫ßu c·ªßa ng∆∞·ªùi d√πng l√†:
        {original_query}
        
        L·ªãch s·ª≠ h·ªôi tho·∫°i:
        {conversation}
        
        Ph·∫£n h·ªìi cu·ªëi c√πng c·ªßa Tr·ª£ l√Ω:
        {last_response}
        
        H√£y ƒë√°nh gi√° xem nhi·ªám v·ª• ƒë√£ ho√†n th√†nh ch∆∞a v√† li·ªáu c√≥ c·∫ßn th√™m th√¥ng tin t·ª´ ng∆∞·ªùi d√πng kh√¥ng.
        N·∫øu nhi·ªám v·ª• ch∆∞a ho√†n th√†nh, h√£y gi·∫£i th√≠ch t·∫°i sao v√† ƒë·ªÅ xu·∫•t c√°ch ti·∫øp c·∫≠n kh√°c.
        """
        
        # For now, we'll use a simple heuristic to determine if the task is complete
        # In a real implementation, you would use the LLM to evaluate this
        
        # Check if we've used at least one agent
        task_complete = len(state.get("used_tools", [])) > 0
        
        # Check if the last response contains certain keywords indicating completion
        completion_indicators = ["ƒë√£ ho√†n th√†nh", "ƒë√£ t√¨m th·∫•y", "k·∫øt qu·∫£", "ƒë√£ x·ª≠ l√Ω", "ƒë√£ tr√≠ch xu·∫•t", "ƒë√£ ph√¢n lo·∫°i"]
        for indicator in completion_indicators:
            if indicator in last_response.lower():
                task_complete = True
                break
        
        # Check if the response addresses the original query
        query_keywords = original_query.lower().split()
        response_keywords = last_response.lower().split()
        common_keywords = set(query_keywords).intersection(set(response_keywords))
        if len(common_keywords) > 2:  # If there are at least 3 common keywords
            task_complete = True
        
        # Set the evaluation results
        feedback = ""
        if task_complete:
            feedback = "Nhi·ªám v·ª• ƒë√£ ƒë∆∞·ª£c ho√†n th√†nh th√†nh c√¥ng. Ph·∫£n h·ªìi ƒë√£ gi·∫£i quy·∫øt y√™u c·∫ßu c·ªßa ng∆∞·ªùi d√πng."
            state["success_criteria_met"] = True
        else:
            feedback = "Nhi·ªám v·ª• ch∆∞a ho√†n th√†nh. C·∫ßn s·ª≠ d·ª•ng th√™m t√°c t·ª≠ ho·∫∑c c√¥ng c·ª• ƒë·ªÉ gi·∫£i quy·∫øt y√™u c·∫ßu c·ªßa ng∆∞·ªùi d√πng."
            state["success_criteria_met"] = False
        
        # Add the feedback to the state
        state["feedback_on_work"] = feedback
        
        # Add evaluator message to the conversation
        state["messages"].append(AIMessage(content=f"[ƒê√°nh gi√° n·ªôi b·ªô: {feedback}]"))
        
        return state
    
    def route_based_on_evaluation(self, state: AgentState) -> str:
        """
        Determine next steps based on the evaluator's assessment.
        """
        if state["success_criteria_met"] or state["require_user_input"]:
            return "complete"
        else:
            # If not complete and we don't need user input, try again with other agents
            return "continue"
    async def route_query(self, state: AgentState) -> AgentState:
        """
        Route the query to the appropriate agent.
        """
        # Just pass through the state, the routing is done in determine_agent
        return state
    
    async def _determine_search_intent(self, query: str) -> str:
        """
        X√°c ƒë·ªãnh m·ª•c ƒë√≠ch t√¨m ki·∫øm d·ª±a tr√™n c√¢u truy v·∫•n.
        
        Args:
            query: C√¢u truy v·∫•n c·ªßa ng∆∞·ªùi d√πng
            
        Returns:
            "filesystem" n·∫øu l√† t√¨m ki·∫øm theo t√™n file, "rag" n·∫øu t√¨m ki·∫øm theo n·ªôi dung
        """
        query = query.lower()
        
        # Keywords indicating file name search
        file_name_keywords = [
            "t√™n file", "t√¨m file", "ƒë∆∞·ªùng d·∫´n", "th∆∞ m·ª•c",
            "trong folder", "trong th∆∞ m·ª•c", "t√¨m ki·∫øm file", "file t√™n"
        ]
        
        # Keywords indicating content search
        content_keywords = [
            "n·ªôi dung", "c√≥ ch·ª©a", "li√™n quan ƒë·∫øn", "n√≥i v·ªÅ",
            "th√¥ng tin v·ªÅ", "t√¨m ki·∫øm th√¥ng tin", "t√†i li·ªáu v·ªÅ", "vƒÉn b·∫£n"
        ]
        
        # Check for explicit content search
        if any(keyword in query for keyword in content_keywords):
            log(f"Ph√°t hi·ªán t√¨m ki·∫øm theo n·ªôi dung: {query}")
            return "rag"
            
        # Check for explicit file search
        if any(keyword in query for keyword in file_name_keywords):
            log(f"Ph√°t hi·ªán t√¨m ki·∫øm theo t√™n file: {query}")
            return "filesystem"
            
        # Default to content search for natural language queries
        if len(query.split()) > 3:  # Longer queries are likely content searches
            log(f"M·∫∑c ƒë·ªãnh t√¨m ki·∫øm theo n·ªôi dung cho c√¢u d√†i: {query}")
            return "rag"
            
        # Default to file system search for short queries
        log(f"M·∫∑c ƒë·ªãnh t√¨m ki·∫øm theo t√™n file cho c√¢u ng·∫Øn: {query}")
        return "filesystem"

    async def run_filesystem_agent(self, state: AgentState) -> AgentState:
        """
        Run the filesystem agent on the current query.
        """
        try:
            # Get the last message that's not from an agent
            query = ""
            for message in reversed(state["messages"]):
                if isinstance(message, HumanMessage):
                    query = message.content
                    break

            log(f"Running FilesystemAgent with query: {query}")

            # Track that we're using this agent
            if "used_tools" not in state:
                state["used_tools"] = []
            state["used_tools"].append("filesystem")

            # Get the filesystem agent graph
            filesystem_agent = self.agents["filesystem"]

            # Run the agent with the query and wait for completion
            config = {"configurable": {"thread_id": self.session_id}}
            log("Waiting for FilesystemAgent to complete...")
            response = await filesystem_agent.graph.ainvoke({"messages": state["messages"]}, config=config)
            log("FilesystemAgent completed")

            # Get the agent's response
            agent_response = None
            for message in reversed(response["messages"]):
                if isinstance(message, AIMessage):
                    agent_response = message
                    break

            if not agent_response or not agent_response.content.strip():
                # If there's no response or it's empty, create a default one
                agent_response = AIMessage(content="T√¥i ƒë√£ t√¨m ki·∫øm nh∆∞ng kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£ ph√π h·ª£p.")

            # Add the agent's response to the state
            response_content = f"üóÇÔ∏è {agent_response.content}"
            print(f"FilesystemAgent response: {response_content[:100]}...")
            state["messages"].append(AIMessage(content=response_content))
            
            # Check if filesystem agent found any results
            if "Kh√¥ng t√¨m th·∫•y" in agent_response.content or "kh√¥ng bi·∫øt" in agent_response.content.lower() or "kh√¥ng t√¨m th·∫•y" in agent_response.content.lower():
                print("Filesystem agent didn't find results. Trying RAG agent...")
                
                # Call RAG agent for content-based search
                rag_agent = self.agents["rag"]
                rag_result = await rag_agent.invoke(query, self.session_id)
                
                if isinstance(rag_result, dict) and 'content' in rag_result:
                    # Add RAG response to messages
                    rag_content = f"üîç T√¨m ki·∫øm theo n·ªôi dung file:\n\n{rag_result['content']}"
                    state["messages"].append(AIMessage(content=rag_content))
                    
                    # Add RAG to used tools
                    if "rag" not in state["used_tools"]:
                        state["used_tools"].append("rag")
                        
                    print(f"RAG agent found results: {rag_content[:100]}...")
            
            # Analyze the response to suggest next agent
            print("Analyzing response to suggest next agent...")
            next_agent = await self._suggest_next_agent(agent_response.content, state)
            if next_agent and next_agent not in state["current_agents"]:
                print(f"Adding {next_agent} to current_agents")
                state["current_agents"].append(next_agent)
            else:
                print(f"No additional agent suggested or already in use")

            return state

        except Exception as e:
            print(f"Error running filesystem agent: {e}")
            # Add an error message to the state
            error_message = f"Xin l·ªói, t√¥i g·∫∑p l·ªói khi t√¨m ki·∫øm t·ªáp: {str(e)}"
            state["messages"].append(AIMessage(content=error_message))
            return state

    async def _suggest_next_agent(self, response_content: str, state: AgentState) -> str:
        """
        S·ª≠ d·ª•ng LLM ƒë·ªÉ ph√¢n t√≠ch ph·∫£n h·ªìi c·ªßa agent v√† ƒë·ªÅ xu·∫•t agent ti·∫øp theo.
        
        Args:
            response_content: N·ªôi dung ph·∫£n h·ªìi c·ªßa agent
            state: Tr·∫°ng th√°i hi·ªán t·∫°i
            
        Returns:
            T√™n c·ªßa agent ti·∫øp theo, ho·∫∑c None n·∫øu kh√¥ng c√≥ ƒë·ªÅ xu·∫•t
        """
        # L·∫•y y√™u c·∫ßu ban ƒë·∫ßu c·ªßa ng∆∞·ªùi d√πng
        original_query = ""
        for message in state["messages"]:
            if isinstance(message, HumanMessage):
                original_query = message.content
                break
        
        # Danh s√°ch c√°c agent ƒë√£ s·ª≠ d·ª•ng
        used_agents = state.get("used_tools", [])
        
        # N·∫øu ƒë√£ s·ª≠ d·ª•ng qu√° nhi·ªÅu agent, kh√¥ng ƒë·ªÅ xu·∫•t th√™m
        if len(used_agents) >= 3:
            print("ƒê√£ s·ª≠ d·ª•ng qu√° nhi·ªÅu agent, kh√¥ng ƒë·ªÅ xu·∫•t th√™m")
            return None
        
        # T·∫°o prompt cho LLM
        prompt = f"""
        B·∫°n l√† m·ªôt h·ªá th·ªëng ƒëi·ªÅu ph·ªëi c√°c agent AI chuy√™n bi·ªát. D·ª±a tr√™n th√¥ng tin sau, h√£y quy·∫øt ƒë·ªãnh agent n√†o n√™n ƒë∆∞·ª£c s·ª≠ d·ª•ng ti·∫øp theo.
        
        Y√™u c·∫ßu ban ƒë·∫ßu c·ªßa ng∆∞·ªùi d√πng: "{original_query}"
        
        Ph·∫£n h·ªìi m·ªõi nh·∫•t t·ª´ agent: "{response_content}"
        
        C√°c agent ƒë√£ ƒë∆∞·ª£c s·ª≠ d·ª•ng: {used_agents}
        
        C√°c agent c√≥ s·∫µn:
        1. filesystem - T√¨m ki·∫øm, li·ªát k√™ v√† qu·∫£n l√Ω t·ªáp v√† th∆∞ m·ª•c
        2. metadata - T·∫°o v√† qu·∫£n l√Ω metadata cho t√†i li·ªáu
        3. text_extraction - Tr√≠ch xu·∫•t vƒÉn b·∫£n t·ª´ t·ªáp PDF, Word ho·∫∑c PowerPoint
        4. file_classification - Ph√¢n lo·∫°i n·ªôi dung t√†i li·ªáu
        
        QUAN TR·ªåNG: Ch·ªâ ƒë·ªÅ xu·∫•t m·ªôt agent ti·∫øp theo n·∫øu th·ª±c s·ª± c·∫ßn thi·∫øt d·ª±a tr√™n y√™u c·∫ßu ban ƒë·∫ßu v√† ph·∫£n h·ªìi hi·ªán t·∫°i.
        N·∫øu agent hi·ªán t·∫°i ƒë√£ gi·∫£i quy·∫øt ƒë∆∞·ª£c v·∫•n ƒë·ªÅ ho·∫∑c kh√¥ng c·∫ßn agent kh√°c, h√£y tr·∫£ l·ªùi "none".
        
        Tr·∫£ l·ªùi ch·ªâ v·ªõi t√™n c·ªßa agent (filesystem, metadata, text_extraction, file_classification) ho·∫∑c "none" n·∫øu kh√¥ng c·∫ßn agent n√†o n·ªØa.
        """
        
        try:
            # S·ª≠ d·ª•ng LLM ƒë·ªÉ quy·∫øt ƒë·ªãnh
            from config.llm import gemini
            response = await gemini.ainvoke(prompt)
            suggestion = response.content.strip().lower()
            
            # Ki·ªÉm tra xem c√≥ t·ª´ "none" trong ph·∫£n h·ªìi kh√¥ng
            if "none" in suggestion:
                print("LLM ƒë·ªÅ xu·∫•t kh√¥ng c·∫ßn s·ª≠ d·ª•ng th√™m agent")
                return None
            
            # X·ª≠ l√Ω ph·∫£n h·ªìi
            valid_agents = ["filesystem", "metadata", "text_extraction", "file_classification"]
            
            # Ch·ªâ ƒë·ªÅ xu·∫•t agent ch∆∞a ƒë∆∞·ª£c s·ª≠ d·ª•ng
            for agent in valid_agents:
                if agent in suggestion and agent not in used_agents:
                    print(f"LLM ƒë·ªÅ xu·∫•t s·ª≠ d·ª•ng {agent} ti·∫øp theo")
                    return agent
            
            # Kh√¥ng c√≥ ƒë·ªÅ xu·∫•t h·ª£p l·ªá
            return None
            
        except Exception as e:
            print(f"L·ªói khi ƒë·ªÅ xu·∫•t agent ti·∫øp theo: {e}")
            return None
    
    async def run_rag_agent(self, state: AgentState) -> AgentState:
        """
        Run the RAG agent to search file contents.
        """
        try:
            # Get the last message that's not from an agent
            query = ""
            for message in reversed(state["messages"]):
                if isinstance(message, HumanMessage):
                    query = message.content
                    break

            log(f"Running RAGAgent with query: {query}")

            # Track that we're using this agent
            if "used_tools" not in state:
                state["used_tools"] = []
            state["used_tools"].append("rag")

            # Get the RAG agent
            rag_agent = self.agents["rag"]

            # Run the agent with the query
            log("Searching with RAGAgent...")
            response = await rag_agent.invoke(query, session_id=self.session_id)
            log("RAGAgent search completed")

            # Format the response
            if isinstance(response, dict) and 'content' in response:
                response_content = response['content']
                # Extract file_paths if present for text extraction compatibility
                file_paths = response.get('file_paths', [])
            else:
                response_content = str(response)
                file_paths = []

            # Add the agent's response to the state with file_paths as additional kwargs if available
            print(f"RAGAgent response: {response_content[:200]}...")
            if file_paths:
                log(f"RAG agent found {len(file_paths)} file paths: {file_paths}")
                state["messages"].append(AIMessage(
                    content=response_content,
                    additional_kwargs={'file_paths': file_paths}
                ))
            else:
                state["messages"].append(AIMessage(content=response_content))
                
            # Mark task as complete since RAG search is typically a terminal operation
            state["task_complete"] = True
            state["require_user_input"] = False
            
            return state
            
        except Exception as e:
            log(f"Error in RAG agent: {str(e)}", level='error')
            state["messages"].append(AIMessage(
                content=f"C√≥ l·ªói x·∫£y ra khi t√¨m ki·∫øm n·ªôi dung: {str(e)}"
            ))
            state["task_complete"] = True
            state["require_user_input"] = False
            return state

    async def run_metadata_agent(self, state: AgentState) -> AgentState:
        """
        Run the metadata agent on the current query.
        """
        try:
            # Get the last message that's not from an agent
            query = ""
            for message in reversed(state["messages"]):
                if isinstance(message, HumanMessage):
                    query = message.content
                    break

            log(f"Running MetadataAgent with query: {query}")

            # Track that we're using this agent
            if "used_tools" not in state:
                state["used_tools"] = []
            state["used_tools"].append("metadata")

            # Extract file path from previous agent messages
            file_path = None
            file_content = None
            file_classification = None
            
            # First, look for file paths from RAG or filesystem agents
            for message in reversed(state["messages"]):
                if isinstance(message, AIMessage):
                    # Check for file_paths in additional_kwargs (from RAG agent)
                    if hasattr(message, '_additional_kwargs') and 'file_paths' in message._additional_kwargs:
                        file_paths = message._additional_kwargs['file_paths']
                        if file_paths and isinstance(file_paths, list) and len(file_paths) > 0:
                            file_path = file_paths[0]  # Take the first file
                            log(f"Found file path from RAG agent: {file_path}")
                            break
                    
                    # Check for file paths in message content
                    if "T√¥i ƒë√£ t√¨m th·∫•y file:" in message.content:
                        import re
                        file_pattern = r'T√¥i ƒë√£ t√¨m th·∫•y file:\s*([A-Z]:\\[^\s\n\r]+)'
                        file_matches = re.findall(file_pattern, message.content)
                        if file_matches:
                            file_path = file_matches[0]
                            log(f"Found file path from message content: {file_path}")
                            break
            
            # Then, look for extracted content from text extraction agent
            for message in reversed(state["messages"]):
                if not isinstance(message, AIMessage):
                    continue
                    
                # Check if this is a text extraction agent message
                is_extraction_msg = ("üìÑ" in message.content or "[Text Extraction Agent]:" in message.content or 
                                   "N·ªôi dung tr√≠ch xu·∫•t:" in message.content or
                                   "K·∫øt qu·∫£ tr√≠ch xu·∫•t t·ª´ file" in message.content)
                
                if is_extraction_msg:
                    log(f"Found text extraction agent message")
                    
                    # Try to extract content using different patterns
                    content = None
                    
                    # Pattern 1: Look for content after "N·ªôi dung tr√≠ch xu·∫•t:"
                    if "N·ªôi dung tr√≠ch xu·∫•t:" in message.content:
                        parts = message.content.split("N·ªôi dung tr√≠ch xu·∫•t:", 1)
                        if len(parts) > 1:
                            content = parts[1].strip()
                    
                    # Pattern 2: Look for content after the file path
                    elif "K·∫øt qu·∫£ tr√≠ch xu·∫•t t·ª´ file" in message.content:
                        # Find the first empty line after the header
                        lines = message.content.split('\n')
                        content_lines = []
                        found_header = False
                        
                        for line in lines:
                            if not found_header and ("K·∫øt qu·∫£ tr√≠ch xu·∫•t t·ª´ file" in line or "N·ªôi dung tr√≠ch xu·∫•t:" in line):
                                found_header = True
                                continue
                            if found_header and line.strip():
                                content_lines.append(line.strip())
                        
                        if content_lines:
                            content = '\n'.join(content_lines).strip()
                    
                    # If we found content, clean it up and store it
                    if content:
                        # Clean up any metadata or additional text
                        if "\n\n" in content:
                            content = content.split("\n\n")[0].strip()
                        
                        # Remove any trailing metadata or instructions
                        stop_phrases = [
                            "\nL∆∞u √Ω:", "\nGhi ch√∫:", "\nTh√¥ng tin th√™m:",
                            "\nNote:", "\nMetadata:", "\n---"
                        ]
                        
                        for phrase in stop_phrases:
                            if phrase in content:
                                content = content.split(phrase, 1)[0].strip()
                        
                        file_content = content
                        log(f"Extracted content length: {len(file_content)} characters")
                        log(f"Content preview: {file_content[:200]}...")
                        break
            
            # Finally, look for classification from file classification agent
            for message in reversed(state["messages"]):
                if isinstance(message, AIMessage) and ("üè∑Ô∏è" in message.content or "[File Classification Agent]:" in message.content or "K·∫øt qu·∫£ ph√¢n lo·∫°i file" in message.content or "Gi√°o d·ª•c" in message.content):
                    log("Found file classification agent message")
                    # Look for classification label in different possible formats
                    import re
                    
                    # Format 1: "Ph√¢n lo·∫°i: Gi√°o d·ª•c"
                    label_pattern1 = r'Ph√¢n lo·∫°i:\s*([^\n\r]+)'
                    # Format 2: "K·∫øt qu·∫£ ph√¢n lo·∫°i file ...: Gi√°o d·ª•c"
                    label_pattern2 = r'K·∫øt qu·∫£ ph√¢n lo·∫°i file[^:]*:\s*([^\n\r]+)'
                    # Format 3: Just the label itself (e.g. "Gi√°o d·ª•c")
                    
                    content = message.content
                    log(f"Analyzing classification content: {content}")
                    
                    # First try the standard patterns
                    label_matches = re.findall(label_pattern1, content)
                    if not label_matches:
                        label_matches = re.findall(label_pattern2, content)
                    
                    # If still no match, check if the content itself is just the label
                    if not label_matches and len(content.strip().split()) <= 3:
                        # If content is just 1-3 words, it might be just the label
                        label_matches = [content.strip()]
                    
                    if label_matches:
                        file_classification = label_matches[0].strip()
                        log(f"Found classification label: {file_classification}")
                        break
            
            # Prepare the metadata parameters
            metadata_params = {}
            
            # Set file information
            if file_path:
                import os
                metadata_params['file_name'] = os.path.basename(file_path)
                metadata_params['file_path'] = file_path
            
            # Set classification if available
            if file_classification and file_classification.lower() not in ["kh√¥ng x√°c ƒë·ªãnh", "ch∆∞a ph√¢n lo·∫°i", "kh√¥ng c√≥ ph√¢n lo·∫°i"]:
                # Clean up the classification label
                label = file_classification.split(':')[-1].strip()
                metadata_params['label'] = label
            
            # Set content if available
            if file_content:
                # Ensure content is properly formatted and not too long
                content = file_content.strip()
                if len(content) > 4000:  # Truncate if too long for the model
                    content = content[:4000] + "... [n·ªôi dung b·ªã c·∫Øt b·ªõt]"
                metadata_params['content'] = content
                log(f"Content length for metadata: {len(content)} characters")
            
            # Build the enhanced query for the metadata agent
            enhanced_query = "T√¥i c·∫ßn t·∫°o v√† l∆∞u metadata v·ªõi c√°c th√¥ng tin sau:\n\n"
            
            # Add file information if available
            if 'file_name' in metadata_params:
                enhanced_query += f"- T√äN FILE: {metadata_params['file_name']}\n"
            if 'file_path' in metadata_params:
                enhanced_query += f"- ƒê∆Ø·ªúNG D·∫™N: {metadata_params['file_path']}\n"
            if 'label' in metadata_params:
                enhanced_query += f"- PH√ÇN LO·∫†I: {metadata_params['label']} (t·ª± ƒë·ªông)\n"
            
            # Add content preview if available
            if 'content' in metadata_params and metadata_params['content']:
                content = metadata_params['content']
                preview_length = min(200, len(content))
                preview = content[:preview_length]
                
                enhanced_query += f"\nN·ªòI DUNG (XEM TR∆Ø·ªöC {preview_length}/{len(content)} k√Ω t·ª±):\n"
                enhanced_query += f"""
================================================================================
{preview}
... [N·ªòI DUNG ƒê·∫¶Y ƒê·ª¶ ƒê∆Ø·ª¢C CUNG C·∫§P ·ªû PH·∫¶N D∆Ø·ªöI]
================================================================================
"""
            
            # Add clear instructions for the metadata agent
            enhanced_query += """

H∆Ø·ªöNG D·∫™N QUAN TR·ªåNG:
1. ƒê·ªåC K·ª∏: To√†n b·ªô n·ªôi dung ƒë√£ ƒë∆∞·ª£c cung c·∫•p ƒë·∫ßy ƒë·ªß ·ªü ph·∫ßn d∆∞·ªõi
2. KH√îNG y√™u c·∫ßu th√™m n·ªôi dung v√¨ ƒë√£ c√≥ s·∫µn
3. Th·ª±c hi·ªán c√°c b∆∞·ªõc sau:
   - G·ªçi create_metadata v·ªõi ƒë·∫ßy ƒë·ªß th√¥ng tin
   - L∆∞u metadata b·∫±ng save_metadata_to_mcp
   - Tr·∫£ v·ªÅ metadata_id ƒë√£ t·∫°o

TH√îNG TIN CHI TI·∫æT:
"""
            
            # Include all metadata params in a clear format
            for key, value in metadata_params.items():
                if key == 'content':
                    enhanced_query += f"\nN·ªòI DUNG ƒê·∫¶Y ƒê·ª¶ ({len(value)} k√Ω t·ª±):\n"
                    enhanced_query += "="*80 + "\n"
                    enhanced_query += value[:4000]  # Truncate to avoid token limits
                    if len(value) > 4000:
                        enhanced_query += "\n... [ƒê√É C·∫ÆT B·ªöT N·ªòI DUNG DO QU√Å D√ÄI]"
                    enhanced_query += "\n" + "="*80 + "\n"
                else:
                    enhanced_query += f"{key.upper()}: {value}\n"
            
            # Final reminder
            enhanced_query += """

L∆ØU √ù CU·ªêI C√ôNG:
- S·ª≠ d·ª•ng N·ªòI DUNG ƒê·∫¶Y ƒê·ª¶ ·ªü tr√™n ƒë·ªÉ t·∫°o metadata
- KH√îNG y√™u c·∫ßu th√™m n·ªôi dung
- Tr·∫£ v·ªÅ metadata_id sau khi l∆∞u th√†nh c√¥ng
"""
            
            log(f"Metadata parameters: {metadata_params}")
            log(f"Enhanced metadata query: {enhanced_query[:300]}...")

            # Get the metadata agent
            metadata_agent = self.agents["metadata"]

            # Initialize MCP connection if needed
            if not hasattr(metadata_agent, 'mcp_initialized') or not metadata_agent.mcp_initialized:
                log("Initializing MCP connection...")
                if not metadata_agent.initialize_mcp_sync():
                    error_msg = "‚ùå Failed to initialize MCP connection for metadata agent"
                    log(error_msg, level='error')
                    state["messages"].append(AIMessage(content=error_msg))
                    return state
            
            # Initialize variables
            metadata_id = None
            response_content = ""
            
            try:
                # Log metadata parameters for debugging
                log("Preparing to invoke MetadataAgent with the following parameters:")
                log(f"- File: {metadata_params.get('file_name', 'N/A')}")
                log(f"- Path: {metadata_params.get('file_path', 'N/A')}")
                log(f"- Label: {metadata_params.get('label', 'N/A')}")
                log(f"- Content length: {len(metadata_params.get('content', ''))} characters")
                
                # Call the metadata agent with the enhanced query and metadata
                log("Invoking MetadataAgent...")
                response = metadata_agent.invoke(
                    query=enhanced_query,
                    sessionId=self.session_id,
                    metadata={
                        'file_name': metadata_params.get('file_name'),
                        'file_path': metadata_params.get('file_path'),
                        'label': metadata_params.get('label'),
                        'content': metadata_params.get('content', '')
                    }
                )
                log("MetadataAgent completed successfully")
                
                # Process the response
                if not response or not response.strip():
                    response_content = "T√¥i ƒë√£ x·ª≠ l√Ω metadata nh∆∞ng kh√¥ng c√≥ k·∫øt qu·∫£ ƒë√°ng ch√∫ √Ω."
                    log("No response content from MetadataAgent")
                else:
                    # Clean up the response
                    response = response.strip()
                    log(f"Raw metadata agent response: {response}")
                    
                    # Try to extract metadata ID from the response
                    import re
                    
                    # Look for various possible ID formats in the response
                    id_patterns = [
                        r'metadata[_-]?id[\s:]*([a-f0-9-]+)',  # metadata-id: xxxx
                        r'id[\s:]*([a-f0-9-]{8,})',            # id: xxxxxxxx-xxxx-...
                        r'([a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12})'  # UUID format
                    ]
                    
                    for pattern in id_patterns:
                        match = re.search(pattern, response, re.IGNORECASE)
                        if match:
                            metadata_id = match.group(1)
                            log(f"Found metadata ID using pattern {pattern}: {metadata_id}")
                            break
                    
                    if metadata_id:
                        response_content = f"‚úÖ ƒê√£ l∆∞u metadata th√†nh c√¥ng. ID: {metadata_id}"
                        log(f"Metadata saved with ID: {metadata_id}")
                        
                        # Also check if the metadata was actually saved to MCP
                        try:
                            metadata_agent = self.agents["metadata"]
                            if hasattr(metadata_agent, 'mcp_connection'):
                                result = metadata_agent.mcp_connection.call_tool_sync(
                                    "get_metadata_by_id", 
                                    {"metadata_id": metadata_id}
                                )
                                if result and 'error' not in result:
                                    log(f"Verified metadata exists in MCP: {metadata_id}")
                                else:
                                    log(f"Warning: Metadata ID {metadata_id} not found in MCP", level='warning')
                        except Exception as e:
                            log(f"Error verifying metadata in MCP: {str(e)}", level='error')
                    else:
                        # If no ID found, check if this is an error message
                        error_keywords = ['l·ªói', 'error', 'failed', 'th·∫•t b·∫°i', 'kh√¥ng t√¨m th·∫•y', 'not found']
                        if any(keyword in response.lower() for keyword in error_keywords):
                            response_content = f"‚ùå L·ªói khi x·ª≠ l√Ω metadata: {response}"
                        else:
                            response_content = f"‚ÑπÔ∏è ƒê√£ x·ª≠ l√Ω metadata: {response}"
                        
                        log(f"Metadata agent response (no ID found): {response}")
                        
                # Add the response to the conversation
                formatted_response = f"üìã {response_content}"
                log(f"MetadataAgent response: {formatted_response[:200]}...")
                state["messages"].append(AIMessage(content=formatted_response))
                
                # Store metadata info in the state for future reference
                if 'metadata' not in state:
                    state['metadata'] = {}
                
                if 'metadata_ids' not in state['metadata']:
                    state['metadata']['metadata_ids'] = []
                    
                if metadata_id:  # Use the metadata_id variable that we defined earlier
                    state['metadata']['metadata_ids'].append(metadata_id)
                    log(f"Added metadata ID to state: {metadata_id}")
                else:
                    log("No metadata ID to add to state", level='warning')
                
                # Mark task as complete
                state["task_complete"] = True
                state["require_user_input"] = False
                
                return state
                
            except Exception as e:
                error_msg = f"L·ªói khi ch·∫°y MetadataAgent: {str(e)}"
                log(error_msg, level='error')
                state["messages"].append(AIMessage(
                    content=f"[L·ªói] {error_msg}. Vui l√≤ng th·ª≠ l·∫°i ho·∫∑c ki·ªÉm tra k·∫øt n·ªëi MCP server."
                ))
                state["task_complete"] = True
                state["require_user_input"] = True
                return state

        except Exception as e:
            import traceback
            print(f"Error running metadata agent: {e}")
            print(traceback.format_exc())
            # Add an error message to the state
            error_message = f"Xin l·ªói, t√¥i g·∫∑p l·ªói khi x·ª≠ l√Ω metadata: {str(e)}"
            state["messages"].append(AIMessage(content=error_message))
            return state

    async def run_text_extraction_agent(self, state: AgentState) -> AgentState:
        """
        Run the text extraction agent on the current query.
        """
        try:
            # T√¨m file path t·ª´ c√°c tin nh·∫Øn tr∆∞·ªõc ƒë√≥ d·ª±a v√†o c√¢u "T√¥i ƒë√£ t√¨m th·∫•y file:"
            file_path = None
            for message in reversed(state["messages"]):
                if isinstance(message, AIMessage):
                    log(f"Checking message for file path: {message.content[:100]}...")
                    
                    # Ki·ªÉm tra xem tin nh·∫Øn c√≥ ph·∫£i l√† t·ª´ RAG agent kh√¥ng (c√≥ th·ªÉ c√≥ tr∆∞·ªùng file_paths)
                    if hasattr(message, '_additional_kwargs') and 'file_paths' in message._additional_kwargs:
                        log(f"Found RAG agent message with file_paths field")
                        file_paths = message._additional_kwargs['file_paths']
                        if file_paths and isinstance(file_paths, list) and len(file_paths) > 0:
                            file_path = file_paths[0]  # L·∫•y file ƒë·∫ßu ti√™n
                            log(f"Extracted file path from RAG agent: {file_path}")
                            break
                    
                    # T√¨m ki·∫øm c√¢u "T√¥i ƒë√£ t√¨m th·∫•y file:" trong tin nh·∫Øn
                    if "T√¥i ƒë√£ t√¨m th·∫•y file:" in message.content:
                        log(f"Found agent message with standard format")
                        
                        # T√¨m ƒë∆∞·ªùng d·∫´n file sau c√¢u "T√¥i ƒë√£ t√¨m th·∫•y file:"
                        import re
                        
                        # T√¨m sau "T√¥i ƒë√£ t√¨m th·∫•y file:" - ki·ªÉm tra c·∫£ ƒë∆∞·ªùng d·∫´n ƒë·∫ßy ƒë·ªß v√† t√™n file
                        full_path_pattern = r'T√¥i ƒë√£ t√¨m th·∫•y file:\s*([A-Z]:\\[^\s\n\r]+)'
                        full_path_matches = re.findall(full_path_pattern, message.content)
                        
                        if full_path_matches:
                            # L·∫•y ƒë∆∞·ªùng d·∫´n v√† lo·∫°i b·ªè c√°c k√Ω t·ª± kh√¥ng mong mu·ªën ·ªü cu·ªëi
                            raw_path = full_path_matches[0]
                            # Lo·∫°i b·ªè c√°c k√Ω t·ª± kh√¥ng mong mu·ªën c√≥ th·ªÉ c√≥ ·ªü cu·ªëi ƒë∆∞·ªùng d·∫´n
                            if raw_path.endswith("'}"):
                                file_path = raw_path[:-2]
                            else:
                                file_path = raw_path
                            log(f"Extracted full file path: {file_path}")
                            break
                    
                    # D·ª± ph√≤ng: N·∫øu kh√¥ng t√¨m th·∫•y c√¢u chu·∫©n, th·ª≠ t√¨m b·∫•t k·ª≥ ƒë∆∞·ªùng d·∫´n Windows n√†o
                    elif any(indicator in message.content for indicator in ["ƒê√£ t√¨m th·∫•y file:", "t√¨m th·∫•y file", "[Filesystem Agent]:", "[RAG Agent]:", "üóÇÔ∏è", "üîç"]):
                        log(f"Found agent message with non-standard format")
                        
                        # T√¨m b·∫•t k·ª≥ ƒë∆∞·ªùng d·∫´n n√†o trong tin nh·∫Øn
                        import re
                        file_pattern = r'[A-Z]:\\(?:[^\\/:*?"<>|\r\n]+\\)*[^\\/:*?"<>|\r\n]*\.[a-zA-Z0-9]+'
                        file_matches = re.findall(file_pattern, message.content)
                        
                        if file_matches:
                            file_path = file_matches[0]
                            log(f"Extracted file path using general pattern: {file_path}")
                            break

            # Get the last message that's not from an agent
            query = ""
            for message in reversed(state["messages"]):
                if isinstance(message, HumanMessage):
                    query = message.content
                    break

            # Ki·ªÉm tra quy·ªÅn truy c·∫≠p file n·∫øu t√¨m th·∫•y file path
            if file_path:
                # Import AccessControlManager
                import sys
                import os
                current_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
                if current_dir not in sys.path:
                    sys.path.insert(0, current_dir)
                from utils.access_control import AccessControlManager
                
                # L·∫•y vai tr√≤ ng∆∞·ªùi d√πng t·ª´ state ho·∫∑c session
                user_role = state.get("user_role", "user")  # M·∫∑c ƒë·ªãnh l√† "user" n·∫øu kh√¥ng c√≥
                
                # Kh·ªüi t·∫°o AccessControlManager
                access_control_file = os.path.join(current_dir, "config", "access_control.json")
                access_manager = AccessControlManager(access_control_file)
                
                # Ki·ªÉm tra quy·ªÅn truy c·∫≠p
                has_access, reason = access_manager.check_file_access(file_path, user_role)
                access_manager.log_access_attempt(file_path, user_role, has_access, reason)
                
                if not has_access:
                    # Kh√¥ng c√≥ quy·ªÅn truy c·∫≠p, th√¥ng b√°o cho ng∆∞·ªùi d√πng
                    error_message = f"‚ö†Ô∏è Kh√¥ng th·ªÉ tr√≠ch xu·∫•t n·ªôi dung: {reason}"
                    state["messages"].append(AIMessage(content=error_message))
                    log(f"Access denied: {reason}", level='warning')
                    return state
                
                # C√≥ quy·ªÅn truy c·∫≠p, ti·∫øp t·ª•c v·ªõi tr√≠ch xu·∫•t
                log(f"Access granted for user role '{user_role}' to file '{file_path}'")
                enhanced_query = f"Extract text from the file at path {file_path}"
                log(f"Enhanced query with file path: {enhanced_query}")
            else:
                # Kh√¥ng t√¨m th·∫•y file path, s·ª≠ d·ª•ng query g·ªëc
                enhanced_query = query
                log(f"WARNING: No file path found! Running TextExtractionAgent with original query: {query}")

            # Track that we're using this agent
            if "used_tools" not in state:
                state["used_tools"] = []
            state["used_tools"].append("text_extraction")

            # Get the text extraction agent
            text_extraction_agent = self.agents["text_extraction"]

            # Run the agent with the query and wait for completion
            log("Waiting for TextExtractionAgent to complete...")
            response = text_extraction_agent.invoke(enhanced_query, self.session_id)
            log("TextExtractionAgent completed")
            
            # Log raw response for debugging
            log(f"Raw TextExtractionAgent response: {response}")

            # Format the response - ch·∫•p nh·∫≠n nhi·ªÅu ƒë·ªãnh d·∫°ng tr·∫£ v·ªÅ kh√°c nhau
            content = ""
            
            # Tr∆∞·ªùng h·ª£p 1: Response l√† dict v·ªõi key 'content'
            if isinstance(response, dict) and 'content' in response:
                content = response['content']
                log(f"Extracted content from response dict with key 'content': {content[:100]}...")
            
            # Tr∆∞·ªùng h·ª£p 2: Response l√† string
            elif isinstance(response, str):
                content = response
                log(f"Response is already a string: {content[:100]}...")
            
            # Tr∆∞·ªùng h·ª£p 3: Response l√† dict nh∆∞ng kh√¥ng c√≥ 'content', th·ª≠ t√¨m c√°c key kh√°c
            elif isinstance(response, dict):
                log(f"Response keys: {list(response.keys())}")
                
                # Th·ª≠ l·∫•y t·ª´ key 'response_type' tr∆∞·ªõc
                if 'response_type' in response and 'content' in response:
                    content = response['content']
                    log(f"Using content from standard response format: {content[:100]}...")
                
                # Th·ª≠ l·∫•y gi√° tr·ªã t·ª´ c√°c key kh√°c n·∫øu l√† string d√†i
                else:
                    for key in response.keys():
                        if isinstance(response[key], str) and len(response[key]) > 20:
                            content = response[key]
                            log(f"Using content from key '{key}': {content[:100]}...")
                            break
            
            # Tr∆∞·ªùng h·ª£p 4: C√°c tr∆∞·ªùng h·ª£p kh√°c, chuy·ªÉn v·ªÅ string
            else:
                content = str(response)
                log(f"Converted response to string: {content[:100]}...")
                
            # Ki·ªÉm tra n·∫øu content ch·ª©a k·∫øt qu·∫£ tr√≠ch xu·∫•t
            if "I'll extract the text from" in content or "Here's the extracted text" in content:
                # T√¨m ph·∫ßn n·ªôi dung tr√≠ch xu·∫•t sau c√°c c√¢u m·ªü ƒë·∫ßu
                import re
                extracted_text = re.split(r"Here's the extracted text[:\s]*|I'll extract the text[^:]*:\s*", content, 1)
                if len(extracted_text) > 1:
                    content = extracted_text[1].strip()
                    log(f"Extracted the actual content after introduction: {content[:100]}...")
            
            # Ki·ªÉm tra n·∫øu content ch·ª©a "I'll use the extract_text_from" (c√¢u tr·∫£ l·ªù c·ªßa agent)
            if "I'll use the extract_text_from" in content and file_path:
                log("Agent response contains tool usage description but no actual extraction result")
                # Th·ª≠ tr·ª±c ti·∫øp c√°c h√†m tr√≠ch xu·∫•t d·ª±a v√†o ƒë·ªãnh d·∫°ng file
                try:
                    if file_path.lower().endswith('.pdf'):
                        from agents.text_extraction_agent import extract_text_from_pdf
                        content = extract_text_from_pdf(file_path)
                        log("Directly extracted text from PDF")
                    elif file_path.lower().endswith('.docx'):
                        from agents.text_extraction_agent import extract_text_from_word
                        content = extract_text_from_word(file_path)
                        log("Directly extracted text from Word document")
                    elif file_path.lower().endswith(('.ppt', '.pptx')):
                        from agents.text_extraction_agent import extract_text_from_powerpoint
                        content = extract_text_from_powerpoint(file_path)
                        log("Directly extracted text from PowerPoint")
                except Exception as e:
                    log(f"Error in direct extraction: {e}", level='error')

            if not content.strip():
                if file_path:
                    content = f"T√¥i ƒë√£ c·ªë g·∫Øng tr√≠ch xu·∫•t n·ªôi dung t·ª´ file {file_path} nh∆∞ng kh√¥ng c√≥ k·∫øt qu·∫£ ƒë√°ng ch√∫ √Ω."
                else:
                    content = "T√¥i ƒë√£ c·ªë g·∫Øng tr√≠ch xu·∫•t n·ªôi dung nh∆∞ng kh√¥ng c√≥ k·∫øt qu·∫£ ƒë√°ng ch√∫ √Ω."

            # Add the agent's response to the state with clear indication of extraction results
            if file_path:
                response_content = f"üìÑ K·∫øt qu·∫£ tr√≠ch xu·∫•t t·ª´ file {file_path}:\n\n{content}"
            else:
                response_content = f"üìÑ {content}"
                
            log(f"TextExtractionAgent response: {response_content[:100]}...")
            state["messages"].append(AIMessage(content=response_content))
            
            # Analyze the response to suggest next agent
            log("Analyzing response to suggest next agent...")
            next_agent = await self._suggest_next_agent(content, state)
            if next_agent and next_agent not in state["current_agents"]:
                log(f"Adding {next_agent} to current_agents")
                state["current_agents"].append(next_agent)
            else:
                log(f"No additional agent suggested or already in use")

            return state

        except Exception as e:
            log(f"Error running text extraction agent: {e}", level='error')
            # Add an error message to the state
            error_message = f"Xin l·ªói, t√¥i g·∫∑p l·ªói khi tr√≠ch xu·∫•t n·ªôi dung: {str(e)}"
            state["messages"].append(AIMessage(content=error_message))
            return state
            
    # The run_rag_agent method is already defined above (lines 653-703)
    # This duplicate definition was causing the 'Unknown agent: rag' error
            
    async def run_file_classification_agent(self, state: AgentState):
        """
        Run the file classification agent on the current query.
        """
        try:
            # T√¨m n·ªôi dung c·∫ßn ph√¢n lo·∫°i t·ª´ TextExtractionAgent
            content_to_classify = None
            file_path = None
            
            # T√¨m k·∫øt qu·∫£ t·ª´ TextExtractionAgent
            for message in reversed(state["messages"]):
                if isinstance(message, AIMessage) and ("üìÑ" in message.content or "[Text Extraction Agent]:" in message.content):
                    # Tr√≠ch xu·∫•t n·ªôi dung sau ph·∫ßn gi·ªõi thi·ªáu
                    text_parts = message.content.split(":\n\n", 1)
                    if len(text_parts) > 1:
                        content_to_classify = text_parts[1].strip()
                        log(f"Found content to classify from TextExtractionAgent: {content_to_classify[:100]}...")
                        
                        # T√¨m file path trong ph·∫ßn gi·ªõi thi·ªáu
                        import re
                        file_pattern = r't·ª´ file ([A-Z]:\\[^\s\n\r]+)'
                        file_matches = re.findall(file_pattern, text_parts[0])
                        if file_matches:
                            file_path = file_matches[0]
                            log(f"Found file path: {file_path}")
                        break
            
            # N·∫øu kh√¥ng t√¨m th·∫•y n·ªôi dung t·ª´ TextExtractionAgent, t√¨m file path t·ª´ FilesystemAgent
            if not content_to_classify:
                for message in reversed(state["messages"]):
                    if isinstance(message, AIMessage) and "T√¥i ƒë√£ t√¨m th·∫•y file:" in message.content:
                        # Tr√≠ch xu·∫•t ƒë∆∞·ªùng d·∫´n file t·ª´ tin nh·∫Øn
                        import re
                        file_pattern = r'T√¥i ƒë√£ t√¨m th·∫•y file:\s*([A-Z]:\\[^\s\n\r]+)'
                        file_matches = re.findall(file_pattern, message.content)
                        if file_matches:
                            raw_path = file_matches[0]
                            # Lo·∫°i b·ªè c√°c k√Ω t·ª± kh√¥ng mong mu·ªën c√≥ th·ªÉ c√≥ ·ªü cu·ªëi ƒë∆∞·ªùng d·∫´n
                            if raw_path.endswith("'}"):
                                file_path = raw_path[:-2]
                            else:
                                file_path = raw_path
                            log(f"Found file path from FilesystemAgent: {file_path}")
                            break

            # Get the last message that's not from an agent
            query = ""
            for message in reversed(state["messages"]):
                if isinstance(message, HumanMessage):
                    query = message.content
                    break

            # Chu·∫©n b·ªã query cho FileClassificationAgent
            if content_to_classify:
                # N·∫øu c√≥ n·ªôi dung, s·ª≠ d·ª•ng n·ªôi dung ƒë√≥ ƒë·ªÉ ph√¢n lo·∫°i
                classification_query = f"Ph√¢n lo·∫°i t·ªáp theo n·ªôi dung: '{content_to_classify[:1000]}'"  # Gi·ªõi h·∫°n ƒë·ªô d√†i
                log(f"Using extracted content for classification")
            elif file_path:
                # N·∫øu ch·ªâ c√≥ ƒë∆∞·ªùng d·∫´n, y√™u c·∫ßu agent ph√¢n lo·∫°i d·ª±a tr√™n file path
                classification_query = f"H√£y ph√¢n lo·∫°i file: {file_path}"
                log(f"Using file path for classification: {file_path}")
            else:
                # Kh√¥ng c√≥ c·∫£ n·ªôi dung v√† ƒë∆∞·ªùng d·∫´n, s·ª≠ d·ª•ng query g·ªëc
                classification_query = query
                log(f"No content or file path found. Using original query: {query}")
            
            # Track that we're using this agent
            if "used_tools" not in state:
                state["used_tools"] = []
            state["used_tools"].append("file_classification")

            # Get the file classification agent
            file_classification_agent = self.agents["file_classification"]

            # Run the agent with the prepared query
            log(f"Running FileClassificationAgent with query: {classification_query[:100]}...")
            response = file_classification_agent.invoke(classification_query, self.session_id)
            log("FileClassificationAgent completed")
            
            # Log raw response for debugging
            log(f"Raw FileClassificationAgent response: {response}")

            # X·ª≠ l√Ω k·∫øt qu·∫£ t·ª´ FileClassificationAgent
            classification_result = ""
            
            # Tr∆∞·ªùng h·ª£p 1: Response l√† dict v·ªõi key 'content'
            if isinstance(response, dict) and 'content' in response:
                classification_result = response['content']
                log(f"Extracted classification from response dict: {classification_result}")
            
            # Tr∆∞·ªùng h·ª£p 2: Response l√† string
            elif isinstance(response, str):
                classification_result = response
                log(f"Response is already a string: {classification_result}")
            
            # Tr∆∞·ªùng h·ª£p 3: C√°c tr∆∞·ªùng h·ª£p kh√°c, chuy·ªÉn v·ªÅ string
            else:
                classification_result = str(response)
                log(f"Converted response to string: {classification_result}")

            # Ki·ªÉm tra k·∫øt qu·∫£ ph√¢n lo·∫°i
            if not classification_result.strip():
                classification_result = "Kh√¥ng th·ªÉ ph√¢n lo·∫°i"

            # Add the agent's response to the state with clear indication of classification results
            if file_path:
                response_content = f"üè∑Ô∏è K·∫øt qu·∫£ ph√¢n lo·∫°i file {file_path}: {classification_result}"
            else:
                response_content = f"üè∑Ô∏è K·∫øt qu·∫£ ph√¢n lo·∫°i: {classification_result}"
                
            log(f"FileClassificationAgent response: {response_content}")
            
            # Th√™m k·∫øt qu·∫£ ph√¢n lo·∫°i v√†o state
            state["messages"].append(AIMessage(content=response_content))
            
            # Analyze the response to suggest next agent
            log("Analyzing response to suggest next agent...")
            next_agent = await self._suggest_next_agent(classification_result, state)
            if next_agent and next_agent not in state["current_agents"]:
                log(f"Adding {next_agent} to current_agents")
                state["current_agents"].append(next_agent)
            else:
                log(f"No additional agent suggested or already in use")

            return state

        except Exception as e:
            log(f"Error running file classification agent: {e}", level='error')
            # Add an error message to the state
            error_message = f"Xin l·ªói, t√¥i g·∫∑p l·ªói khi ph√¢n lo·∫°i t·ªáp: {str(e)}"
            state["messages"].append(AIMessage(content=error_message))
            return state

    async def plan_agents(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """
        L·∫≠p k·∫ø ho·∫°ch s·ª≠ d·ª•ng c√°c agent d·ª±a tr√™n y√™u c·∫ßu c·ªßa ng∆∞·ªùi d√πng.
        
        Args:
            state: Tr·∫°ng th√°i hi·ªán t·∫°i c·ªßa h·ªá th·ªëng
            
        Returns:
            Tr·∫°ng th√°i ƒë√£ c·∫≠p nh·∫≠t v·ªõi k·∫ø ho·∫°ch s·ª≠ d·ª•ng agent
        """
        # L·∫•y y√™u c·∫ßu c·ªßa ng∆∞·ªùi d√πng t·ª´ tin nh·∫Øn cu·ªëi c√πng
        last_message = state["messages"][-1]
        query = last_message.content
        
        try:
            # X√°c ƒë·ªãnh m·ª•c ƒë√≠ch t√¨m ki·∫øm (filesystem hay rag) ƒë·ªÉ cung c·∫•p g·ª£i √Ω cho LLM
            search_intent = await self._determine_search_intent(query)
            intent_hint = "" if search_intent == "filesystem" else "\nG·ª£i √Ω: Y√™u c·∫ßu n√†y c√≥ th·ªÉ li√™n quan ƒë·∫øn t√¨m ki·∫øm theo n·ªôi dung, n√™n c√≥ th·ªÉ c·∫ßn s·ª≠ d·ª•ng RAG agent."
            
            # S·ª≠ d·ª•ng LLM ƒë·ªÉ l·∫≠p k·∫ø ho·∫°ch cho m·ªçi lo·∫°i y√™u c·∫ßu
            planning_prompt = f"""
            B·∫°n l√† m·ªôt h·ªá th·ªëng ƒëi·ªÅu ph·ªëi c√°c agent AI chuy√™n bi·ªát. D·ª±a tr√™n y√™u c·∫ßu c·ªßa ng∆∞·ªùi d√πng, h√£y l·∫≠p k·∫ø ho·∫°ch s·ª≠ d·ª•ng c√°c agent ph√π h·ª£p.
            
            Y√™u c·∫ßu c·ªßa ng∆∞·ªùi d√πng: "{query}"
            
            C√°c agent c√≥ s·∫µn:
            1. filesystem - T√¨m ki·∫øm, li·ªát k√™ v√† qu·∫£n l√Ω t·ªáp v√† th∆∞ m·ª•c theo t√™n file
            2. rag - T√¨m ki·∫øm t√†i li·ªáu theo n·ªôi dung ho·∫∑c ng·ªØ nghƒ©a (t√¨m ki·∫øm theo t·ª´ kh√≥a, ch·ªß ƒë·ªÅ, ho·∫∑c n·ªôi dung li√™n quan)
            3. metadata - T·∫°o v√† qu·∫£n l√Ω metadata cho t√†i li·ªáu (l∆∞u th√¥ng tin v·ªÅ file nh∆∞ t√™n, lo·∫°i, nh√£n, m√¥ t·∫£ v√†o MCP server)
            4. text_extraction - Tr√≠ch xu·∫•t vƒÉn b·∫£n t·ª´ t·ªáp PDF, Word ho·∫∑c PowerPoint
            5. file_classification - Ph√¢n lo·∫°i n·ªôi dung t√†i li·ªáu
            
            L∆ØU √ù QUAN TR·ªåNG (PH·∫¢I TU√ÇN TH·ª¶ CH√çNH X√ÅC):
            - N·∫øu y√™u c·∫ßu ch·ªâ li√™n quan ƒë·∫øn t√¨m ki·∫øm file th√¨ ch·ªâ s·ª≠ d·ª•ng filesystem agent ho·∫∑c rag agent kh√¥ng s·ª≠ d·ª•ng th√™m c√°c agent kh√°c
            - N·∫øu y√™u c·∫ßu li√™n quan ƒë·∫øn t√¨m ki·∫øm theo t√™n file, s·ª≠ d·ª•ng filesystem agent
            - N·∫øu y√™u c·∫ßu li√™n quan ƒë·∫øn t√¨m ki·∫øm theo n·ªôi dung, ch·ªß ƒë·ªÅ, ho·∫∑c ng·ªØ nghƒ©a, s·ª≠ d·ª•ng rag agent
            - N·∫øu y√™u c·∫ßu li√™n quan ƒë·∫øn vi·ªác l∆∞u metadata, PH·∫¢I tu√¢n th·ªß th·ª© t·ª± ch√≠nh x√°c sau:
              1. ƒê·∫ßu ti√™n: t√¨m file (filesystem ho·∫∑c rag)
              2. Ti·∫øp theo: tr√≠ch xu·∫•t n·ªôi dung (text_extraction)
              3. Sau ƒë√≥: ph√¢n lo·∫°i (file_classification)
              4. Cu·ªëi c√πng: l∆∞u metadata (metadata)
            - KH√îNG BAO GI·ªú ƒë·∫∑t metadata agent tr∆∞·ªõc text_extraction ho·∫∑c file_classification
            - N·∫øu y√™u c·∫ßu c√≥ nhi·ªÅu b∆∞·ªõc, h√£y li·ªát k√™ t·∫•t c·∫£ c√°c agent c·∫ßn thi·∫øt theo ƒë√∫ng th·ª© t·ª± logic
            {intent_hint}
            
            H√£y l·∫≠p k·∫ø ho·∫°ch s·ª≠ d·ª•ng c√°c agent. ƒê·∫ßu ti√™n, tr·∫£ l·ªùi v·ªõi danh s√°ch c√°c agent c·∫ßn s·ª≠ d·ª•ng theo th·ª© t·ª±, ch·ªâ li·ªát k√™ t√™n c√°c agent (filesystem, rag, metadata, text_extraction, file_classification), c√°ch nhau b·∫±ng d·∫•u ph·∫©y.
            
            Sau ƒë√≥, vi·∫øt m·ªôt ƒëo·∫°n vƒÉn ng·∫Øn gi·∫£i th√≠ch k·∫ø ho·∫°ch c·ªßa b·∫°n b·∫±ng ti·∫øng Vi·ªát.
            """
            

            # S·ª≠ d·ª•ng LLM ƒë·ªÉ l·∫≠p k·∫ø ho·∫°ch
            from config.llm import gemini
            response = await gemini.ainvoke(planning_prompt)
            plan_response = response.content.strip()
            
            # T√°ch ph·∫ßn danh s√°ch agent v√† ph·∫ßn gi·∫£i th√≠ch
            parts = plan_response.split('\n', 1)
            agent_list = parts[0].strip().lower()
            plan_message = parts[1].strip() if len(parts) > 1 else f"T√¥i s·∫Ω gi√∫p b·∫°n v·ªõi y√™u c·∫ßu: '{query}'."
            
            # X·ª≠ l√Ω danh s√°ch agent
            needed_agents = []
            valid_agents = ["filesystem", "rag", "metadata", "text_extraction", "file_classification"]
            
            for agent in valid_agents:
                if agent in agent_list:
                    needed_agents.append(agent)
            
            if not needed_agents:
                # M·∫∑c ƒë·ªãnh s·ª≠ d·ª•ng filesystem n·∫øu kh√¥ng c√≥ agent n√†o ƒë∆∞·ª£c ch·ªçn
                needed_agents.append("filesystem")
                plan_message += "\nT√¥i s·∫Ω b·∫Øt ƒë·∫ßu v·ªõi Filesystem Agent ƒë·ªÉ t√¨m ki·∫øm th√¥ng tin."
            
            log(f"K·∫ø ho·∫°ch agent d·ª±a tr√™n LLM: {needed_agents}")
            
        except Exception as e:
            log(f"L·ªói khi l·∫≠p k·∫ø ho·∫°ch s·ª≠ d·ª•ng agent: {e}", level='error')
            # S·ª≠ d·ª•ng m·∫∑c ƒë·ªãnh n·∫øu c√≥ l·ªói
            needed_agents = ["filesystem"]
            plan_message = f"T√¥i s·∫Ω gi√∫p b·∫°n v·ªõi y√™u c·∫ßu: '{query}'. T√¥i s·∫Ω b·∫Øt ƒë·∫ßu v·ªõi Filesystem Agent ƒë·ªÉ t√¨m ki·∫øm th√¥ng tin."
        
        # Update state with the plan
        state["current_agents"] = needed_agents
        state["messages"].append(AIMessage(content=plan_message))
        
        return state
        
    async def run(self, query: str, session_id: str = None, user_role: str = "user") -> Dict[str, Any]:
        """
        Run the multi-agent system with the given query.
        
        Args:
            query: C√¢u truy v·∫•n c·ªßa ng∆∞·ªùi d√πng
            session_id: ID phi√™n l√†m vi·ªác, ƒë∆∞·ª£c t·∫°o t·ª± ƒë·ªông n·∫øu kh√¥ng cung c·∫•p
            user_role: Vai tr√≤ c·ªßa ng∆∞·ªùi d√πng, m·∫∑c ƒë·ªãnh l√† "user"
        
        Returns:
            Dict ch·ª©a k·∫øt qu·∫£ v√† tr·∫°ng th√°i c·ªßa h·ªá th·ªëng
        """
        try:
            # Set session ID
            self.session_id = session_id or str(uuid.uuid4())
            
            # Initialize state
            state = {
                "messages": [HumanMessage(content=query)],
                "current_agents": [],
                "task_complete": False,
                "require_user_input": False,
                "success_criteria_met": False,
                "completed": False,
                "used_tools": [],
                "chain_of_thought": ["1. B·∫Øt ƒë·∫ßu x·ª≠ l√Ω y√™u c·∫ßu: " + query],
                "user_role": user_role  # Th√™m vai tr√≤ ng∆∞·ªùi d√πng v√†o state
            }
            
            # Plan which agents to use
            state = await self.plan_agents(state)
            log(f"K·∫ø ho·∫°ch agent ban ƒë·∫ßu: {state['current_agents']}")
            
            # Validate and fix agent sequence if needed
            state = await self._validate_agent_sequence(state)
            log(f"K·∫ø ho·∫°ch agent sau khi ki·ªÉm tra: {state['current_agents']}")
            state["chain_of_thought"].append(f"2. L·∫≠p k·∫ø ho·∫°ch s·ª≠ d·ª•ng c√°c agent: {', '.join(state['current_agents'])}")
            
            # Run the agents in the planned order
            step_count = 3
            agent_execution_order = []
            
            while not state.get("completed", False) and state["current_agents"]:
                agent_name = state["current_agents"].pop(0)
                agent_execution_order.append(agent_name)
                log(f"Running agent: {agent_name} (Th·ª© t·ª± th·ª±c thi: {agent_execution_order})")
                state["chain_of_thought"].append(f"{step_count}. ƒêang ch·∫°y agent: {agent_name}")
                
                # Add execution order to state for later analysis
                if "agent_execution_order" not in state:
                    state["agent_execution_order"] = []
                state["agent_execution_order"].append(agent_name)
                
                # L∆∞u tr·∫°ng th√°i tr∆∞·ªõc khi ch·∫°y agent
                pre_run_messages_count = len(state["messages"])
                
                # Run the agent
                if agent_name == "filesystem":
                    state = await self.run_filesystem_agent(state)
                elif agent_name == "text_extraction":
                    state = await self.run_text_extraction_agent(state)
                elif agent_name == "file_classification":
                    state = await self.run_file_classification_agent(state)
                elif agent_name == "metadata":
                    state = await self.run_metadata_agent(state)
                elif agent_name == "rag":
                    state = await self.run_rag_agent(state)
                else:
                    log(f"Unknown agent: {agent_name}")
                
                # L·∫•y k·∫øt qu·∫£ m·ªõi nh·∫•t t·ª´ agent
                if len(state["messages"]) > pre_run_messages_count:
                    latest_message = state["messages"][-1].content
                    # R√∫t g·ªçn n·ªôi dung ƒë·ªÉ hi·ªÉn th·ªã trong chain of thought
                    if len(latest_message) > 200:
                        summary = latest_message[:197] + "..."
                    else:
                        summary = latest_message
                    state["chain_of_thought"].append(f"{step_count}a. K·∫øt qu·∫£ t·ª´ {agent_name}: {summary}")
                
                step_count += 1
            
            # Mark as completed
            state["completed"] = True
            state["chain_of_thought"].append(f"{step_count}. Ho√†n th√†nh x·ª≠ l√Ω")
            
            # Generate execution summary
            agent_summary = ""
            if "agent_execution_order" in state:
                agent_summary = f"Th·ª© t·ª± th·ª±c thi c√°c agent: {', '.join(state['agent_execution_order'])}"
                log(f"Agent execution summary: {agent_summary}")
                state["chain_of_thought"].append(f"T√≥m t·∫Øt th·ª±c thi: {agent_summary}")
            
            # Add used tools to the summary
            log(f"Used tools: {state.get('used_tools', [])}")
            
            # Return the final state with execution summary
            return {
                "response_type": "data",
                "is_task_complete": True,
                "require_user_input": False,
                "content": state["messages"][-1].content if state["messages"] else "",
                "state": state,
                "chain_of_thought": state["chain_of_thought"],
                "agent_execution_order": state.get("agent_execution_order", []),
                "used_tools": state.get("used_tools", [])
            }
        except Exception as e:
            log(f"Error running multi-agent system: {e}", level='error')
            return {
                "response_type": "error",
                "content": f"Xin l·ªói, ƒë√£ x·∫£y ra l·ªói: {str(e)}",
                "is_task_complete": False,
                "require_user_input": False,
                "chain_of_thought": [f"L·ªói: {str(e)}"]
            }
             
    async def stream(self, query: str, session_id: str = "default", user_role: str = "user") -> AsyncGenerator[Dict[str, Any], None]:
        """
        Stream the multi-agent system's response.
        
        Args:
            query: The user's query
            session_id: Session ID for memory management
            user_role: Vai tr√≤ c·ªßa ng∆∞·ªùi d√πng, m·∫∑c ƒë·ªãnh l√† "user"
            
        Yields:
            Dict with partial response content and metadata
        """
        try:
            # Initialize the agent if not already initialized
            if not self.graph:
                await self.initialize()
                
            # Set the session ID for this run
            self.session_id = session_id
            
            # Create the initial state
            initial_state = {
                "messages": [HumanMessage(content=query)],
                "current_agents": [],
                "task_complete": False,
                "require_user_input": False,
                "feedback_on_work": None,
                "success_criteria_met": False,
                "used_tools": [],
                "user_role": user_role  # Th√™m vai tr√≤ ng∆∞·ªùi d√πng v√†o state
            }
            
            # Stream the graph execution
            config = {"configurable": {"thread_id": session_id}}
            async for chunk in self.graph.astream(initial_state, config=config):
                # Extract the latest message
                if "messages" in chunk and chunk["messages"]:
                    # Find the latest non-evaluator message
                    latest_message = None
                    for message in reversed(chunk["messages"]):
                        if isinstance(message, AIMessage) and not message.content.startswith("[ƒê√°nh gi√° n·ªôi b·ªô:"):
                            latest_message = message
                            break
                    
                    if latest_message:
                        # Yield the partial response
                        yield {
                            "response_type": "text",
                            "content": latest_message.content,
                            "is_task_complete": chunk.get("success_criteria_met", False),
                            "require_user_input": chunk.get("require_user_input", False),
                            "is_partial": True,
                            "used_tools": chunk.get("used_tools", [])
                        }
            
            # Yield the final complete response
            final_state = await self.graph.ainvoke(initial_state, config=config)
            
            # Find the last non-evaluator message
            final_message = None
            for message in reversed(final_state["messages"]):
                if isinstance(message, AIMessage) and not message.content.startswith("[ƒê√°nh gi√° n·ªôi b·ªô:"):
                    final_message = message
                    break
            
            if not final_message:
                final_message = final_state["messages"][-1] if final_state["messages"] else AIMessage(content="Kh√¥ng c√≥ ph·∫£n h·ªìi t·ª´ h·ªá th·ªëng.")
            
            yield {
                "response_type": "text",
                "content": final_message.content,
                "is_task_complete": final_state.get("success_criteria_met", False),
                "require_user_input": final_state.get("require_user_input", False),
                "is_partial": False,
                "used_tools": final_state.get("used_tools", [])
            }
            
        except Exception as e:
            print(f"Error streaming multi-agent system: {e}")
            yield {
                "response_type": "error",
                "content": f"Xin l·ªói, ƒë√£ x·∫£y ra l·ªói: {str(e)}",
                "is_task_complete": False,
                "require_user_input": False,
                "is_partial": False
            }

# Business domain-specific agents (placeholders for future implementation)
class BusinessAnalysisAgent:
    """Agent specialized in business analysis tasks."""
    pass

class FinanceAgent:
    """Agent specialized in finance and accounting tasks."""
    pass

class HRAgent:
    """Agent specialized in HR and personnel management tasks."""
    pass


async def main():
    """
    Test the enhanced worker-evaluator multi-agent system.
    """
    try:
        # Initialize the multi-agent system
        multi_agent = await MultiAgentSystem().initialize()
        session_id = "test_session_123"
        
        # Test v·ªõi c√¢u truy v·∫•n ƒë∆°n gi·∫£n v√† vai tr√≤ ng∆∞·ªùi d√πng
        query1 = "T√¨m file c√≥ t√™n li√™n quan ƒë·∫øn project-final sau ƒë√≥ tr√≠ch xu·∫•t n·ªôi dung"
        print(f"\nTest Query 1: {query1}")
        print("Running with worker-evaluator pattern...")
        
        # Th·ª≠ nghi·ªám v·ªõi c√°c vai tr√≤ kh√°c nhau
        user_roles = ["user", "admin", "manager"]
        
        for role in user_roles:
            print(f"\nTesting with user role: {role}")
            result1 = await multi_agent.run(query1, session_id=f"{session_id}_{role}", user_role=role)
            print(f"Response for {role}: {result1.get('content', 'No content')}")
            print(f"Used tools: {result1.get('used_tools', [])}")
        
        
        
        print("\nMulti-agent tests completed successfully!")
        
    except Exception as e:
        print(f"Error in main: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(main())