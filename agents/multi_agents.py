import os
import sys
import asyncio
import re
from typing import Dict, List, Any, Optional, Annotated, Tuple, Union

from typing import Dict, Any, List, AsyncIterable, TypedDict, Annotated, Optional
from langchain_mcp_adapters.client import MultiServerMCPClient
from typing_extensions import AsyncGenerator
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from utils.logger import log

from langchain_core.messages import AIMessage, HumanMessage, SystemMessage
from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langchain_mcp_adapters.client import MultiServerMCPClient
from pydantic import BaseModel, Field

from config.llm import gemini
from agents.filesystem_agent import FilesystemAgent
from agents.metadata_agent import MetadataAgent
from agents.text_extraction_agent import TextExtractionAgent
from agents.file_classification_agent import FileClassificationAgent
from agents.rag_agent import RAGAgent
from agents.human_feedback_agent import HumanFeedbackAgent
from agents.data_analysis_agent import DataAnalysisAgent

# Global MemorySaver instance shared by all agents
memory = MemorySaver()

# Setup MCP client for filesystem access
mcp_client = MultiServerMCPClient({
    "document_search": {
        "command": "cmd",
        "args": [
            "/c",
            "npx",
            "-y",
            "@modelcontextprotocol/server-filesystem",
            "C:\\Users\\dhuu3\\Desktop\\local-classify-docs-ai-agent\\data",
            # C:\Users\dhuu3\Desktop\local-classify-docs-ai-agent\data

        ],
        "transport": "stdio",
    }
})

# Define the state for our multi-agent system
class AgentState(TypedDict):
    messages: Annotated[List[Any], add_messages]  # Messages in the conversation
    current_agents: List[str]  # Which agents are currently active or have been used
    task_complete: bool  # Whether the task is complete
    require_user_input: bool  # Whether user input is needed
    feedback_on_work: Optional[str]  # Feedback from evaluator
    success_criteria_met: bool  # Whether success criteria have been met
    used_tools: List[str]  # Tools that have been used
    chain_of_thought: List[str]  # Detailed execution steps
    agent_results: Dict[str, str]  # Results from each agent
    original_query: str  # Original user query for reflection
    extracted_contents: Dict[str, str]  # file_path -> content
    analysis_metrics: List[str]  # metrics to analyze
    analysis_results: Dict[str, Any]  # results from data analysis

class ReflectionAgent:
    """
    Agent chuy√™n v·ªÅ reflection - t·ªïng h·ª£p v√† tr·∫£ l·ªùi cu·ªëi c√πng cho ng∆∞·ªùi d√πng
    d·ª±a tr√™n k·∫øt qu·∫£ t·ª´ c√°c agent kh√°c v√† query ban ƒë·∫ßu.
    """
    
    def __init__(self):
        """Initialize the ReflectionAgent."""
        self.model = gemini
    
    async def reflect_and_respond(self, state: AgentState) -> str:
        """
        Ph√¢n t√≠ch k·∫øt qu·∫£ t·ª´ c√°c agent v√† t·∫°o c√¢u tr·∫£ l·ªùi cu·ªëi c√πng c√≥ ng·ªØ nghƒ©a t·ªët.
        
        Args:
            state: Tr·∫°ng th√°i hi·ªán t·∫°i c·ªßa h·ªá th·ªëng
            
        Returns:
            C√¢u tr·∫£ l·ªùi cu·ªëi c√πng ƒë∆∞·ª£c t·ªëi ∆∞u h√≥a cho ng∆∞·ªùi d√πng
        """
        try:
            # Import c√°c module c·∫ßn thi·∫øt
            import re
            import os
        
            # Check if this was a data analysis query FIRST
            used_tools = state.get("used_tools", [])
            analysis_results = state.get("analysis_results", {})
            
            if "data_analysis" in used_tools and analysis_results:
                # Create specialized reflection for data analysis
                original_query = state.get("original_query", "")
                extracted_contents = state.get("extracted_contents", {})
                
                reflection_prompt = f"""
                B·∫°n l√† m·ªôt AI assistant chuy√™n v·ªÅ t·ªïng h·ª£p k·∫øt qu·∫£ ph√¢n t√≠ch d·ªØ li·ªáu t√†i ch√≠nh.
                
                Y√äU C·∫¶U BAN ƒê·∫¶U C·ª¶A NG∆Ø·ªúI D√ôNG:
                "{original_query}"
                
                K·∫æT QU·∫¢ PH√ÇN T√çCH D·ªÆ LI·ªÜU:
                {analysis_results.get('report', 'Kh√¥ng c√≥ b√°o c√°o ph√¢n t√≠ch')}
                
                C√ÅC C√îNG C·ª§ ƒê√É S·ª¨ D·ª§NG:
                {', '.join(used_tools)}
                
                S·ªê L∆Ø·ª¢NG FILE ƒê∆Ø·ª¢C PH√ÇN T√çCH:
                {len(extracted_contents)} files
                
                Y√äU C·∫¶U:
                H√£y t·∫°o m·ªôt c√¢u tr·∫£ l·ªùi ng·∫Øn g·ªçn, t·ª± nhi√™n v√† h·ªØu √≠ch t√≥m t·∫Øt k·∫øt qu·∫£ so s√°nh d·ªØ li·ªáu t√†i ch√≠nh.
                
                H∆Ø·ªöNG D·∫™N TR·∫¢ L·ªúI:
                1. X√°c nh·∫≠n ƒë√£ so s√°nh d·ªØ li·ªáu t·ª´ c√°c file th√†nh c√¥ng
                2. T√≥m t·∫Øt c√°c xu h∆∞·ªõng ch√≠nh (tƒÉng/gi·∫£m)
                3. ƒê∆∞a ra nh·∫≠n x√©t v·ªÅ hi·ªáu su·∫•t kinh doanh
                4. S·ª≠ d·ª•ng ng√¥n ng·ªØ d·ªÖ hi·ªÉu, tr√°nh thu·∫≠t ng·ªØ ph·ª©c t·∫°p
                
                L∆ØU √ù QUAN TR·ªåNG:
                - T·∫≠p trung v√†o nh·ªØng th√¥ng tin quan tr·ªçng nh·∫•t
                - S·ª≠ d·ª•ng ng√¥n ng·ªØ t·ª± nhi√™n, g·∫ßn g≈©i
                - Gi·ªõi h·∫°n trong 3-4 c√¢u
                - ƒê·∫£m b·∫£o c√¢u tr·∫£ l·ªùi c√≥ gi√° tr·ªã v√† actionable
                
                C√ÇU TR·∫¢ L·ªúI (ch·ªâ tr·∫£ v·ªÅ c√¢u tr·∫£ l·ªùi, kh√¥ng c√≥ ph·∫ßn gi·∫£i th√≠ch):
                """
                
                response = await self.model.ainvoke(reflection_prompt)
                return "üí∞ " + response.content.strip()
            
            # Ki·ªÉm tra n·∫øu qu√° tr√¨nh x·ª≠ l√Ω ƒë√£ b·ªã d·ª´ng (v√≠ d·ª•: do quy·ªÅn truy c·∫≠p b·ªã t·ª´ ch·ªëi)
            if state.get("stop_processing", False):
                log(f"ReflectionAgent detected stop_processing flag with reason: {state.get('stop_reason', 'unknown')}", level='warning')
                
                # X·ª≠ l√Ω tr∆∞·ªùng h·ª£p quy·ªÅn truy c·∫≠p b·ªã t·ª´ ch·ªëi
                if state.get("stop_reason") == "access_denied":
                    # T·∫°o prompt ƒë·∫∑c bi·ªát cho tr∆∞·ªùng h·ª£p quy·ªÅn truy c·∫≠p b·ªã t·ª´ ch·ªëi
                    access_denied_prompt = f"""
                    B·∫°n l√† m·ªôt AI assistant chuy√™n v·ªÅ t·ªïng h·ª£p k·∫øt qu·∫£ v√† tr·∫£ l·ªùi ng∆∞·ªùi d√πng m·ªôt c√°ch t·ª± nhi√™n, th√¢n thi·ªán.
                    
                    Y√äU C·∫¶U BAN ƒê·∫¶U C·ª¶A NG∆Ø·ªúI D√ôNG:
                    "{state.get('original_query', '')}"  
                    
                    T√åNH HU·ªêNG:
                    ƒê√£ t√¨m th·∫•y c√°c file ph√π h·ª£p v·ªõi y√™u c·∫ßu, nh∆∞ng ng∆∞·ªùi d√πng kh√¥ng c√≥ quy·ªÅn truy c·∫≠p v√†o c√°c file n√†y.
                    
                    Y√äU C·∫¶U:
                    H√£y t·∫°o m·ªôt c√¢u tr·∫£ l·ªùi ng·∫Øn g·ªçn, t·ª± nhi√™n v√† h·ªØu √≠ch th√¥ng b√°o cho ng∆∞·ªùi d√πng r·∫±ng:
                    1. ƒê√£ t√¨m th·∫•y file ph√π h·ª£p v·ªõi y√™u c·∫ßu c·ªßa h·ªç
                    2. Tuy nhi√™n, h·ªç kh√¥ng c√≥ quy·ªÅn truy c·∫≠p v√†o c√°c file n√†y
                    3. H·ªç c·∫ßn c√≥ quy·ªÅn truy c·∫≠p ph√π h·ª£p ƒë·ªÉ xem n·ªôi dung
                    
                    L∆ØU √ù QUAN TR·ªåNG:
                    - S·ª≠ d·ª•ng ng√¥n ng·ªØ t·ª± nhi√™n, g·∫ßn g≈©i
                    - Gi·ªõi h·∫°n trong 2-3 c√¢u
                    - Kh√¥ng c·∫ßn gi·∫£i th√≠ch th√™m sau c√¢u tr·∫£ l·ªùi
                    - KH√îNG ƒë·ªÅ c·∫≠p ƒë·∫øn vi·ªác ph√¢n lo·∫°i file ho·∫∑c l∆∞u metadata v√¨ qu√° tr√¨nh ƒë√£ d·ª´ng l·∫°i
                    
                    C√ÇU TR·∫¢ L·ªúI (ch·ªâ tr·∫£ v·ªÅ c√¢u tr·∫£ l·ªùi, kh√¥ng c√≥ ph·∫ßn gi·∫£i th√≠ch):
                    """
                    
                    # G·ªçi LLM ƒë·ªÉ t·∫°o ph·∫£n h·ªìi cho tr∆∞·ªùng h·ª£p quy·ªÅn truy c·∫≠p b·ªã t·ª´ ch·ªëi
                    response = await self.model.ainvoke(access_denied_prompt)
                    return "üí≠ " + response.content.strip()
                else:
                    # X·ª≠ l√Ω c√°c tr∆∞·ªùng h·ª£p d·ª´ng kh√°c
                    error_prompt = f"""
                    B·∫°n l√† m·ªôt AI assistant chuy√™n v·ªÅ t·ªïng h·ª£p k·∫øt qu·∫£ v√† tr·∫£ l·ªùi ng∆∞·ªùi d√πng m·ªôt c√°ch t·ª± nhi√™n, th√¢n thi·ªán.
                    
                    Y√äU C·∫¶U BAN ƒê·∫¶U C·ª¶A NG∆Ø·ªúI D√ôNG:
                    "{state.get('original_query', '')}"  
                    
                    T√åNH HU·ªêNG:
                    ƒê√£ x·∫£y ra l·ªói trong qu√° tr√¨nh x·ª≠ l√Ω: {state.get('stop_reason', 'L·ªói kh√¥ng x√°c ƒë·ªãnh')}
                    
                    Y√äU C·∫¶U:
                    H√£y t·∫°o m·ªôt c√¢u tr·∫£ l·ªùi ng·∫Øn g·ªçn, t·ª± nhi√™n v√† h·ªØu √≠ch th√¥ng b√°o cho ng∆∞·ªùi d√πng v·ªÅ l·ªói ƒë√£ x·∫£y ra.
                    
                    L∆ØU √ù QUAN TR·ªåNG:
                    - S·ª≠ d·ª•ng ng√¥n ng·ªØ t·ª± nhi√™n, g·∫ßn g≈©i
                    - Gi·ªõi h·∫°n trong 2-3 c√¢u
                    - Kh√¥ng c·∫ßn gi·∫£i th√≠ch th√™m sau c√¢u tr·∫£ l·ªùi
                    
                    C√ÇU TR·∫¢ L·ªúI (ch·ªâ tr·∫£ v·ªÅ c√¢u tr·∫£ l·ªùi, kh√¥ng c√≥ ph·∫ßn gi·∫£i th√≠ch):
                    """
                    
                    # G·ªçi LLM ƒë·ªÉ t·∫°o ph·∫£n h·ªìi cho tr∆∞·ªùng h·ª£p l·ªói kh√°c
                    response = await self.model.ainvoke(error_prompt)
                    return "üí≠ " + response.content.strip()
            # L·∫•y query ban ƒë·∫ßu
            original_query = state.get("original_query", "")
            if not original_query:
                # Fallback: t√¨m trong messages
                for message in state["messages"]:
                    if isinstance(message, HumanMessage):
                        original_query = message.content
                        break
            
            # Thu th·∫≠p k·∫øt qu·∫£ t·ª´ c√°c agent
            agent_results = state.get("agent_results", {})
            used_tools = state.get("used_tools", [])
            chain_of_thought = state.get("chain_of_thought", [])
            
            # T·∫°o t√≥m t·∫Øt c√°c k·∫øt qu·∫£ quan tr·ªçng
            key_findings = []
            file_found = None
            extraction_result = None
            classification_result = None
            metadata_ids = []
            
            # Thu th·∫≠p th√¥ng tin chi ti·∫øt v·ªÅ file
            # ƒê·∫£m b·∫£o kh·ªüi t·∫°o l·∫°i detailed_files m·ªói l·∫ßn g·ªçi
            detailed_files = []
            classification_labels = state.get("classification_labels", {})
            
            # X√≥a file_count c≈© trong state n·∫øu c√≥
            if "file_count" in state:
                del state["file_count"]
            
            # Ph√¢n t√≠ch k·∫øt qu·∫£ t·ª´ t·ª´ng agent
            for message in state["messages"]:
                if not isinstance(message, AIMessage):
                    continue
                    
                content = message.content
                
                # K·∫øt qu·∫£ t·ª´ RAG/Filesystem agent - t√¨m file
                # Ki·ªÉm tra nhi·ªÅu ƒë·ªãnh d·∫°ng th√¥ng b√°o t√¨m th·∫•y file
                file_found_indicators = [
                    "T√¥i ƒë√£ t√¨m th·∫•y file:", 
                    "T√¨m th·∫•y c√°c file sau:", 
                    "ƒê√£ t√¨m th·∫•y c√°c file:",
                    "T√¨m th·∫•y nhi·ªÅu file:",
                    "files found:",
                    "found files:",
                    "k·∫øt qu·∫£ t√¨m ki·∫øm:",
                    "search results:",
                    "plan-"  # Th√™m d·∫•u hi·ªáu t√¨m ki·∫øm file c√≥ ch·ª©a "plan"
                ]
                
                # Ki·ªÉm tra n·∫øu c√≥ b·∫•t k·ª≥ indicator n√†o trong n·ªôi dung
                has_file_indicator = any(indicator.lower() in content.lower() for indicator in file_found_indicators)
                
                # T√¨m t·∫•t c·∫£ c√°c ƒë∆∞·ªùng d·∫´n file trong n·ªôi dung
                file_pattern = r'[A-Z]:\\[^\\/:*?"<>|\r\n]+(?:\\[^\\/:*?"<>|\r\n]+)*\\?'
                file_matches = re.findall(file_pattern, content)
                
                # L·ªçc ra c√°c ƒë∆∞·ªùng d·∫´n h·ª£p l·ªá
                files_found = [match.strip() for match in file_matches if os.path.exists(match.strip())]
                
                # N·∫øu t√¨m th·∫•y file nh∆∞ng ch∆∞a c√≥ trong files_found, th·ª≠ c√°ch kh√°c
                if has_file_indicator and not files_found:
                    # Th·ª≠ t√¨m theo ƒë·ªãnh d·∫°ng danh s√°ch ƒë√°nh s·ªë ho·∫∑c g·∫°ch ƒë·∫ßu d√≤ng
                    list_pattern = r'(?:\d+\.\s*|-\s*|\*\s*)([^\n\r]+)'
                    list_matches = re.findall(list_pattern, content)
                    if list_matches:
                        # L·ªçc ra c√°c m·ª•c c√≥ v·∫ª gi·ªëng ƒë∆∞·ªùng d·∫´n file
                        potential_paths = [match.strip() for match in list_matches]
                        files_found = [path for path in potential_paths if os.path.exists(path)]
                
                # N·∫øu v·∫´n ch∆∞a t√¨m th·∫•y, th·ª≠ t√¨m b·∫•t k·ª≥ chu·ªói n√†o gi·ªëng ƒë∆∞·ªùng d·∫´n
                if not files_found and has_file_indicator:
                    # T√¨m c√°c chu·ªói c√≥ ch·ª©a d·∫•u ch·∫•m (ƒëu√¥i file) v√† d·∫•u g·∫°ch ch√©o
                    potential_paths = re.findall(r'[\w\\:]+\.[\w.]+', content)
                    files_found = [path for path in potential_paths if os.path.exists(path)]
                
                # N·∫øu t√¨m th·∫•y file, x·ª≠ l√Ω k·∫øt qu·∫£
                if files_found:
                    # L·∫•y danh s√°ch file t·ª´ state n·∫øu c√≥ (ƒë√¢y l√† danh s√°ch ch√≠nh x√°c t·ª´ RAG agent)
                    # H√†m helper ƒë·ªÉ ki·ªÉm tra v√† x·ª≠ l√Ω k·∫øt qu·∫£ t·ª´ agent m·ªôt c√°ch an to√†n
                    def safe_get_agent_result(agent_name):
                        if "agent_results" not in state or agent_name not in state["agent_results"]:
                            return {}
                        
                        agent_result = state["agent_results"][agent_name]
                        if isinstance(agent_result, dict):
                            return agent_result
                        elif isinstance(agent_result, str):
                            try:
                                # Th·ª≠ parse JSON n·∫øu l√† string
                                if '{' in agent_result and '}' in agent_result:
                                    import json
                                    parsed_result = json.loads(agent_result)
                                    log(f"ReflectionAgent debug - Parsed {agent_name} result: {parsed_result}")
                                    return parsed_result
                            except Exception as e:
                                log(f"ReflectionAgent debug - Failed to parse {agent_name} result: {str(e)}")
                        
                        # Tr·∫£ v·ªÅ dict r·ªóng n·∫øu kh√¥ng ph·∫£i dict v√† kh√¥ng th·ªÉ parse
                        log(f"ReflectionAgent debug - {agent_name} result is not a dict: {agent_result}")
                        return {}
                    
                    # Log state keys for debugging
                    log(f"ReflectionAgent debug - State keys: {list(state.keys())}")
                    if "agent_results" in state:
                        log(f"ReflectionAgent debug - Agent results keys: {list(state['agent_results'].keys())}")
                        
                        # X·ª≠ l√Ω an to√†n cho t·∫•t c·∫£ c√°c agent results
                        rag_result = safe_get_agent_result("rag")
                        text_extraction_result = safe_get_agent_result("text_extraction")
                        file_classification_result = safe_get_agent_result("file_classification")
                        metadata_result = safe_get_agent_result("metadata")
                    
                    state_file_paths = []
                    
                    # Th·ª≠ l·∫•y t·ª´ agent_results.rag.file_paths
                    if isinstance(rag_result, dict) and "file_paths" in rag_result:
                        state_file_paths = rag_result["file_paths"]
                        log(f"ReflectionAgent debug - Found file_paths in rag_result: {state_file_paths}")
                    # Th·ª≠ l·∫•y tr·ª±c ti·∫øp t·ª´ state
                    elif "file_paths" in state:
                        state_file_paths = state["file_paths"]
                        log(f"ReflectionAgent debug - Found file_paths in state: {state_file_paths}")
                    # Th·ª≠ l·∫•y t·ª´ processed_files
                    elif "processed_files" in state:
                        state_file_paths = state["processed_files"]
                        log(f"ReflectionAgent debug - Found processed_files in state: {state_file_paths}")
                    
                    # S·ª≠ d·ª•ng danh s√°ch file t·ª´ state n·∫øu c√≥, n·∫øu kh√¥ng th√¨ d√πng files_found
                    actual_files = state_file_paths if state_file_paths else files_found
                    
                    # ƒê·∫£m b·∫£o actual_files l√† list v√† ch·ªâ ch·ª©a c√°c ƒë∆∞·ªùng d·∫´n duy nh·∫•t
                    unique_files = set()
                    
                    if isinstance(actual_files, str):
                        # N·∫øu actual_files l√† string, c√≥ th·ªÉ l√† m·ªôt file duy nh·∫•t ho·∫∑c m√¥ t·∫£
                        unique_files.add(actual_files)
                    else:
                        # Th√™m t·∫•t c·∫£ c√°c file v√†o set ƒë·ªÉ lo·∫°i b·ªè tr√πng l·∫∑p
                        for file_path in actual_files:
                            if file_path and isinstance(file_path, str):
                                unique_files.add(file_path)
                    
                    # S·ªë l∆∞·ª£ng file ch√≠nh x√°c l√† s·ªë l∆∞·ª£ng ph·∫ßn t·ª≠ duy nh·∫•t
                    file_count = len(unique_files)
                    
                    # L∆∞u file_count v√†o state ƒë·ªÉ c√°c ph·∫ßn kh√°c c·ªßa code c√≥ th·ªÉ truy c·∫≠p
                    state["file_count"] = file_count
                    state["unique_files"] = list(unique_files)
                    
                    log(f"ReflectionAgent debug - Actual file count: {file_count}, unique_files: {list(unique_files)}")
                    
                    # Thu th·∫≠p th√¥ng tin chi ti·∫øt v·ªÅ t·ª´ng file
                    # S·ª≠ d·ª•ng unique_files ƒë√£ ƒë∆∞·ª£c t·∫°o tr∆∞·ªõc ƒë√≥
                    unique_file_list = state.get("unique_files", [])
                    
                    # X·ª≠ l√Ω t·ª´ng file duy nh·∫•t
                    for file_path in unique_file_list:
                        file_name = os.path.basename(file_path)
                        file_info = {
                            "file_path": file_path,
                            "file_name": file_name,
                            "label": classification_labels.get(file_name, ""),
                            "metadata_id": ""
                        }
                        detailed_files.append(file_info)
                    
                    # T·∫°o t√™n hi·ªÉn th·ªã ng·∫Øn g·ªçn cho danh s√°ch file
                    if file_count == 1:
                        if isinstance(actual_files, str):
                            file_name = os.path.basename(actual_files)
                            file_names = [file_name]
                        else:
                            file_names = [os.path.basename(actual_files[0])]
                        file_found = f"1 file: {file_names[0]}"
                    elif file_count <= 3 and not isinstance(actual_files, str):
                        file_names = [os.path.basename(f) for f in actual_files]
                        file_found = f"{file_count} files: {', '.join(file_names)}"
                    elif not isinstance(actual_files, str):
                        file_names = [os.path.basename(f) for f in actual_files[:2]]
                        file_found = f"{file_count} files: {', '.join(file_names)} v√† {file_count - 2} file kh√°c"
                    
                    # Th√™m th√¥ng tin v·ªÅ s·ªë l∆∞·ª£ng file v√†o key_findings
                    if file_count == 1:
                        key_findings.append(f"ƒê√£ t√¨m th·∫•y 1 file")
                    else:
                        key_findings.append(f"ƒê√£ t√¨m th·∫•y {file_count} files")
                    
                    # Log th√¥ng tin v·ªÅ file
                    if isinstance(actual_files, str):
                        log(f"ReflectionAgent: ƒê√£ t√¨m th·∫•y 1 file: {os.path.basename(actual_files)}")
                    else:
                        file_names = [os.path.basename(f) for f in actual_files[:3]]
                        log(f"ReflectionAgent: ƒê√£ t√¨m th·∫•y {file_count} files: {', '.join(file_names)}...")
                
                # K·∫øt qu·∫£ t·ª´ Text Extraction agent
                elif "üìù" in content and ("K·∫øt qu·∫£ tr√≠ch xu·∫•t t·ª´ file" in content or "K·∫øt qu·∫£ tr√≠ch xu·∫•t t·ª´ c√°c file" in content):
                    # Ki·ªÉm tra xem c√≥ ph·∫£i l√† tr√≠ch xu·∫•t nhi·ªÅu file kh√¥ng
                    is_multi_extraction = "K·∫øt qu·∫£ tr√≠ch xu·∫•t t·ª´ c√°c file" in content or "tr√≠ch xu·∫•t nhi·ªÅu file" in content.lower()
                    
                    # L·∫•y n·ªôi dung tr√≠ch xu·∫•t t·ª´ text_extraction_results trong state n·∫øu c√≥
                    extracted_content = ""
                    if "agent_results" in state and "text_extraction" in state["agent_results"]:
                        extracted_content = state["agent_results"]["text_extraction"]
                        log(f"Found extracted content in agent_results: {len(extracted_content)} characters")
                    
                    # N·∫øu kh√¥ng c√≥ trong agent_results, th·ª≠ tr√≠ch xu·∫•t t·ª´ n·ªôi dung message
                    if not extracted_content:
                        # T√°ch n·ªôi dung sau header
                        parts = content.split(":\n\n", 1)
                        if len(parts) > 1:
                            extracted_content = parts[1].strip()
                            log(f"Extracted content from message: {len(extracted_content)} characters")
                    
                    # N·∫øu v·∫´n kh√¥ng c√≥, th·ª≠ c√°ch kh√°c
                    if not extracted_content:
                        content_lines = content.split('\n')
                        extract_lines = []
                        found_header = False
                        
                        for line in content_lines:
                            if not found_header and ("K·∫øt qu·∫£ tr√≠ch xu·∫•t t·ª´ file" in line or "File:" in line):
                                found_header = True
                                continue
                            if found_header and line.strip():
                                extract_lines.append(line.strip())
                        
                        if extract_lines:
                            extracted_content = "\n".join(extract_lines)
                            log(f"Extracted content line by line: {len(extracted_content)} characters")
                    
                    # T·∫°o preview cho extraction_result
                    if extracted_content:
                        # L·∫•y t·ªëi ƒëa 500 k√Ω t·ª± ƒë·∫ßu ti√™n cho preview
                        preview_length = min(500, len(extracted_content))
                        extraction_result = extracted_content[:preview_length]
                        if len(extracted_content) > preview_length:
                            extraction_result += "..."
                    else:
                        # Fallback: L·∫•y 3 d√≤ng ƒë·∫ßu ti√™n sau header
                        content_lines = content.split('\n')
                        preview_lines = []
                        found_content = False
                        file_count = 0
                        
                        for line in content_lines:
                            if "K·∫øt qu·∫£ tr√≠ch xu·∫•t t·ª´ file" in line or "File:" in line:
                                file_count += 1
                                found_content = True
                            elif found_content and line.strip() and not line.startswith("File:"):
                                preview_lines.append(line.strip())
                                if len(preview_lines) >= 3:  # L·∫•y 3 d√≤ng ƒë·∫ßu
                                    break
                        
                        if preview_lines:
                            extraction_result = " ".join(preview_lines)[:100] + "..."
                    
                    # ƒê·∫øm s·ªë file ƒë√£ x·ª≠ l√Ω
                    if "accessible_files" in state:
                        file_count = len(state["accessible_files"])
                    elif "file_count" in state:
                        file_count = state["file_count"]
                    
                    # Th√™m k·∫øt qu·∫£ v√†o key_findings
                    if is_multi_extraction or file_count > 1:
                        key_findings.append(f"ƒê√£ tr√≠ch xu·∫•t n·ªôi dung t·ª´ {file_count} files")
                    else:
                        key_findings.append(f"ƒê√£ tr√≠ch xu·∫•t n·ªôi dung t·ª´ file")
                        
                    # L∆∞u n·ªôi dung tr√≠ch xu·∫•t v√†o state ƒë·ªÉ s·ª≠ d·ª•ng trong reflection
                    state["extracted_content_preview"] = extraction_result
                
                # K·∫øt qu·∫£ t·ª´ File Classification agent
                elif "üè∑Ô∏è" in content and "K·∫øt qu·∫£ ph√¢n lo·∫°i file" in content:
                    # Ki·ªÉm tra xem c√≥ ph·∫£i l√† ph√¢n lo·∫°i nhi·ªÅu file kh√¥ng
                    is_multi_classification = "nhi·ªÅu file" in content.lower() or "c√°c file" in content.lower()
                    
                    # Tr√≠ch xu·∫•t s·ªë l∆∞·ª£ng file t·ª´ n·ªôi dung
                    file_count_pattern = r'(\d+)\s+files?'
                    file_count_matches = re.findall(file_count_pattern, content)
                    file_count = int(file_count_matches[0]) if file_count_matches else 1
                    
                    # Thu th·∫≠p th√¥ng tin ph√¢n lo·∫°i chi ti·∫øt
                    file_classifications = {}
                    lines = content.split('\n')
                    
                    # T√¨m c√°c d√≤ng ch·ª©a th√¥ng tin ph√¢n lo·∫°i
                    for line in lines:
                        # Ki·ªÉm tra c√°c m·∫´u ph·ªï bi·∫øn
                        if "File:" in line or "file:" in line:
                            # M·∫´u 1: File: t√™n_file - ph√¢n_lo·∫°i
                            if "-" in line:
                                parts = line.split("-", 1)
                                file_part = parts[0]
                                class_part = parts[1].strip()
                                
                                # Tr√≠ch xu·∫•t t√™n file
                                if "File:" in file_part or "file:" in file_part:
                                    file_name = file_part.split(":", 1)[1].strip()
                                    file_classifications[file_name] = class_part
                            
                            # M·∫´u 2: File: t√™n_file: ph√¢n_lo·∫°i
                            elif line.count(":") >= 2:
                                parts = line.split(":", 2)
                                if len(parts) >= 3:
                                    file_name = parts[1].strip()
                                    class_part = parts[2].strip()
                                    file_classifications[file_name] = class_part
                        
                        # M·∫´u 3: t√™n_file - ph√¢n_lo·∫°i
                        elif "-" in line and not line.startswith("#") and not line.startswith("-"):
                            parts = line.split("-", 1)
                            file_name = parts[0].strip()
                            class_part = parts[1].strip()
                            
                            # Ki·ªÉm tra xem c√≥ ph·∫£i t√™n file h·ª£p l·ªá kh√¥ng
                            if "." in file_name and not " " in file_name:
                                file_classifications[file_name] = class_part
                    
                    # Log k·∫øt qu·∫£ tr√≠ch xu·∫•t ƒë·ªÉ debug
                    log(f"Extracted classifications: {file_classifications}")
                    
                    # N·∫øu kh√¥ng t√¨m th·∫•y ph√¢n lo·∫°i, th·ª≠ t√¨m ki·∫øm to√†n b·ªô n·ªôi dung
                    if not file_classifications:
                        # T√¨m c√°c m·∫´u nh∆∞ "plan2023.pdf - K·∫ø ho·∫°ch kinh doanh"
                        pattern = r'([\w.-]+\.\w+)\s*[-:]\s*([^\n\r]+)'
                        matches = re.findall(pattern, content)
                        for file_name, classification in matches:
                            file_classifications[file_name.strip()] = classification.strip()
                    
                    # C·∫≠p nh·∫≠t th√¥ng tin ph√¢n lo·∫°i cho c√°c file ƒë√£ t√¨m th·∫•y
                    for file_info in detailed_files:
                        if file_info["file_name"] in file_classifications:
                            file_info["label"] = file_classifications[file_info["file_name"]]
                    
                    # S·ª≠ d·ª•ng s·ªë l∆∞·ª£ng file th·ª±c t·∫ø t·ª´ detailed_files ho·∫∑c state["file_count"]
                    actual_file_count = state.get("file_count", len(detailed_files))
                    
                    if is_multi_classification or actual_file_count > 1:
                        # Tr√≠ch xu·∫•t c√°c nh√£n ph√¢n lo·∫°i cho nhi·ªÅu file
                        classifications = list(file_classifications.values())
                        
                        if classifications:
                            # L·∫•y c√°c ph√¢n lo·∫°i duy nh·∫•t
                            unique_classifications = list(set(classifications))
                            classification_result = f"{', '.join(unique_classifications[:3])}"
                            if len(unique_classifications) > 3:
                                classification_result += f" v√† {len(unique_classifications) - 3} lo·∫°i kh√°c"
                            key_findings.append(f"ƒê√£ ph√¢n lo·∫°i {actual_file_count} files: {classification_result}")
                        else:
                            # Fallback n·∫øu kh√¥ng t√¨m th·∫•y chi ti·∫øt ph√¢n lo·∫°i
                            label_pattern = r'K·∫øt qu·∫£ ph√¢n lo·∫°i file[^:]*:\s*([^\n\r]+)'
                            label_matches = re.findall(label_pattern, content)
                            if label_matches:
                                classification_result = label_matches[0].strip()
                                key_findings.append(f"ƒê√£ ph√¢n lo·∫°i {actual_file_count} files: {classification_result}")
                    else:
                        # X·ª≠ l√Ω ph√¢n lo·∫°i ƒë∆°n file
                        label_pattern = r'K·∫øt qu·∫£ ph√¢n lo·∫°i file[^:]*:\s*([^\n\r]+)'
                        label_matches = re.findall(label_pattern, content)
                        if label_matches:
                            classification_result = label_matches[0].strip()
                            key_findings.append(f"ƒê√£ ph√¢n lo·∫°i file: {classification_result}")
                
                # K·∫øt qu·∫£ t·ª´ Metadata agent
                elif "üìã" in content and "ƒê√£ l∆∞u metadata th√†nh c√¥ng" in content:
                    # Ki·ªÉm tra xem c√≥ ph·∫£i l√† l∆∞u metadata cho nhi·ªÅu file kh√¥ng
                    is_multi_file_metadata = "nhi·ªÅu file" in content.lower() or "c√°c file" in content.lower()
                    
                    # Tr√≠ch xu·∫•t metadata ID v√† file paths
                    id_pattern = r'ID:\s*([a-f0-9-]+)'
                    id_matches = re.findall(id_pattern, content)
                    
                    # Tr√≠ch xu·∫•t th√¥ng tin chi ti·∫øt v·ªÅ metadata
                    metadata_file_info = {}
                    lines = content.split('\n')
                    current_file = None
                    current_id = None
                    
                    for line in lines:
                        # T√¨m ID metadata
                        if "ID:" in line:
                            id_match = re.search(r'ID:\s*([a-f0-9-]+)', line)
                            if id_match:
                                current_id = id_match.group(1)
                                if current_id not in metadata_ids:
                                    metadata_ids.append(current_id)
                        
                        # T√¨m th√¥ng tin file
                        if "File:" in line or "ƒê∆∞·ªùng d·∫´n:" in line:
                            file_path_match = re.search(r'(?:File|ƒê∆∞·ªùng d·∫´n):\s*(.+)', line)
                            if file_path_match:
                                file_path = file_path_match.group(1).strip()
                                file_name = os.path.basename(file_path)
                                
                                # C·∫≠p nh·∫≠t metadata ID cho file trong detailed_files
                                for file_info in detailed_files:
                                    if file_info["file_name"] == file_name or file_info["file_path"] == file_path:
                                        file_info["metadata_id"] = current_id
                    
                    # Tr√≠ch xu·∫•t s·ªë l∆∞·ª£ng file t·ª´ n·ªôi dung
                    file_count_pattern = r'(\d+)\s+files?'
                    file_count_matches = re.findall(file_count_pattern, content)
                    file_count = int(file_count_matches[0]) if file_count_matches else 1
                    
                    if id_matches:
                        if is_multi_file_metadata or file_count > 1:
                            key_findings.append(f"ƒê√£ l∆∞u metadata cho {file_count} files v·ªõi ID: {', '.join(metadata_ids[:3])}")
                            if len(metadata_ids) > 3:
                                key_findings[-1] += f" v√† {len(metadata_ids) - 3} ID kh√°c"
                        else:
                            key_findings.append(f"ƒê√£ l∆∞u metadata v·ªõi ID: {metadata_ids[0]}")
                            
                    # C·∫≠p nh·∫≠t th√¥ng tin metadata cho c√°c file ch∆∞a c√≥ metadata_id
                    if len(metadata_ids) == 1 and detailed_files:
                        for file_info in detailed_files:
                            if "metadata_id" not in file_info:
                                file_info["metadata_id"] = metadata_ids[0]
            
            # T·∫°o prompt cho reflection
            # T·∫°o ph·∫ßn m√¥ t·∫£ chi ti·∫øt v·ªÅ c√°c file ƒë√£ t√¨m th·∫•y
            file_info = ""
            file_count = 0  # Kh·ªüi t·∫°o file_count v·ªõi gi√° tr·ªã m·∫∑c ƒë·ªãnh
            
            if detailed_files:
                file_count = len(detailed_files)  # C·∫≠p nh·∫≠t file_count d·ª±a tr√™n detailed_files
                file_list = []
                for file_info_item in detailed_files[:3]:  # Gi·ªõi h·∫°n hi·ªÉn th·ªã chi ti·∫øt 3 file ƒë·∫ßu ti√™n
                    file_detail = f"File: {file_info_item['file_name']}"
                    if file_info_item.get("label"):
                        file_detail += f", Ph√¢n lo·∫°i: {file_info_item['label']}"
                    if file_info_item.get("metadata_id"):
                        file_detail += f", Metadata ID: {file_info_item['metadata_id']}"
                    file_list.append(file_detail)
                
                file_info = f"ƒê√£ t√¨m th·∫•y {len(detailed_files)} files:\n- " + "\n- ".join(file_list)
                if len(detailed_files) > 3:
                    file_info += f"\n- v√† {len(detailed_files) - 3} file kh√°c"
            elif file_found:
                file_count = 1  # N·∫øu c√≥ file_found, c√≥ √≠t nh·∫•t 1 file
                if "files:" in file_found.lower() or "file:" in file_found.lower():
                    # N·∫øu ƒë√£ c√≥ th√¥ng tin ƒë·∫ßy ƒë·ªß v·ªÅ file
                    file_info = file_found
                    # Th·ª≠ ƒë·∫øm s·ªë file t·ª´ file_found
                    import re
                    file_count_matches = re.findall(r'(\d+)\s+files?', file_found.lower())
                    if file_count_matches:
                        file_count = int(file_count_matches[0])
                else:
                    # N·∫øu ch·ªâ c√≥ t√™n file ƒë∆°n l·∫ª
                    file_info = f"File: {file_found}"
            
            # ƒê·∫£m b·∫£o file_count ƒë∆∞·ª£c l·∫•y t·ª´ state n·∫øu c√≥
            if "file_count" in state:
                file_count = state["file_count"]
                log(f"Using file_count from state: {file_count}")
            elif "accessible_files" in state:
                file_count = len(state["accessible_files"])
                log(f"Using file_count from accessible_files: {file_count}")
            
            # Ki·ªÉm tra xem metadata agent c√≥ th·ª±c s·ª± ƒë∆∞·ª£c s·ª≠ d·ª•ng kh√¥ng
            metadata_agent_used = "metadata" in used_tools
            
            # L·∫•y n·ªôi dung tr√≠ch xu·∫•t t·ª´ state n·∫øu c√≥
            extracted_content = ""
            if "agent_results" in state and "text_extraction" in state["agent_results"]:
                extracted_content = state["agent_results"]["text_extraction"]
                # Gi·ªõi h·∫°n ƒë·ªô d√†i n·ªôi dung tr√≠ch xu·∫•t ƒë·ªÉ tr√°nh prompt qu√° d√†i
                if len(extracted_content) > 1000:
                    extracted_content = extracted_content[:1000] + "..."
                log(f"Found extracted content in agent_results: {len(extracted_content)} characters")
            
            # T·∫°o prompt v·ªõi th√¥ng tin r√µ r√†ng h∆°n v√† s·ªë l∆∞·ª£ng file ch√≠nh x√°c
            reflection_prompt = f"""
            B·∫°n l√† m·ªôt AI assistant chuy√™n v·ªÅ t·ªïng h·ª£p k·∫øt qu·∫£ v√† tr·∫£ l·ªùi ng∆∞·ªùi d√πng m·ªôt c√°ch t·ª± nhi√™n, th√¢n thi·ªán.
            
            Y√äU C·∫¶U BAN ƒê·∫¶U C·ª¶A NG∆Ø·ªúI D√ôNG:
            "{original_query}"
            
            C√ÅC C√îNG C·ª§ ƒê√É S·ª¨ D·ª§NG:
            {', '.join(used_tools) if used_tools else 'Kh√¥ng c√≥'}
            
            K·∫æT QU·∫¢ CH√çNH:
            {chr(10).join(f"- {finding}" for finding in key_findings) if key_findings else "- Kh√¥ng c√≥ k·∫øt qu·∫£ n√†o ƒë∆∞·ª£c ghi nh·∫≠n"}
            
            TH√îNG TIN CHI TI·∫æT V·ªÄ FILE:
            {file_info if file_info else "- Kh√¥ng t√¨m th·∫•y file n√†o ph√π h·ª£p"}
            
            S·ªê L∆Ø·ª¢NG FILE CH√çNH X√ÅC: {file_count}
            
            # Kh√¥ng hi·ªÉn th·ªã n·ªôi dung tr√≠ch xu·∫•t trong prompt
            # {f"N·ªòI DUNG TR√çCH XU·∫§T:\n{extracted_content}" if extracted_content and "text_extraction" in used_tools else ""}
            
            L∆ØU √ù ƒê·∫∂C BI·ªÜT:
            {'ƒê√£ s·ª≠ d·ª•ng metadata agent ƒë·ªÉ l∆∞u metadata. H√£y ƒë·ªÅ c·∫≠p ƒë·∫øn vi·ªác ƒë√£ l∆∞u metadata trong ph·∫£n h·ªìi c·ªßa b·∫°n.' if metadata_agent_used else 'KH√îNG ƒë·ªÅ c·∫≠p ƒë·∫øn vi·ªác l∆∞u metadata trong ph·∫£n h·ªìi c·ªßa b·∫°n v√¨ metadata agent kh√¥ng ƒë∆∞·ª£c s·ª≠ d·ª•ng.'}
            {'KH√îNG ƒë·ªÅ c·∫≠p ƒë·∫øn vi·ªác tr√≠ch xu·∫•t n·ªôi dung trong ph·∫£n h·ªìi c·ªßa b·∫°n.' if "text_extraction" in used_tools else 'KH√îNG ƒë·ªÅ c·∫≠p ƒë·∫øn n·ªôi dung tr√≠ch xu·∫•t n·∫øu kh√¥ng c√≥.'}
            
            Y√äU C·∫¶U:
            H√£y t·∫°o m·ªôt c√¢u tr·∫£ l·ªùi ng·∫Øn g·ªçn, t·ª± nhi√™n v√† h·ªØu √≠ch d·ª±a tr√™n th√¥ng tin tr√™n.
            
            H∆Ø·ªöNG D·∫™N TR·∫¢ L·ªúI:
            1. N·∫øu ƒë√£ t√¨m th·∫•y file:
               - X√°c nh·∫≠n ƒë√£ t√¨m th·∫•y file th√†nh c√¥ng
               - Li·ªát k√™ t√™n c√°c file ch√≠nh (n·∫øu √≠t h∆°n 5 file) ho·∫∑c s·ªë l∆∞·ª£ng file (n·∫øu nhi·ªÅu h∆°n 5)
               - QUAN TR·ªåNG: N·∫øu c√≥ k·∫øt qu·∫£ ph√¢n lo·∫°i, LU√îN ƒë·ªÅ c·∫≠p ƒë·∫øn vi·ªác c√°c file ƒë∆∞·ª£c ph√¢n lo·∫°i l√† g√¨
               - M√¥ t·∫£ ng·∫Øn g·ªçn v·ªÅ c√°c file ƒë√£ t√¨m th·∫•y
                
            2. N·∫øu kh√¥ng t√¨m th·∫•y file:
               - Th√¥ng b√°o kh√¥ng t√¨m th·∫•y file ph√π h·ª£p
               - ƒê·ªÅ xu·∫•t c√°c t·ª´ kh√≥a t√¨m ki·∫øm kh√°c n·∫øu c√≥ th·ªÉ
            
            3. N·∫øu c√≥ l·ªói ho·∫∑c v·∫•n ƒë·ªÅ:
               - Gi·∫£i th√≠ch ng·∫Øn g·ªçn v·∫•n ƒë·ªÅ
               - ƒê·ªÅ xu·∫•t h∆∞·ªõng kh·∫Øc ph·ª•c n·∫øu c√≥
               
            4. N·∫øu ƒë√£ tr√≠ch xu·∫•t n·ªôi dung:
                - KH√îNG ƒë·ªÅ c·∫≠p ƒë·∫øn vi·ªác tr√≠ch xu·∫•t n·ªôi dung trong ph·∫£n h·ªìi
                - T·∫≠p trung v√†o k·∫øt qu·∫£ ph√¢n lo·∫°i ho·∫∑c t√¨m ki·∫øm ho·∫∑c save metadata t√πy v√†o y√™u c·∫ßu c·ªßa ng∆∞·ªùi d√πng
            
            L∆ØU √ù QUAN TR·ªåNG:
            - Lu√¥n ƒë·ªÅ c·∫≠p ƒë·∫øn c√°c file ƒë√£ t√¨m th·∫•y n·∫øu c√≥
            - LU√îN ƒë·ªÅ c·∫≠p ƒë·∫øn k·∫øt qu·∫£ ph√¢n lo·∫°i file n·∫øu c√≥ (v√≠ d·ª•: "Hai file ƒë·ªÅu ƒë∆∞·ª£c ph√¢n lo·∫°i l√† t√†i ch√≠nh")
            - S·ª≠ d·ª•ng ng√¥n ng·ªØ t·ª± nhi√™n, g·∫ßn g≈©i
            - Gi·ªõi h·∫°n trong 2-3 c√¢u 
            - KH√îNG ƒë·ªÅ c·∫≠p ƒë·∫øn vi·ªác tr√≠ch xu·∫•t n·ªôi dung trong ph·∫£n h·ªìi
            - Kh√¥ng c·∫ßn gi·∫£i th√≠ch th√™m sau c√¢u tr·∫£ l·ªùi
            
            C√ÇU TR·∫¢ L·ªúI (ch·ªâ tr·∫£ v·ªÅ c√¢u tr·∫£ l·ªùi, kh√¥ng c√≥ ph·∫ßn gi·∫£i th√≠ch):
            """
            
            # G·ªçi LLM ƒë·ªÉ t·∫°o reflection response
            response = await self.model.ainvoke(reflection_prompt)
            reflection_response = response.content.strip()
            
            # ƒê·∫£m b·∫£o s·ªë l∆∞·ª£ng file ƒë∆∞·ª£c b√°o c√°o ch√≠nh x√°c
            # S·ª≠ d·ª•ng state["file_count"] ƒë√£ ƒë∆∞·ª£c x√°c ƒë·ªãnh tr∆∞·ªõc ƒë√≥
            file_count = state.get("file_count", 0)
            
            # N·∫øu kh√¥ng c√≥ file_count trong state, s·ª≠ d·ª•ng s·ªë l∆∞·ª£ng file duy nh·∫•t trong detailed_files
            if file_count == 0 and detailed_files:
                # S·ªë l∆∞·ª£ng file ch√≠nh x√°c l√† s·ªë l∆∞·ª£ng ph·∫ßn t·ª≠ trong detailed_files
                # V√¨ detailed_files ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω ƒë·ªÉ kh√¥ng c√≥ tr√πng l·∫∑p
                file_count = len(detailed_files)
                
            # ƒê·∫£m b·∫£o file_count lu√¥n l√† s·ªë nguy√™n d∆∞∆°ng
            file_count = max(0, file_count)
                
            log(f"ReflectionAgent debug - Final file count for response: {file_count}, detailed_files: {len(detailed_files) if detailed_files else 0}")
            
            # Ki·ªÉm tra n·∫øu ph·∫£n h·ªìi kh√¥ng ch√≠nh x√°c v·ªÅ s·ªë l∆∞·ª£ng file
            incorrect_file_count = False
            
            # Ki·ªÉm tra n·∫øu ph·∫£n h·ªìi ƒë·ªÅ c·∫≠p ƒë·∫øn s·ªë l∆∞·ª£ng file kh√°c v·ªõi s·ªë l∆∞·ª£ng th·ª±c t·∫ø
            # T√¨m c√°c s·ªë trong ph·∫£n h·ªìi
            numbers_in_response = re.findall(r'\b(\d+)\s+files?\b', reflection_response.lower())
            
            # N·∫øu c√≥ s·ªë trong ph·∫£n h·ªìi v√† kh√°c v·ªõi file_count
            for num_str in numbers_in_response:
                if int(num_str) != file_count:
                    incorrect_file_count = True
                    break
                    
            # N·∫øu ch·ªâ c√≥ 1 file nh∆∞ng ph·∫£n h·ªìi ƒë·ªÅ c·∫≠p ƒë·∫øn nhi·ªÅu file
            if file_count == 1 and ("files" in reflection_response.lower() or re.search(r'\d+\s+files', reflection_response.lower())):
                incorrect_file_count = True
                
            # N·∫øu c√≥ nhi·ªÅu file nh∆∞ng ph·∫£n h·ªìi kh√¥ng ƒë·ªÅ c·∫≠p ƒë·∫øn nhi·ªÅu file
            if file_count > 1 and "files" not in reflection_response.lower():
                incorrect_file_count = True
                
            if incorrect_file_count:
                # T·∫°o danh s√°ch t√™n file ƒë·ªÉ hi·ªÉn th·ªã trong prompt
                file_names = []
                if detailed_files:
                    file_names = [f_info["file_name"] for f_info in detailed_files[:3]]
                    if len(detailed_files) > 3:
                        file_names.append(f"v√† {len(detailed_files) - 3} file kh√°c")
                
                # Th·ª≠ l·∫°i v·ªõi prompt r√µ r√†ng h∆°n
                if file_count == 1:
                    # N·∫øu ch·ªâ c√≥ 1 file
                    file_name = file_names[0] if file_names else "file"
                    enhanced_prompt = f"""
                    {reflection_prompt}
                    
                    L∆ØU √ù ƒê·∫∂C BI·ªÜT: 
                    B·∫°n ƒë√£ t√¨m th·∫•y CH√çNH X√ÅC 1 FILE, kh√¥ng ph·∫£i nhi·ªÅu file.
                    File n√†y l√†: {file_name}
                    H√£y ƒë·∫£m b·∫£o ƒë·ªÅ c·∫≠p ƒë·∫øn vi·ªác t√¨m th·∫•y CH·ªà M·ªòT file trong c√¢u tr·∫£ l·ªùi c·ªßa b·∫°n.
                    KH√îNG ƒë∆∞·ª£c ƒë·ªÅ c·∫≠p ƒë·∫øn nhi·ªÅu file trong c√¢u tr·∫£ l·ªùi.
                    """
                else:
                    # N·∫øu c√≥ nhi·ªÅu file
                    enhanced_prompt = f"""
                    {reflection_prompt}
                    
                    L∆ØU √ù ƒê·∫∂C BI·ªÜT: 
                    B·∫°n ƒë√£ t√¨m th·∫•y CH√çNH X√ÅC {file_count} FILE, kh√¥ng ph·∫£i nhi·ªÅu h∆°n hay √≠t h∆°n.
                    C√°c file bao g·ªìm: {', '.join(file_names) if file_names else file_found}
                    H√£y ƒë·∫£m b·∫£o ƒë·ªÅ c·∫≠p ƒë·∫øn vi·ªác t√¨m th·∫•y CH√çNH X√ÅC {file_count} FILE trong c√¢u tr·∫£ l·ªùi c·ªßa b·∫°n v√† li·ªát k√™ t√™n file.
                    KH√îNG ƒë∆∞·ª£c ƒë·ªÅ c·∫≠p ƒë·∫øn s·ªë l∆∞·ª£ng file kh√°c v·ªõi {file_count}.
                    """
                
                try:
                    enhanced_response = await self.model.ainvoke(enhanced_prompt)
                    enhanced_reflection = enhanced_response.content.strip()
                    
                    # Ki·ªÉm tra xem ph·∫£n h·ªìi m·ªõi c√≥ ch√≠nh x√°c v·ªÅ s·ªë l∆∞·ª£ng file kh√¥ng
                    is_correct_response = False
                    
                    if file_count == 1:
                        # N·∫øu ch·ªâ c√≥ 1 file, ph·∫£n h·ªìi kh√¥ng n√™n ƒë·ªÅ c·∫≠p ƒë·∫øn nhi·ªÅu file
                        if "files" not in enhanced_reflection.lower() and "nhi·ªÅu file" not in enhanced_reflection.lower():
                            is_correct_response = True
                    else:
                        # N·∫øu c√≥ nhi·ªÅu file, ph·∫£n h·ªìi ph·∫£i ƒë·ªÅ c·∫≠p ƒë·∫øn nhi·ªÅu file
                        if "files" in enhanced_reflection.lower() or "nhi·ªÅu file" in enhanced_reflection.lower():
                            is_correct_response = True
                    
                    if is_correct_response:
                        reflection_response = enhanced_reflection
                        log(f"Enhanced reflection response generated with correct file count mention: {file_count}")
                except Exception as e:
                    log(f"Error generating enhanced reflection: {str(e)}", level='warning')
            
            log(f"Reflection response generated: {reflection_response}")
            return reflection_response
            
        except Exception as e:
            log(f"Error in reflection agent: {str(e)}", level='error')
            # Fallback response
            return f"T√¥i ƒë√£ ho√†n th√†nh y√™u c·∫ßu c·ªßa b·∫°n. ƒê√£ s·ª≠ d·ª•ng {len(state.get('used_tools', []))} c√¥ng c·ª• ƒë·ªÉ x·ª≠ l√Ω v√† ƒë·∫°t ƒë∆∞·ª£c k·∫øt qu·∫£ mong mu·ªën."

class MultiAgentSystem:
    """
    Multi-Agent System that orchestrates specialized agents using a worker-evaluator pattern.
    
    This system can use multiple specialized agents in sequence (FilesystemAgent, MetadataAgent,
    TextExtractionAgent, FileClassificationAgent) based on the user's query and includes
    an evaluator component to assess if the task has been completed successfully.
    """
    def __init__(self):
        """
        Initialize the MultiAgentSystem.
        """
        self.model = gemini
        self.graph = None
        self.agents = {}
        self.session_id = None
        self.all_tools = []
        self.reflection_agent = ReflectionAgent()  # Th√™m reflection agent
        self.human_feedback_agent = None  # Kh·ªüi t·∫°o human feedback agent
        self.data_analysis_agent = DataAnalysisAgent()  # Th√™m data analysis agent
    
    async def initialize(self):
        """
        Asynchronously initialize all specialized agents and create the workflow graph.
        
        Returns:
            MultiAgentSystem: The initialized multi-agent system.
        """
        try:
            # Initialize specialized agents
            print("Initializing specialized agents...")
            
            # Kh·ªüi t·∫°o human feedback agent
            self.human_feedback_agent = HumanFeedbackAgent(session_id=self.session_id)
            
            mcp_client = MultiServerMCPClient({
                "document_search": {
                    "command": "cmd",
                    "args": [
                        "/c",
                        "npx",
                        "-y",
                        "@modelcontextprotocol/server-filesystem",
                        "C:\\Users\\dhuu3\\Desktop\\local-classify-docs-ai-agent\\data"  # Adjusted path,
                    ],
                    "transport": "stdio"
                }
            })
            print("Using provided MCP client for FilesystemAgent")
            
            self.agents["filesystem"] = await FilesystemAgent.create(mcp_client=mcp_client)
            self.agents["metadata"] = MetadataAgent()
            self.agents["text_extraction"] = TextExtractionAgent()
            self.agents["file_classification"] = FileClassificationAgent()
            self.agents["rag"] = RAGAgent()
            self.agents["data_analysis"] = DataAnalysisAgent()
            # Build RAG index for data directory
            data_dir = "C:\\Users\\dhuu3\\Desktop\\local-classify-docs-ai-agent\\data"
            await self.agents["rag"].build_index(data_dir)
            print("All specialized agents initialized successfully")
            
            # Collect tools from all agents
            # This would require each agent to expose its tools
            # For now, we'll use a placeholder approach
            self.all_tools = []
            
            # Build the graph
            await self.build_graph()
            
            return self
            
        except Exception as e:
            print(f"Error initializing multi-agent system: {e}")
            import traceback
            traceback.print_exc()
            raise
    
    async def build_graph(self):
        """
        Build the state graph for the multi-agent system using a worker-evaluator pattern.
        """
        # Create a state graph with our AgentState
        graph_builder = StateGraph(AgentState)
        
        # Add nodes for each component
        graph_builder.add_node("worker", self.worker)
        graph_builder.add_node("router", self.route_query)
        graph_builder.add_node("human_feedback", self.process_human_feedback)
        graph_builder.add_node("filesystem_agent", self.run_filesystem_agent)
        graph_builder.add_node("metadata_agent", self.run_metadata_agent)
        graph_builder.add_node("text_extraction_agent", self.run_text_extraction_agent)
        graph_builder.add_node("file_classification_agent", self.run_file_classification_agent)
        graph_builder.add_node("rag_agent", self.run_rag_agent)
        graph_builder.add_node("data_analysis_agent", self.run_data_analysis_agent)
        graph_builder.add_node("evaluator", self.evaluator)
        graph_builder.add_node("reflection", self.run_reflection_agent)  # Th√™m reflection node
        
        # Add edges
        graph_builder.add_edge(START, "worker")
        
        # Worker can route to specific agents or directly to evaluator
        graph_builder.add_conditional_edges(
            "worker", 
            self.worker_router,
            {
                "router": "router",
                "evaluator": "evaluator",
                "human_feedback": "human_feedback"
            }
        )
        
        # Router determines which agent to use
        graph_builder.add_conditional_edges(
            "router",
            self.determine_agent,
            {
                "filesystem": "filesystem_agent",
                "metadata": "metadata_agent",
                "text_extraction": "text_extraction_agent",
                "file_classification": "file_classification_agent",
                "rag": "rag_agent",
                "data_analysis": "data_analysis_agent",
                "evaluator": "evaluator"
            }
        )
        
        # Connect all agent nodes back to worker
        graph_builder.add_edge("filesystem_agent", "worker")
        graph_builder.add_edge("metadata_agent", "worker")
        graph_builder.add_edge("text_extraction_agent", "worker")
        graph_builder.add_edge("file_classification_agent", "worker")
        graph_builder.add_edge("rag_agent", "worker")
        graph_builder.add_edge("data_analysis_agent", "worker")
        graph_builder.add_edge("human_feedback", "worker")
        
        # Evaluator routes to reflection instead of directly to END
        graph_builder.add_conditional_edges(
            "evaluator",
            self.route_based_on_evaluation,
            {"complete": "reflection", "continue": "worker"}  # Thay ƒë·ªïi: complete -> reflection
        )
        
        # Reflection agent ends the workflow
        graph_builder.add_edge("reflection", END)
        
        # Compile the graph
        self.graph = graph_builder.compile(checkpointer=memory)
        log("Multi-agent graph built successfully with reflection agent")
        
        # T·∫°o bi·ªÉu ƒë·ªì tr·ª±c quan cho h·ªá th·ªëng ƒëa t√°c t·ª≠
        try:
            from IPython.display import Image, display
            import os
            
            # T·∫°o th∆∞ m·ª•c cho bi·ªÉu ƒë·ªì n·∫øu ch∆∞a t·ªìn t·∫°i
            graph_dir = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), "graphs")
            os.makedirs(graph_dir, exist_ok=True)
            
            # ƒê∆∞·ªùng d·∫´n ƒë·∫øn file bi·ªÉu ƒë·ªì
            graph_path = os.path.join(graph_dir, "multiagent.png")
            
            # T·∫°o bi·ªÉu ƒë·ªì d∆∞·ªõi d·∫°ng PNG s·ª≠ d·ª•ng Mermaid
            try:
                # Ph∆∞∆°ng ph√°p 1: S·ª≠ d·ª•ng draw_mermaid_png
                mermaid_png = self.graph.get_graph().draw_mermaid_png()
                
                # L∆∞u file PNG
                with open(graph_path, 'wb') as f:
                    f.write(mermaid_png)
                    
                log(f"ƒê√£ t·∫°o bi·ªÉu ƒë·ªì LangGraph t·∫°i: {graph_path}")
                
                # Hi·ªÉn th·ªã bi·ªÉu ƒë·ªì n·∫øu ƒëang ch·∫°y trong m√¥i tr∆∞·ªùng Jupyter
                try:
                    display(Image(mermaid_png))
                except:
                    pass
                    
            except Exception as e1:
                log(f"L·ªói khi t·∫°o bi·ªÉu ƒë·ªì b·∫±ng draw_mermaid_png: {str(e1)}")
                
                # Ph∆∞∆°ng ph√°p 2: S·ª≠ d·ª•ng to_dot
                try:
                    import tempfile
                    import subprocess
                    
                    # T·∫°o bi·ªÉu ƒë·ªì d∆∞·ªõi d·∫°ng dot
                    dot_graph = self.graph.get_graph().to_dot()
                    
                    # L∆∞u file dot t·∫°m th·ªùi
                    temp_dot = tempfile.NamedTemporaryFile(suffix='.dot', delete=False)
                    temp_dot.write(dot_graph.encode('utf-8'))
                    temp_dot.close()
                    
                    # S·ª≠ d·ª•ng graphviz ƒë·ªÉ chuy·ªÉn ƒë·ªïi t·ª´ dot sang png
                    subprocess.run(['dot', '-Tpng', temp_dot.name, '-o', graph_path])
                    
                    # X√≥a file t·∫°m
                    os.unlink(temp_dot.name)
                    
                    log(f"ƒê√£ t·∫°o bi·ªÉu ƒë·ªì LangGraph b·∫±ng ph∆∞∆°ng ph√°p dot t·∫°i: {graph_path}")
                    
                except Exception as e2:
                    log(f"L·ªói khi t·∫°o bi·ªÉu ƒë·ªì b·∫±ng ph∆∞∆°ng ph√°p dot: {str(e2)}")
                    
                    # Ph∆∞∆°ng ph√°p 3: S·ª≠ d·ª•ng NetworkX
                    try:
                        import networkx as nx
                        import matplotlib.pyplot as plt
                        
                        # T·∫°o bi·ªÉu ƒë·ªì t·ª´ JSON
                        graph_json = self.graph.get_graph().to_json()
                        
                        G = nx.DiGraph()
                        
                        # Th√™m nodes
                        for node in graph_json.get('nodes', []):
                            G.add_node(node['id'], type='agent')
                        
                        # Th√™m edges
                        for edge in graph_json.get('edges', []):
                            G.add_edge(edge['source'], edge['target'], label=edge.get('condition', ''))
                        
                        # V·∫Ω bi·ªÉu ƒë·ªì
                        plt.figure(figsize=(12, 8))
                        pos = nx.spring_layout(G, seed=42)
                        nx.draw(G, pos, with_labels=True, node_color='lightblue', node_size=2000, font_size=10, font_weight='bold')
                        
                        # V·∫Ω nh√£n c·∫°nh
                        edge_labels = {(u, v): d['label'] for u, v, d in G.edges(data=True) if 'label' in d}
                        nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=8)
                        
                        plt.title('H·ªá th·ªëng ƒëa t√°c t·ª≠ ph√¢n lo·∫°i t√†i li·ªáu', fontsize=16)
                        plt.axis('off')
                        plt.tight_layout()
                        plt.savefig(graph_path, dpi=300, bbox_inches='tight')
                        plt.close()
                        
                        log(f"ƒê√£ t·∫°o bi·ªÉu ƒë·ªì LangGraph b·∫±ng NetworkX t·∫°i: {graph_path}")
                    except Exception as e3:
                        log(f"L·ªói khi t·∫°o bi·ªÉu ƒë·ªì b·∫±ng NetworkX: {str(e3)}")
        except Exception as e:
            log(f"L·ªói khi t·∫°o bi·ªÉu ƒë·ªì LangGraph: {str(e)}")
            # Kh√¥ng l√†m gi√°n ƒëo·∫°n qu√° tr√¨nh kh·ªüi t·∫°o n·∫øu c√≥ l·ªói khi t·∫°o bi·ªÉu ƒë·ªì
    
    async def run_reflection_agent(self, state: AgentState) -> AgentState:
        """
        Run the reflection agent to create final response for user.
        """
        try:
            log("Running ReflectionAgent...")
            
            # Ki·ªÉm tra xem c√≥ ph·∫£n h·ªìi ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω kh√¥ng
            if state.get("feedback_processed", False):
                # N·∫øu ƒë√£ x·ª≠ l√Ω ph·∫£n h·ªìi, kh√¥ng c·∫ßn ch·∫°y reflection agent
                log("Ph·∫£n h·ªìi ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω, b·ªè qua reflection", level='info')
                state["task_complete"] = True
                return state
                
            # Track that we're using reflection agent
            if "used_tools" not in state:
                state["used_tools"] = []
            state["used_tools"].append("reflection")
            
            # Generate reflection response
            reflection_response = await self.reflection_agent.reflect_and_respond(state)
            
            # Add reflection response to messages
            state["messages"].append(AIMessage(content=f"üí≠ {reflection_response}"))
            
            # Add to chain of thought
            if "chain_of_thought" not in state:
                state["chain_of_thought"] = []
            state["chain_of_thought"].append(f"ü§î Reflection: T·∫°o c√¢u tr·∫£ l·ªùi cu·ªëi c√πng cho ng∆∞·ªùi d√πng")
            
            # Mark task as complete
            state["task_complete"] = True
            state["success_criteria_met"] = True
            
            log(f"ReflectionAgent completed: {reflection_response}")
            return state
            
        except Exception as e:
            log(f"Error in reflection agent: {str(e)}", level='error')
            # Fallback response
            fallback_response = "T√¥i ƒë√£ ho√†n th√†nh y√™u c·∫ßu c·ªßa b·∫°n th√†nh c√¥ng."
            state["messages"].append(AIMessage(content=f"üí≠ {fallback_response}"))
            state["task_complete"] = True
            state["success_criteria_met"] = True
            return state

    # async def process_human_feedback(self, state: AgentState) -> AgentState:
    #     """
    #     X·ª≠ l√Ω ph·∫£n h·ªìi t·ª´ ng∆∞·ªùi d√πng.
    #     """
    #     try:
    #         # Ki·ªÉm tra xem c√≥ tin nh·∫Øn cu·ªëi c√πng kh√¥ng
    #         if not state.get("messages") or not isinstance(state["messages"][-1], HumanMessage):
    #             return state
                
    #         # L·∫•y n·ªôi dung tin nh·∫Øn cu·ªëi c√πng
    #         last_message = state["messages"][-1].content
    #         log(f"Ki·ªÉm tra tin nh·∫Øn cu·ªëi c√πng: {last_message[:100]}...", level='info')
                
    #         # Ki·ªÉm tra xem c√≥ ph·∫£i l√† ph·∫£n h·ªìi feedback kh√¥ng
    #         if self.human_feedback_agent:
    #             is_feedback = await self.human_feedback_agent.is_feedback_message(last_message)
    #             if is_feedback:
    #                 log("ƒêang x·ª≠ l√Ω ph·∫£n h·ªìi t·ª´ ng∆∞·ªùi d√πng...", level='info')
                    
    #                 # Import LLM ƒë·ªÉ s·ª≠ d·ª•ng cho vi·ªác x·ª≠ l√Ω ph·∫£n h·ªìi
    #                 from config.llm import gemini
                    
    #                 # G·ªçi human feedback agent ƒë·ªÉ x·ª≠ l√Ω ph·∫£n h·ªìi
    #                 updated_state = await self.human_feedback_agent.process_feedback(state, last_message)
                    
    #                 # Th√™m v√†o chain of thought
    #                 if "chain_of_thought" not in updated_state:
    #                     updated_state["chain_of_thought"] = []
    #                 updated_state["chain_of_thought"].append(f"üí¨ ƒê√£ x·ª≠ l√Ω ph·∫£n h·ªìi t·ª´ ng∆∞·ªùi d√πng v√† c·∫≠p nh·∫≠t ph√¢n lo·∫°i")
                    
    #                 # ƒê√°nh d·∫•u l√† ƒë√£ x·ª≠ l√Ω ph·∫£n h·ªìi
    #                 updated_state["feedback_processed"] = True
    #                 log("ƒê√£ x·ª≠ l√Ω ph·∫£n h·ªìi t·ª´ ng∆∞·ªùi d√πng th√†nh c√¥ng", level='info')
    #                 return updated_state
    #             else:
    #                 log("Tin nh·∫Øn kh√¥ng ph·∫£i l√† ph·∫£n h·ªìi, b·ªè qua", level='info')
    #         else:
    #             log("Kh√¥ng c√≥ human_feedback_agent ƒë·ªÉ x·ª≠ l√Ω ph·∫£n h·ªìi", level='warning')
                
    #         return state
            
    #     except Exception as e:
    #         log(f"L·ªói khi x·ª≠ l√Ω ph·∫£n h·ªìi t·ª´ ng∆∞·ªùi d√πng: {e}", level='error')
    #         import traceback
    #         traceback.print_exc()
    #         return state
            
    async def worker_router(self, state: AgentState) -> str:
        """
        Router node that decides where to go next after the worker node.
        """
        log("üîÅ [WORKER_ROUTER] ƒê·ªãnh tuy·∫øn sau worker node", level='info')
        log(f"üîÑ [WORKER_ROUTER] Tr·∫°ng th√°i is_feedback: {state.get('is_feedback')}", level='info')
        log(f"üîÑ [WORKER_ROUTER] Tr·∫°ng th√°i feedback_processed: {state.get('feedback_processed')}", level='info')
        
        # N·∫øu ƒë√£ ƒë∆∞·ª£c ƒë√°nh d·∫•u l√† ph·∫£n h·ªìi t·ª´ worker
        if state.get("is_feedback") or state.get("feedback_processed"):
            log("‚úÖ [WORKER_ROUTER] Ph·∫£n h·ªìi ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω, ƒë·ªãnh tuy·∫øn ƒë·∫øn evaluator", level='info')
            return "evaluator"
            
        # Ki·ªÉm tra l·∫°i xem tin nh·∫Øn cu·ªëi c√πng c√≥ ph·∫£i l√† ph·∫£n h·ªìi kh√¥ng (tr∆∞·ªùng h·ª£p b·ªè s√≥t)
        if state.get("messages") and isinstance(state["messages"][-1], HumanMessage):
            last_message = state["messages"][-1].content
            log(f"üí¨ [WORKER_ROUTER] Ki·ªÉm tra l·∫°i tin nh·∫Øn: '{last_message}'", level='info')
            
            # Ki·ªÉm tra tr·ª±c ti·∫øp c√°c pattern ph·ªï bi·∫øn tr∆∞·ªõc khi g·ªçi is_feedback_message
            message_lower = last_message.lower()
            if ".pdf" in message_lower and "ph√¢n lo·∫°i ƒë√∫ng l√†" in message_lower:
                log("üéØ [WORKER_ROUTER] Ph√°t hi·ªán pattern '.pdf ph√¢n lo·∫°i ƒë√∫ng l√†', x·ª≠ l√Ω nh∆∞ feedback", level='info')
                state["is_feedback"] = True
                log("üíæ [WORKER_ROUTER] ƒê√£ ƒë√°nh d·∫•u state[\"is_feedback\"] = True", level='info')
                return "human_feedback"
            
            # Ki·ªÉm tra xem c√≥ ph·∫£i l√† ph·∫£n h·ªìi kh√¥ng
            try:
                if self.human_feedback_agent:
                    is_feedback = await self.human_feedback_agent.is_feedback_message(last_message)
                    log(f"üîç [WORKER_ROUTER] K·∫øt qu·∫£ ki·ªÉm tra feedback: {is_feedback}", level='info')
                    
                    if is_feedback:
                        log("üîî [WORKER_ROUTER] Ph√°t hi·ªán ph·∫£n h·ªìi t·ª´ ng∆∞·ªùi d√πng trong worker_router, ƒë·ªãnh tuy·∫øn ƒë·∫øn human_feedback node", level='info')
                        # ƒê√°nh d·∫•u l√† ph·∫£n h·ªìi ƒë·ªÉ c√°c node kh√°c bi·∫øt
                        state["is_feedback"] = True
                        log("üíæ [WORKER_ROUTER] ƒê√£ ƒë√°nh d·∫•u state[\"is_feedback\"] = True", level='info')
                        return "human_feedback"
            except Exception as e:
                log(f"‚ö†Ô∏è [WORKER_ROUTER] L·ªói khi ki·ªÉm tra feedback: {str(e)}", level='error')
    
        # N·∫øu kh√¥ng c√≤n agent n√†o trong k·∫ø ho·∫°ch, chuy·ªÉn sang evaluator
        if not state.get("current_agents"):
            log("üîç [WORKER_ROUTER] Kh√¥ng c√≤n agent n√†o trong k·∫ø ho·∫°ch, chuy·ªÉn sang evaluator", level='info')
            return "evaluator"
            
        # N·∫øu ƒë√£ s·ª≠ d·ª•ng qu√° nhi·ªÅu agent, chuy·ªÉn sang evaluator ƒë·ªÉ tr√°nh v√≤ng l·∫∑p v√¥ h·∫°n
        if len(state.get("used_tools", [])) >= 3:
            log("‚ö†Ô∏è [WORKER_ROUTER] ƒê√£ s·ª≠ d·ª•ng qu√° nhi·ªÅu agent, chuy·ªÉn sang evaluator", level='info')
            return "evaluator"
            
        # Ki·ªÉm tra xem c√≥ ƒëang l·∫∑p l·∫°i agent kh√¥ng
        if len(state.get("used_tools", [])) >= 2:
            last_two_tools = state["used_tools"][-2:]
            if last_two_tools[0] == last_two_tools[1]:
                log("‚õî [WORKER_ROUTER] Ph√°t hi·ªán l·∫∑p l·∫°i agent, chuy·ªÉn sang evaluator", level='info')
                return "evaluator"
                
        # Ti·∫øp t·ª•c v·ªõi router
        log("‚û°Ô∏è [WORKER_ROUTER] Ti·∫øp t·ª•c v·ªõi router", level='info')
        return "router"
    
    async def process_human_feedback(self, state: AgentState) -> AgentState:
        """
        Process human feedback on classification or metadata.
        This method is called when a feedback message is detected.
        """
        try:
            log("üîÑ [HUMAN_FEEDBACK] B·∫Øt ƒë·∫ßu x·ª≠ l√Ω ph·∫£n h·ªìi t·ª´ ng∆∞·ªùi d√πng", level='info')
            
            # L·∫•y tin nh·∫Øn ph·∫£n h·ªìi t·ª´ ng∆∞·ªùi d√πng
            last_message = state["messages"][-1].content
            log(f"üí¨ [HUMAN_FEEDBACK] Tin nh·∫Øn ph·∫£n h·ªìi: '{last_message}'", level='info')
            
            # ƒê·∫£m b·∫£o human_feedback_agent ƒë∆∞·ª£c kh·ªüi t·∫°o v·ªõi session_id hi·ªán t·∫°i
            if not self.human_feedback_agent or self.human_feedback_agent.session_id != self.session_id:
                from agents.human_feedback_agent import HumanFeedbackAgent
                self.human_feedback_agent = HumanFeedbackAgent(session_id=self.session_id)
                log(f"üîÑ [HUMAN_FEEDBACK] Kh·ªüi t·∫°o l·∫°i HumanFeedbackAgent v·ªõi session_id: {self.session_id}", level='info')
            
            # S·ª≠ d·ª•ng human_feedback_agent ƒë·ªÉ x·ª≠ l√Ω ph·∫£n h·ªìi
            if self.human_feedback_agent:
                # Tr√≠ch xu·∫•t th√¥ng tin ph·∫£n h·ªìi
                feedback_info = await self.human_feedback_agent.extract_feedback_info(last_message, self.model)
                log(f"üìù [HUMAN_FEEDBACK] Th√¥ng tin ph·∫£n h·ªìi: {feedback_info}", level='info')
                
                # ƒê·∫£m b·∫£o state c√≥ tr∆∞·ªùng messages
                if "messages" not in state:
                    state["messages"] = []
                
                # √Åp d·ª•ng ph·∫£n h·ªìi v√†o k·∫øt qu·∫£ ph√¢n lo·∫°i
                updated_state = await self.human_feedback_agent.apply_context_adaptation(feedback_info, state)
                
                # ƒê√°nh d·∫•u l√† ƒë√£ x·ª≠ l√Ω ph·∫£n h·ªìi
                updated_state["feedback_processed"] = True
                
                # Th√¥ng b√°o x√°c nh·∫≠n ƒë√£ ƒë∆∞·ª£c th√™m trong apply_context_adaptation
                log("‚úÖ [HUMAN_FEEDBACK] Ho√†n th√†nh x·ª≠ l√Ω ph·∫£n h·ªìi", level='info')
                return updated_state
            else:
                log("‚ö†Ô∏è [HUMAN_FEEDBACK] Kh√¥ng c√≥ human_feedback_agent ƒë·ªÉ x·ª≠ l√Ω ph·∫£n h·ªìi!", level='warning')
                # Th√™m th√¥ng b√°o l·ªói
                error_msg = "‚ùå Kh√¥ng th·ªÉ x·ª≠ l√Ω ph·∫£n h·ªìi do thi·∫øu human_feedback_agent"
                state["messages"].append(AIMessage(content=error_msg))
                return state
                
        except Exception as e:
            log(f"‚ùå [HUMAN_FEEDBACK] L·ªói khi x·ª≠ l√Ω ph·∫£n h·ªìi: {str(e)}", level='error')
            import traceback
            traceback.print_exc()
            # Th√™m th√¥ng b√°o l·ªói
            error_msg = f"‚ùå ƒê√£ x·∫£y ra l·ªói khi x·ª≠ l√Ω ph·∫£n h·ªìi: {str(e)}"
            state["messages"].append(AIMessage(content=error_msg))
            return state
    
    async def worker(self, state: AgentState) -> AgentState:
        """
        Worker node that processes the user's query and determines next steps.
        """
        log("üîß [WORKER] B·∫Øt ƒë·∫ßu x·ª≠ l√Ω trong worker node", level='info')
        
        # Ki·ªÉm tra xem tin nh·∫Øn cu·ªëi c√πng c√≥ ph·∫£i l√† ph·∫£n h·ªìi kh√¥ng
        if state.get("messages") and isinstance(state["messages"][-1], HumanMessage):
            last_message = state["messages"][-1].content
            log(f"üí¨ [WORKER] Tin nh·∫Øn cu·ªëi c√πng l√† HumanMessage: '{last_message}'", level='info')
            
            # Ki·ªÉm tra tr·ª±c ti·∫øp c√°c pattern ph·ªï bi·∫øn tr∆∞·ªõc khi g·ªçi is_feedback_message
            message_lower = last_message.lower()
            
            # Ki·ªÉm tra pattern ".pdf ph√¢n lo·∫°i ƒë√∫ng l√†"
            if ".pdf" in message_lower and "ph√¢n lo·∫°i ƒë√∫ng l√†" in message_lower:
                log("üéØ [WORKER] Ph√°t hi·ªán pattern '.pdf ph√¢n lo·∫°i ƒë√∫ng l√†', x·ª≠ l√Ω nh∆∞ feedback", level='info')
                state["is_feedback"] = True
                log("üíæ [WORKER] ƒê√£ ƒë√°nh d·∫•u state[\"is_feedback\"] = True", level='info')
                # X·ª≠ l√Ω ph·∫£n h·ªìi tr·ª±c ti·∫øp
                state = await self.process_human_feedback(state)
                log("‚úÖ [WORKER] Ho√†n th√†nh x·ª≠ l√Ω feedback, tr·∫£ v·ªÅ state", level='info')
                return state
            
            # Ki·ªÉm tra pattern "kh√¥ng ph·∫£i lo·∫°i"
            if ".pdf" in message_lower and "kh√¥ng ph·∫£i lo·∫°i" in message_lower:
                log("üéØ [WORKER] Ph√°t hi·ªán pattern '.pdf kh√¥ng ph·∫£i lo·∫°i', x·ª≠ l√Ω nh∆∞ feedback", level='info')
                state["is_feedback"] = True
                log("üíæ [WORKER] ƒê√£ ƒë√°nh d·∫•u state[\"is_feedback\"] = True", level='info')
                # X·ª≠ l√Ω ph·∫£n h·ªìi tr·ª±c ti·∫øp
                state = await self.process_human_feedback(state)
                log("‚úÖ [WORKER] Ho√†n th√†nh x·ª≠ l√Ω feedback, tr·∫£ v·ªÅ state", level='info')
                return state
            
            # Ki·ªÉm tra ngay t·ª´ ƒë·∫ßu xem c√≥ ph·∫£i l√† ph·∫£n h·ªìi kh√¥ng
            if self.human_feedback_agent:
                log("ü§ñ [WORKER] C√≥ human_feedback_agent, ki·ªÉm tra feedback...", level='info')
                try:
                    is_feedback = await self.human_feedback_agent.is_feedback_message(last_message)
                    log(f"üîç [WORKER] K·∫øt qu·∫£ ki·ªÉm tra feedback: {is_feedback}", level='info')
                    
                    if is_feedback:
                        log("‚úÖ [WORKER] Ph√°t hi·ªán ph·∫£n h·ªìi t·ª´ ng∆∞·ªùi d√πng trong worker, ƒëang x·ª≠ l√Ω...", level='info')
                        # ƒê√°nh d·∫•u l√† ph·∫£n h·ªìi ƒë·ªÉ worker_router c√≥ th·ªÉ ƒë·ªãnh tuy·∫øn ƒë√∫ng
                        state["is_feedback"] = True
                        log("üíæ [WORKER] ƒê√£ ƒë√°nh d·∫•u state[\"is_feedback\"] = True", level='info')
                        # X·ª≠ l√Ω ph·∫£n h·ªìi tr·ª±c ti·∫øp
                        state = await self.process_human_feedback(state)
                        log("‚úÖ [WORKER] Ho√†n th√†nh x·ª≠ l√Ω feedback, tr·∫£ v·ªÅ state", level='info')
                        return state
                    else:
                        log("‚ùå [WORKER] Tin nh·∫Øn kh√¥ng ph·∫£i l√† feedback, ti·∫øp t·ª•c x·ª≠ l√Ω b√¨nh th∆∞·ªùng", level='info')
                except Exception as e:
                    log(f"‚ö†Ô∏è [WORKER] L·ªói khi ki·ªÉm tra feedback: {str(e)}", level='error')
            else:
                log("‚ö†Ô∏è [WORKER] Kh√¥ng c√≥ human_feedback_agent!", level='warning')
        else:
            log("üí¨ [WORKER] Kh√¥ng c√≥ tin nh·∫Øn ho·∫∑c tin nh·∫Øn cu·ªëi kh√¥ng ph·∫£i HumanMessage", level='info')
                
        # N·∫øu kh√¥ng ph·∫£i ph·∫£n h·ªìi, ti·∫øp t·ª•c x·ª≠ l√Ω b√¨nh th∆∞·ªùng
        
        # Create or update system message with task information
        system_message = f"""
        B·∫°n l√† m·ªôt tr·ª£ l√Ω AI th√¥ng minh c√≥ th·ªÉ s·ª≠ d·ª•ng nhi·ªÅu c√¥ng c·ª• v√† t√°c t·ª≠ chuy√™n bi·ªát ƒë·ªÉ ho√†n th√†nh nhi·ªám v·ª•.
        B·∫°n c√≥ th·ªÉ ti·∫øp t·ª•c l√†m vi·ªác v·ªõi m·ªôt nhi·ªám v·ª• cho ƒë·∫øn khi ho√†n th√†nh ho·∫∑c c·∫ßn th√™m th√¥ng tin t·ª´ ng∆∞·ªùi d√πng.
        
        B·∫°n c√≥ quy·ªÅn truy c·∫≠p v√†o c√°c t√°c t·ª≠ chuy√™n bi·ªát sau:
        1. Filesystem Agent: S·ª≠ d·ª•ng khi c·∫ßn t√¨m ki·∫øm, li·ªát k√™ ho·∫∑c qu·∫£n l√Ω t·ªáp v√† th∆∞ m·ª•c theo t√™n file.
        2. RAG Agent: S·ª≠ d·ª•ng khi c·∫ßn t√¨m ki·∫øm t√†i li·ªáu theo n·ªôi dung ho·∫∑c ng·ªØ nghƒ©a.
        3. Metadata Agent: S·ª≠ d·ª•ng khi c·∫ßn t·∫°o ho·∫∑c qu·∫£n l√Ω metadata cho t√†i li·ªáu.
        4. Text Extraction Agent: S·ª≠ d·ª•ng khi c·∫ßn tr√≠ch xu·∫•t vƒÉn b·∫£n t·ª´ c√°c t·ªáp PDF, Word ho·∫∑c PowerPoint.
        5. File Classification Agent: S·ª≠ d·ª•ng khi c·∫ßn ph√¢n lo·∫°i n·ªôi dung t√†i li·ªáu.
        
        B·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng nhi·ªÅu t√°c t·ª≠ trong c√πng m·ªôt nhi·ªám v·ª• n·∫øu c·∫ßn thi·∫øt.
        V√≠ d·ª•: T√¨m t·ªáp v·ªõi Filesystem Agent, sau ƒë√≥ tr√≠ch xu·∫•t n·ªôi dung v·ªõi Text Extraction Agent.
        
        H√£y ph√¢n t√≠ch y√™u c·∫ßu c·ªßa ng∆∞·ªùi d√πng v√† quy·∫øt ƒë·ªãnh s·ª≠ d·ª•ng t√°c t·ª≠ n√†o ho·∫∑c k·∫øt h·ª£p c√°c t√°c t·ª≠ ƒë·ªÉ ho√†n th√†nh nhi·ªám v·ª•.
        """
        
        # Add feedback if available
        if state.get("feedback_on_work"):
            system_message += f"""
        
Tr∆∞·ªõc ƒë√≥, b·∫°n ƒë√£ th·ª≠ gi·∫£i quy·∫øt nhi·ªám v·ª• nh∆∞ng ch∆∞a ho√†n th√†nh. ƒê√¢y l√† ph·∫£n h·ªìi:
{state['feedback_on_work']}

H√£y ƒëi·ªÅu ch·ªânh c√°ch ti·∫øp c·∫≠n c·ªßa b·∫°n d·ª±a tr√™n ph·∫£n h·ªìi n√†y.
        """
        
        # Add system message if not already present
        found_system_message = False
        messages = state["messages"]
        for i, message in enumerate(messages):
            if isinstance(message, SystemMessage):
                messages[i] = SystemMessage(content=system_message)
                found_system_message = True
                break
        
        if not found_system_message:
            state["messages"] = [SystemMessage(content=system_message)] + state["messages"]
        
        # Store original query if not already stored
        if not state.get("original_query"):
            for message in state["messages"]:
                if isinstance(message, HumanMessage):
                    state["original_query"] = message.content
                    break
        
        # Analyze the query to determine next steps
        last_message = state["messages"][-1]
        if not isinstance(last_message, HumanMessage):
            # If the last message is not from a human, we're in a continuation
            # Just return the state for routing
            return state
            
        # S·ª≠ d·ª•ng LLM ƒë·ªÉ l·∫≠p k·∫ø ho·∫°ch s·ª≠ d·ª•ng agent
        query = last_message.content
        
        try:
            # T·∫°o prompt cho LLM
            planning_prompt = f"""
            B·∫°n l√† m·ªôt h·ªá th·ªëng ƒëi·ªÅu ph·ªëi c√°c agent AI chuy√™n bi·ªát. D·ª±a tr√™n y√™u c·∫ßu c·ªßa ng∆∞·ªùi d√πng, h√£y l·∫≠p k·∫ø ho·∫°ch s·ª≠ d·ª•ng c√°c agent ph√π h·ª£p.
            
            Y√™u c·∫ßu c·ªßa ng∆∞·ªùi d√πng: "{query}"
            
            C√°c agent c√≥ s·∫µn:
            1. filesystem - T√¨m ki·∫øm, li·ªát k√™ v√† qu·∫£n l√Ω t·ªáp v√† th∆∞ m·ª•c
            2. metadata - T·∫°o v√† qu·∫£n l√Ω metadata cho t√†i li·ªáu
            3. text_extraction - Tr√≠ch xu·∫•t vƒÉn b·∫£n t·ª´ t·ªáp PDF, Word ho·∫∑c PowerPoint
            4. file_classification - Ph√¢n lo·∫°i n·ªôi dung t√†i li·ªáu
            
            H√£y l·∫≠p k·∫ø ho·∫°ch s·ª≠ d·ª•ng c√°c agent. ƒê·∫ßu ti√™n, tr·∫£ l·ªùi v·ªõi danh s√°ch c√°c agent c·∫ßn s·ª≠ d·ª•ng theo th·ª© t·ª±, ch·ªâ li·ªát k√™ t√™n c√°c agent (filesystem, metadata, text_extraction, file_classification), c√°ch nhau b·∫±ng d·∫•u ph·∫©y.
            
            Sau ƒë√≥, vi·∫øt m·ªôt ƒëo·∫°n vƒÉn ng·∫Øn gi·∫£i th√≠ch k·∫ø ho·∫°ch c·ªßa b·∫°n b·∫±ng ti·∫øng Vi·ªát.
            """
            
            # S·ª≠ d·ª•ng LLM ƒë·ªÉ l·∫≠p k·∫ø ho·∫°ch
            from config.llm import gemini
            response = await gemini.ainvoke(planning_prompt)
            plan_response = response.content.strip()
            
            # T√°ch ph·∫ßn danh s√°ch agent v√† ph·∫ßn gi·∫£i th√≠ch
            parts = plan_response.split('\n', 1)
            agent_list = parts[0].strip().lower()
            plan_message = parts[1].strip() if len(parts) > 1 else f"T√¥i s·∫Ω gi√∫p b·∫°n v·ªõi y√™u c·∫ßu: '{query}'."
            
            # X·ª≠ l√Ω danh s√°ch agent
            needed_agents = []
            valid_agents = ["filesystem", "metadata", "text_extraction", "file_classification"]
            
            for agent in valid_agents:
                if agent in agent_list:
                    needed_agents.append(agent)
            
            if not needed_agents:
                # M·∫∑c ƒë·ªãnh s·ª≠ d·ª•ng filesystem n·∫øu kh√¥ng c√≥ agent n√†o ƒë∆∞·ª£c ch·ªçn
                needed_agents.append("filesystem")
                plan_message += "\nT√¥i s·∫Ω b·∫Øt ƒë·∫ßu v·ªõi Filesystem Agent ƒë·ªÉ t√¨m ki·∫øm th√¥ng tin."
            
            print(f"K·∫ø ho·∫°ch agent: {needed_agents}")
            
        except Exception as e:
            print(f"L·ªói khi l·∫≠p k·∫ø ho·∫°ch s·ª≠ d·ª•ng agent: {e}")
            # S·ª≠ d·ª•ng m·∫∑c ƒë·ªãnh n·∫øu c√≥ l·ªói
            needed_agents = ["filesystem"]
            plan_message = f"T√¥i s·∫Ω gi√∫p b·∫°n v·ªõi y√™u c·∫ßu: '{query}'. T√¥i s·∫Ω b·∫Øt ƒë·∫ßu v·ªõi Filesystem Agent ƒë·ªÉ t√¨m ki·∫øm th√¥ng tin."
        
        # Update state with the plan
        state["current_agents"] = needed_agents
        state["messages"].append(AIMessage(content=plan_message))
        
        return state
        
    # Removed duplicate worker_router method
    
    def determine_agent(self, state: AgentState) -> str:
        """
        Determine which agent to use next based on the current_agents list.
        """
        if not state["current_agents"]:
            log("Kh√¥ng c√≤n agent n√†o trong danh s√°ch, chuy·ªÉn sang evaluator")
            return "evaluator"
        
        # Ki·ªÉm tra xem agent ti·∫øp theo ƒë√£ ƒë∆∞·ª£c s·ª≠ d·ª•ng ch∆∞a
        next_agent = state["current_agents"][0]
        used_tools = state.get("used_tools", [])
        
        # N·∫øu agent ti·∫øp theo ƒë√£ ƒë∆∞·ª£c s·ª≠ d·ª•ng, b·ªè qua v√† ki·ªÉm tra agent ti·∫øp theo
        if next_agent in used_tools:
            log(f"Agent {next_agent} ƒë√£ ƒë∆∞·ª£c s·ª≠ d·ª•ng, b·ªè qua")
            # X√≥a agent n√†y kh·ªèi danh s√°ch
            state["current_agents"] = state["current_agents"][1:]
            # G·ªçi ƒë·ªá quy ƒë·ªÉ t√¨m agent ti·∫øp theo
            return self.determine_agent(state)
        
        # L·∫•y agent ti·∫øp theo t·ª´ danh s√°ch
        log(f"S·ª≠ d·ª•ng agent {next_agent} ti·∫øp theo")
        
        # X√≥a n√≥ kh·ªèi danh s√°ch ƒë·ªÉ kh√¥ng s·ª≠ d·ª•ng l·∫°i
        state["current_agents"] = state["current_agents"][1:]
        
        # Ki·ªÉm tra n·∫øu l√† RAG agent
        
        if next_agent == "data_analysis":
            return "data_analysis"
        elif next_agent == "rag":
            return "rag_agent"
        return next_agent
        
    async def _validate_agent_sequence(self, state: AgentState) -> AgentState:
        """
        Validate and fix the agent sequence to ensure proper workflow, especially for metadata operations.
        
        Args:
            state: Current agent state with planned agents
            
        Returns:
            Updated state with corrected agent sequence
        """
        current_agents = state.get("current_agents", [])
        log(f"Validating agent sequence: {current_agents}")
        
        # If no agents or only one agent, no need to validate sequence
        if len(current_agents) <= 1:
            return state
            
        # Check if metadata agent is included in the plan
        if "metadata" in current_agents:
            log("Ph√°t hi·ªán metadata agent trong k·∫ø ho·∫°ch, ki·ªÉm tra th·ª© t·ª±")
            
            # Define the correct sequence for metadata operations
            metadata_workflow = []
            
            # Step 1: First agent should be filesystem or rag (search agent)
            if "filesystem" in current_agents or "rag" in current_agents:
                search_agent = "rag" if "rag" in current_agents else "filesystem"
                metadata_workflow.append(search_agent)
                log(f"S·ª≠ d·ª•ng {search_agent} l√†m agent t√¨m ki·∫øm trong workflow metadata")
            else:
                # If no search agent is specified, add rag as default
                metadata_workflow.append("rag")
                log("Th√™m rag agent v√†o ƒë·∫ßu workflow v√¨ kh√¥ng t√¨m th·∫•y agent t√¨m ki·∫øm")
                # Also add it to current_agents to ensure it's included in the final sequence
                current_agents.append("rag")
                
            # Step 2: Add text_extraction agent
            metadata_workflow.append("text_extraction")
            
            # Step 3: Add file_classification agent
            metadata_workflow.append("file_classification")
            
            # Step 4: Finally add metadata agent
            metadata_workflow.append("metadata")
            
            # Create a new agent sequence with correct order
            # Remove any agents that are already in the metadata workflow
            new_agents = [agent for agent in current_agents if agent not in metadata_workflow]
            
            # Add the metadata workflow agents in correct order
            new_agents.extend([agent for agent in metadata_workflow if agent in current_agents])
            
            # If metadata is in the plan but required agents are missing, add them
            if "metadata" in new_agents:
                metadata_index = new_agents.index("metadata")
                missing_agents = []
                
                # Check for missing required agents
                if "text_extraction" not in new_agents:
                    missing_agents.append("text_extraction")
                    log("Th√™m text_extraction agent v√†o workflow v√¨ c·∫ßn thi·∫øt cho metadata")
                    
                if "file_classification" not in new_agents:
                    missing_agents.append("file_classification")
                    log("Th√™m file_classification agent v√†o workflow v√¨ c·∫ßn thi·∫øt cho metadata")
                
                # Insert missing agents in the correct order before metadata
                for agent in reversed(missing_agents):
                    new_agents.insert(metadata_index, agent)
            
            # Update the state with the corrected sequence
            if new_agents != current_agents:
                log(f"ƒê√£ ƒëi·ªÅu ch·ªânh th·ª© t·ª± agent: {current_agents} -> {new_agents}")
                # state["chain_of_thought"].append(f"ƒêi·ªÅu ch·ªânh th·ª© t·ª± agent ƒë·ªÉ ƒë·∫£m b·∫£o workflow ch√≠nh x√°c: {', '.join(new_agents)}")
                state["current_agents"] = new_agents
        
        return state
        
    async def evaluator(self, state: AgentState) -> AgentState:
        """
        Evaluator node that assesses if the task has been completed successfully.
        """
        # Ki·ªÉm tra xem c√≥ ph·∫£n h·ªìi ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω kh√¥ng
        if state.get("feedback_processed", False):
            # N·∫øu ƒë√£ x·ª≠ l√Ω ph·∫£n h·ªìi, ƒë√°nh d·∫•u nhi·ªám v·ª• ho√†n th√†nh
            log("Ph·∫£n h·ªìi ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω, ƒë√°nh d·∫•u nhi·ªám v·ª• ho√†n th√†nh", level='info')
            state["task_complete"] = True
            state["success_criteria_met"] = True
            return state
            
        # Format the conversation history
        conversation = "L·ªãch s·ª≠ h·ªôi tho·∫°i:\n\n"
        for message in state["messages"]:
            if isinstance(message, HumanMessage):
                conversation += f"Ng∆∞·ªùi d√πng: {message.content}\n"
            elif isinstance(message, AIMessage):
                conversation += f"Tr·ª£ l√Ω: {message.content}\n"
            elif isinstance(message, SystemMessage):
                # Skip system messages in the conversation history
                pass
        
        # Get the original query
        original_query = ""
        for message in state["messages"]:
            if isinstance(message, HumanMessage):
                original_query = message.content
                break
        
        # Get the last response
        last_response = ""
        for message in reversed(state["messages"]):
            if isinstance(message, AIMessage):
                last_response = message.content
                break
        
        # Create evaluator prompt
        evaluator_prompt = f"""
        B·∫°n l√† m·ªôt ƒë√°nh gi√° vi√™n x√°c ƒë·ªãnh xem m·ªôt nhi·ªám v·ª• ƒë√£ ƒë∆∞·ª£c ho√†n th√†nh th√†nh c√¥ng hay ch∆∞a.
        ƒê√°nh gi√° ph·∫£n h·ªìi cu·ªëi c√πng c·ªßa Tr·ª£ l√Ω d·ª±a tr√™n y√™u c·∫ßu ban ƒë·∫ßu c·ªßa ng∆∞·ªùi d√πng.
        
        Y√™u c·∫ßu ban ƒë·∫ßu c·ªßa ng∆∞·ªùi d√πng l√†:
        {original_query}
        
        L·ªãch s·ª≠ h·ªôi tho·∫°i:
        {conversation}
        
        Ph·∫£n h·ªìi cu·ªëi c√πng c·ªßa Tr·ª£ l√Ω:
        {last_response}
        
        H√£y ƒë√°nh gi√° xem nhi·ªám v·ª• ƒë√£ ho√†n th√†nh ch∆∞a v√† li·ªáu c√≥ c·∫ßn th√™m th√¥ng tin t·ª´ ng∆∞·ªùi d√πng kh√¥ng.
        N·∫øu nhi·ªám v·ª• ch∆∞a ho√†n th√†nh, h√£y gi·∫£i th√≠ch t·∫°i sao v√† ƒë·ªÅ xu·∫•t c√°ch ti·∫øp c·∫≠n kh√°c.
        """
        
        # For now, we'll use a simple heuristic to determine if the task is complete
        # In a real implementation, you would use the LLM to evaluate this
        
        # Check if we've used at least one agent
        task_complete = len(state.get("used_tools", [])) > 0
        
        # Check if the last response contains certain keywords indicating completion
        completion_indicators = ["ƒë√£ ho√†n th√†nh", "ƒë√£ t√¨m th·∫•y", "k·∫øt qu·∫£", "ƒë√£ x·ª≠ l√Ω", "ƒë√£ tr√≠ch xu·∫•t", "ƒë√£ ph√¢n lo·∫°i"]
        for indicator in completion_indicators:
            if indicator in last_response.lower():
                task_complete = True
                break
        
        # Check if the response addresses the original query
        query_keywords = original_query.lower().split()
        response_keywords = last_response.lower().split()
        common_keywords = set(query_keywords).intersection(set(response_keywords))
        if len(common_keywords) > 2:  # If there are at least 3 common keywords
            task_complete = True
        
        # Set the evaluation results
        feedback = ""
        if task_complete:
            feedback = "Nhi·ªám v·ª• ƒë√£ ƒë∆∞·ª£c ho√†n th√†nh th√†nh c√¥ng. Ph·∫£n h·ªìi ƒë√£ gi·∫£i quy·∫øt y√™u c·∫ßu c·ªßa ng∆∞·ªùi d√πng."
            state["success_criteria_met"] = True
        else:
            feedback = "Nhi·ªám v·ª• ch∆∞a ho√†n th√†nh. C·∫ßn s·ª≠ d·ª•ng th√™m t√°c t·ª≠ ho·∫∑c c√¥ng c·ª• ƒë·ªÉ gi·∫£i quy·∫øt y√™u c·∫ßu c·ªßa ng∆∞·ªùi d√πng."
            state["success_criteria_met"] = False
        
        # Add the feedback to the state
        state["feedback_on_work"] = feedback
        
        # Add evaluator message to the conversation
        state["messages"].append(AIMessage(content=f"[ƒê√°nh gi√° n·ªôi b·ªô: {feedback}]"))
        
        return state
    
    def route_based_on_evaluation(self, state: AgentState) -> str:
        """
        Determine next steps based on the evaluator's assessment.
        """
        if state["success_criteria_met"] or state["require_user_input"]:
            return "complete"
        else:
            # If not complete and we don't need user input, try again with other agents
            return "continue"
    async def route_query(self, state: AgentState) -> AgentState:
        """
        Route the query to the appropriate agent.
        """
        # Just pass through the state, the routing is done in determine_agent
        return state
    
    async def _determine_search_intent(self, query: str) -> str:
        """
        X√°c ƒë·ªãnh m·ª•c ƒë√≠ch t√¨m ki·∫øm d·ª±a tr√™n c√¢u truy v·∫•n.
        
        Args:
            query: C√¢u truy v·∫•n c·ªßa ng∆∞·ªùi d√πng
            
        Returns:
            "filesystem" n·∫øu l√† t√¨m ki·∫øm theo t√™n file, "rag" n·∫øu t√¨m ki·∫øm theo n·ªôi dung
        """
        query = query.lower()
        
        # Keywords indicating file name search
        file_name_keywords = [
            "t√™n file", "t√¨m file", "ƒë∆∞·ªùng d·∫´n", "th∆∞ m·ª•c",
            "trong folder", "trong th∆∞ m·ª•c", "t√¨m ki·∫øm file", "file t√™n"
        ]
        
        # Keywords indicating content search
        content_keywords = [
            "n·ªôi dung", "c√≥ ch·ª©a", "li√™n quan ƒë·∫øn", "n√≥i v·ªÅ",
            "th√¥ng tin v·ªÅ", "t√¨m ki·∫øm th√¥ng tin", "t√†i li·ªáu v·ªÅ", "vƒÉn b·∫£n"
        ]
        
        # Check for explicit content search
        if any(keyword in query for keyword in content_keywords):
            log(f"Ph√°t hi·ªán t√¨m ki·∫øm theo n·ªôi dung: {query}")
            return "rag"
            
        # Check for explicit file search
        if any(keyword in query for keyword in file_name_keywords):
            log(f"Ph√°t hi·ªán t√¨m ki·∫øm theo t√™n file: {query}")
            return "filesystem"
            
        # Default to content search for natural language queries
        if len(query.split()) > 3:  # Longer queries are likely content searches
            log(f"M·∫∑c ƒë·ªãnh t√¨m ki·∫øm theo n·ªôi dung cho c√¢u d√†i: {query}")
            return "rag"
            
        # Default to file system search for short queries
        log(f"M·∫∑c ƒë·ªãnh t√¨m ki·∫øm theo t√™n file cho c√¢u ng·∫Øn: {query}")
        return "filesystem"

    async def run_filesystem_agent(self, state: AgentState) -> AgentState:
        """
        Run the filesystem agent on the current query.
        """
        try:
            # Get the last message that's not from an agent
            query = ""
            for message in reversed(state["messages"]):
                if isinstance(message, HumanMessage):
                    query = message.content
                    break

            log(f"Running FilesystemAgent with query: {query}")

            # Track that we're using this agent
            if "used_tools" not in state:
                state["used_tools"] = []
            state["used_tools"].append("filesystem")

            # Get the filesystem agent graph
            filesystem_agent = self.agents["filesystem"]

            # Run the agent with the query and wait for completion
            config = {"configurable": {"thread_id": self.session_id}}
            log("Waiting for FilesystemAgent to complete...")
            response = await filesystem_agent.graph.ainvoke({"messages": state["messages"]}, config=config)
            log("FilesystemAgent completed")

            # Get the agent's response
            agent_response = None
            for message in reversed(response["messages"]):
                if isinstance(message, AIMessage):
                    agent_response = message
                    break

            if not agent_response or not agent_response.content.strip():
                # If there's no response or it's empty, create a default one
                agent_response = AIMessage(content="T√¥i ƒë√£ t√¨m ki·∫øm nh∆∞ng kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£ ph√π h·ª£p.")

            # Add the agent's response to the state
            response_content = f"üóÇÔ∏è {agent_response.content}"
            print(f"FilesystemAgent response: {response_content}")
            log(f"FilesystemAgent response: {response_content}")
            state["messages"].append(AIMessage(content=response_content))
            
            # Store result in agent_results
            if "agent_results" not in state:
                state["agent_results"] = {}
            state["agent_results"]["filesystem"] = agent_response.content
            
            # Check if filesystem agent found any results
            if "Kh√¥ng t√¨m th·∫•y" in agent_response.content or "kh√¥ng bi·∫øt" in agent_response.content.lower() or "kh√¥ng t√¨m th·∫•y" in agent_response.content.lower():
                print("Filesystem agent didn't find results. Trying RAG agent...")
                
                # Call RAG agent for content-based search
                rag_agent = self.agents["rag"]
                rag_result = await rag_agent.invoke(query, self.session_id)
                
                if isinstance(rag_result, dict) and 'content' in rag_result:
                    # Add RAG response to messages
                    rag_content = f"üîç T√¨m ki·∫øm theo n·ªôi dung file:\n\n{rag_result['content']}"
                    state["messages"].append(AIMessage(content=rag_content))
                    
                    # Store RAG result
                    state["agent_results"]["rag"] = rag_result['content']
                    
                    # Add RAG to used tools
                    if "rag" not in state["used_tools"]:
                        state["used_tools"].append("rag")
                        
                    print(f"RAG agent found results: {rag_content[:100]}...")
            
            # Analyze the response to suggest next agent
            print("Analyzing response to suggest next agent...")
            next_agent = await self._suggest_next_agent(agent_response.content, state)
            if next_agent and next_agent not in state["current_agents"]:
                print(f"Adding {next_agent} to current_agents")
                state["current_agents"].append(next_agent)
            else:
                print(f"No additional agent suggested or already in use")

            return state

        except Exception as e:
            print(f"Error running filesystem agent: {e}")
            # Add an error message to the state
            error_message = f"Xin l·ªói, t√¥i g·∫∑p l·ªói khi t√¨m ki·∫øm t·ªáp: {str(e)}"
            state["messages"].append(AIMessage(content=error_message))
            return state
        
    async def run_data_analysis_agent(self, state: AgentState) -> AgentState:
        try:
            log("Running DataAnalysisAgent...")
            
            # Track that we're using this agent
            if "used_tools" not in state:
                state["used_tools"] = []
            state["used_tools"].append("data_analysis")
            
            # Get extracted contents from previous agents
            extracted_contents = state.get("extracted_contents", {})
            
            if not extracted_contents:
                # Try to get from text_extraction_results if not in extracted_contents
                if "text_extraction_results" in state:
                    extracted_contents = state["text_extraction_results"]
                    state["extracted_contents"] = extracted_contents
                    log(f"Found extracted contents from text_extraction_results: {len(extracted_contents)} files")
            
            if not extracted_contents:
                error_msg = "‚ùå Kh√¥ng t√¨m th·∫•y n·ªôi dung ƒë√£ tr√≠ch xu·∫•t ƒë·ªÉ ph√¢n t√≠ch"
                state["messages"].append(AIMessage(content=error_msg))
                return state
            
            # Get analysis metrics from the original query
            original_query = state.get("original_query", "")
            
            # Use DataAnalysisAgent to determine metrics to analyze
            data_analysis_agent = self.agents["data_analysis"]
            metrics_response = await data_analysis_agent.invoke(original_query, self.session_id)
            
            if isinstance(metrics_response, dict) and "metrics" in metrics_response:
                metrics = metrics_response["metrics"]
                log(f"Analysis metrics determined: {metrics}")
            else:
                # Default metrics for financial comparison
                metrics = ["doanh thu", "l·ª£i nhu·∫≠n", "chi ph√≠"]
                log(f"Using default metrics: {metrics}")
            
            # Store metrics in state
            state["analysis_metrics"] = metrics
            
            # Perform data analysis
            log(f"Analyzing {len(extracted_contents)} files with metrics: {metrics}")
            analysis_results = await data_analysis_agent.analyze_contents(extracted_contents, metrics)
            
            # Store analysis results in state
            state["analysis_results"] = analysis_results
            
            # Format the response
            if analysis_results and "report" in analysis_results:
                report = analysis_results["report"]
                response_content = f"üìä K·∫øt qu·∫£ ph√¢n t√≠ch so s√°nh d·ªØ li·ªáu:\n\n{report}"
            else:
                response_content = f"üìä ƒê√£ ho√†n th√†nh ph√¢n t√≠ch {len(extracted_contents)} files"
            
            # Add response to messages
            state["messages"].append(AIMessage(content=response_content))
            
            # Store result in agent_results
            if "agent_results" not in state:
                state["agent_results"] = {}
            state["agent_results"]["data_analysis"] = analysis_results
            
            # Add to chain of thought
            if "chain_of_thought" not in state:
                state["chain_of_thought"] = []
            state["chain_of_thought"].append(f"üìä ƒê√£ ph√¢n t√≠ch v√† so s√°nh d·ªØ li·ªáu t·ª´ {len(extracted_contents)} files")
            
            log(f"DataAnalysisAgent completed: analyzed {len(extracted_contents)} files")
            return state
        
        except Exception as e:
            log(f"Error in data analysis agent: {str(e)}", level='error')
            error_message = f"‚ùå L·ªói khi ph√¢n t√≠ch d·ªØ li·ªáu: {str(e)}"
            state["messages"].append(AIMessage(content=error_message))
            return state

    async def _suggest_next_agent(self, response_content: str, state: AgentState) -> str:
        """
        S·ª≠ d·ª•ng LLM ƒë·ªÉ ph√¢n t√≠ch ph·∫£n h·ªìi c·ªßa agent v√† ƒë·ªÅ xu·∫•t agent ti·∫øp theo.
        
        Args:
            response_content: N·ªôi dung ph·∫£n h·ªìi c·ªßa agent
            state: Tr·∫°ng th√°i hi·ªán t·∫°i
            
        Returns:
            T√™n c·ªßa agent ti·∫øp theo, ho·∫∑c None n·∫øu kh√¥ng c√≥ ƒë·ªÅ xu·∫•t
        """
        # L·∫•y y√™u c·∫ßu ban ƒë·∫ßu c·ªßa ng∆∞·ªùi d√πng
        original_query = ""
        for message in state["messages"]:
            if isinstance(message, HumanMessage):
                original_query = message.content
                break
        
        # Danh s√°ch c√°c agent ƒë√£ s·ª≠ d·ª•ng
        used_agents = state.get("used_tools", [])
        
        # N·∫øu ƒë√£ s·ª≠ d·ª•ng qu√° nhi·ªÅu agent, kh√¥ng ƒë·ªÅ xu·∫•t th√™m
        if len(used_agents) >= 3:
            print("ƒê√£ s·ª≠ d·ª•ng qu√° nhi·ªÅu agent, kh√¥ng ƒë·ªÅ xu·∫•t th√™m")
            return None
        
        # T·∫°o prompt cho LLM
        prompt = f"""
        B·∫°n l√† m·ªôt h·ªá th·ªëng ƒëi·ªÅu ph·ªëi c√°c agent AI chuy√™n bi·ªát. D·ª±a tr√™n th√¥ng tin sau, h√£y quy·∫øt ƒë·ªãnh agent n√†o n√™n ƒë∆∞·ª£c s·ª≠ d·ª•ng ti·∫øp theo.
        
        Y√™u c·∫ßu ban ƒë·∫ßu c·ªßa ng∆∞·ªùi d√πng: "{original_query}"
        
        Ph·∫£n h·ªìi m·ªõi nh·∫•t t·ª´ agent: "{response_content}"
        
        C√°c agent ƒë√£ ƒë∆∞·ª£c s·ª≠ d·ª•ng: {used_agents}
        
        C√°c agent c√≥ s·∫µn:
        1. filesystem - T√¨m ki·∫øm, li·ªát k√™ v√† qu·∫£n l√Ω t·ªáp v√† th∆∞ m·ª•c
        2. metadata - T·∫°o v√† qu·∫£n l√Ω metadata cho t√†i li·ªáu
        3. text_extraction - Tr√≠ch xu·∫•t vƒÉn b·∫£n t·ª´ t·ªáp PDF, Word ho·∫∑c PowerPoint
        4. file_classification - Ph√¢n lo·∫°i n·ªôi dung t√†i li·ªáu
        
        QUAN TR·ªåNG: Ch·ªâ ƒë·ªÅ xu·∫•t m·ªôt agent ti·∫øp theo n·∫øu th·ª±c s·ª± c·∫ßn thi·∫øt d·ª±a tr√™n y√™u c·∫ßu ban ƒë·∫ßu v√† ph·∫£n h·ªìi hi·ªán t·∫°i.
        N·∫øu agent hi·ªán t·∫°i ƒë√£ gi·∫£i quy·∫øt ƒë∆∞·ª£c v·∫•n ƒë·ªÅ ho·∫∑c kh√¥ng c·∫ßn agent kh√°c, h√£y tr·∫£ l·ªùi "none".
        
        Tr·∫£ l·ªùi ch·ªâ v·ªõi t√™n c·ªßa agent (filesystem, metadata, text_extraction, file_classification) ho·∫∑c "none" n·∫øu kh√¥ng c·∫ßn agent n√†o n·ªØa.
        """
        
        try:
            # S·ª≠ d·ª•ng LLM ƒë·ªÉ quy·∫øt ƒë·ªãnh
            from config.llm import gemini
            response = await gemini.ainvoke(prompt)
            suggestion = response.content.strip().lower()
            
            # Ki·ªÉm tra xem c√≥ t·ª´ "none" trong ph·∫£n h·ªìi kh√¥ng
            if "none" in suggestion:
                print("LLM ƒë·ªÅ xu·∫•t kh√¥ng c·∫ßn s·ª≠ d·ª•ng th√™m agent")
                return None
            
            # X·ª≠ l√Ω ph·∫£n h·ªìi
            valid_agents = ["filesystem", "metadata", "text_extraction", "file_classification"]
            
            # Ch·ªâ ƒë·ªÅ xu·∫•t agent ch∆∞a ƒë∆∞·ª£c s·ª≠ d·ª•ng
            for agent in valid_agents:
                if agent in suggestion and agent not in used_agents:
                    print(f"LLM ƒë·ªÅ xu·∫•t s·ª≠ d·ª•ng {agent} ti·∫øp theo")
                    return agent
            
            # Kh√¥ng c√≥ ƒë·ªÅ xu·∫•t h·ª£p l·ªá
            return None
            
        except Exception as e:
            print(f"L·ªói khi ƒë·ªÅ xu·∫•t agent ti·∫øp theo: {e}")
            return None
    
    async def run_rag_agent(self, state: AgentState) -> AgentState:
        """
        Run the RAG agent to search file contents.
        """
        try:
            # Get the last message that's not from an agent
            query = ""
            for message in reversed(state["messages"]):
                if isinstance(message, HumanMessage):
                    query = message.content
                    break

            log(f"Running RAGAgent with query: {query}")

            # Track that we're using this agent
            if "used_tools" not in state:
                state["used_tools"] = []
            state["used_tools"].append("rag")

            # Get the RAG agent
            rag_agent = self.agents["rag"]

            # Run the agent with the query
            log("Searching with RAGAgent...")
            response = await rag_agent.invoke(query, session_id=self.session_id)
            log("RAGAgent search completed")

            # Format the response
            if isinstance(response, dict) and 'content' in response:
                response_content = response['content']
                # Extract file_paths if present for text extraction compatibility
                file_paths = response.get('file_paths', [])
            else:
                response_content = str(response)
                file_paths = []
                
                # N·∫øu RAG tr·∫£ v·ªÅ chu·ªói vƒÉn b·∫£n c√≥ ch·ª©a ƒë∆∞·ªùng d·∫´n file, tr√≠ch xu·∫•t ch√∫ng
                # M·∫´u: "T√¥i ƒë√£ t√¨m th·∫•y c√°c file sau:\n1. C:\path\to\file1.docx\n2. C:\path\to\file2.docx"
                if "\n" in response_content and ("T√¥i ƒë√£ t√¨m th·∫•y" in response_content or "t√¨m th·∫•y c√°c file" in response_content):
                    lines = response_content.split("\n")
                    for line in lines:
                        # T√¨m c√°c d√≤ng c√≥ ƒë∆∞·ªùng d·∫´n file
                        if line.strip().startswith("1.") or line.strip().startswith("2.") or line.strip().startswith("3."):
                            # Tr√≠ch xu·∫•t ƒë∆∞·ªùng d·∫´n file t·ª´ d√≤ng
                            parts = line.strip().split(".", 1)
                            if len(parts) > 1:
                                file_path = parts[1].strip()
                                file_paths.append(file_path)
                    
                    log(f"Extracted {len(file_paths)} file paths from RAG response text: {file_paths}")

            # Add the agent's response to the state with file_paths as additional kwargs if available
            print(f"RAGAgent response: {response_content[:200]}...")
            if file_paths:
                log(f"RAG agent found {len(file_paths)} file paths: {file_paths}")
                state["messages"].append(AIMessage(
                    content=response_content,
                    additional_kwargs={'file_paths': file_paths}
                ))
            else:
                state["messages"].append(AIMessage(content=response_content))
            
            # Store result in agent_results
            if "agent_results" not in state:
                state["agent_results"] = {}
            state["agent_results"]["rag"] = response_content
            
            # L∆∞u ƒë∆∞·ªùng d·∫´n file v√†o state ƒë·ªÉ c√°c agent kh√°c c√≥ th·ªÉ s·ª≠ d·ª•ng
            if file_paths:
                state["processed_files"] = file_paths
                
            return state
            
        except Exception as e:
            log(f"Error in RAG agent: {str(e)}", level='error')
            state["messages"].append(AIMessage(
                content=f"C√≥ l·ªói x·∫£y ra khi t√¨m ki·∫øm n·ªôi dung: {str(e)}"
            ))
            return state

    async def run_metadata_agent(self, state: AgentState) -> AgentState:
        """
        Run the metadata agent on the current query.
        """
        try:
            # Get the last message that's not from an agent
            query = ""
            for message in reversed(state["messages"]):
                if isinstance(message, HumanMessage):
                    query = message.content
                    break

            log(f"Running MetadataAgent with query: {query}")

            # Track that we're using this agent
            if "used_tools" not in state:
                state["used_tools"] = []
            state["used_tools"].append("metadata")

            # Extract file paths from previous agent messages
            file_paths = []
            file_content = None
            file_classification = None
            
            # Ki·ªÉm tra xem c√≥ file paths ƒë√£ ƒë∆∞·ª£c l∆∞u trong state t·ª´ c√°c agent tr∆∞·ªõc ƒë√≥ kh√¥ng
            if "accessible_files" in state:
                file_paths = state["accessible_files"]
                log(f"Found {len(file_paths)} file paths from state: {file_paths}")
            elif "classified_files" in state:
                file_paths = state["classified_files"]
                log(f"Found {len(file_paths)} file paths from classified_files: {file_paths}")
            else:
                # First, look for file paths from RAG or filesystem agents
                for message in reversed(state["messages"]):
                    if isinstance(message, AIMessage):
                        # Check for file_paths in additional_kwargs (from RAG agent)
                        if hasattr(message, '_additional_kwargs') and 'file_paths' in message._additional_kwargs:
                            paths = message._additional_kwargs['file_paths']
                            if paths and isinstance(paths, list) and len(paths) > 0:
                                file_paths = paths
                                log(f"Found {len(file_paths)} file paths from RAG agent: {file_paths}")
                                break
                        
                        # Check for file paths in message content
                        if "T√¥i ƒë√£ t√¨m th·∫•y file:" in message.content:
                            import re
                            # T√¨m m·ªôt file path
                            file_pattern = r'T√¥i ƒë√£ t√¨m th·∫•y file:\s*([A-Z]:\\[^\s\n\r]+)'
                            file_matches = re.findall(file_pattern, message.content)
                            if file_matches:
                                file_paths = file_matches
                                log(f"Found {len(file_paths)} file paths from message content: {file_paths}")
                                break
                            
                            # T√¨m nhi·ªÅu file paths t·ª´ danh s√°ch ƒë√°nh s·ªë
                            numbered_pattern = r'\d+\. ([A-Z]:\\[^\s\n\r]+)'
                            numbered_matches = re.findall(numbered_pattern, message.content)
                            if numbered_matches:
                                file_paths = numbered_matches
                                log(f"Found {len(file_paths)} file paths from numbered list: {file_paths}")
                                break
            
            # Then, look for extracted content from text extraction agent
            for message in reversed(state["messages"]):
                if not isinstance(message, AIMessage):
                    continue
                    
                # Check if this is a text extraction agent message
                is_extraction_msg = ("üìÑ" in message.content or "[Text Extraction Agent]:" in message.content or 
                                   "N·ªôi dung tr√≠ch xu·∫•t:" in message.content or
                                   "K·∫øt qu·∫£ tr√≠ch xu·∫•t t·ª´ file" in message.content)
                
                if is_extraction_msg:
                    log(f"Found text extraction agent message")
                    
                    # Try to extract content using different patterns
                    content = None
                    
                    # Pattern 1: Look for content after "N·ªôi dung tr√≠ch xu·∫•t:"
                    if "N·ªôi dung tr√≠ch xu·∫•t:" in message.content:
                        parts = message.content.split("N·ªôi dung tr√≠ch xu·∫•t:", 1)
                        if len(parts) > 1:
                            content = parts[1].strip()
                    
                    # Pattern 2: Look for content after the file path
                    elif "K·∫øt qu·∫£ tr√≠ch xu·∫•t t·ª´ file" in message.content:
                        # Find the first empty line after the header
                        lines = message.content.split('\n')
                        content_lines = []
                        found_header = False
                        
                        for line in lines:
                            if not found_header and ("K·∫øt qu·∫£ tr√≠ch xu·∫•t t·ª´ file" in line or "N·ªôi dung tr√≠ch xu·∫•t:" in line):
                                found_header = True
                                continue
                            if found_header and line.strip():
                                content_lines.append(line.strip())
                        
                        if content_lines:
                            content = '\n'.join(content_lines).strip()
                    
                    # If we found content, clean it up and store it
                    if content:
                        # Clean up any metadata or additional text
                        if "\n\n" in content:
                            content = content.split("\n\n")[0].strip()
                        
                        # Remove any trailing metadata or instructions
                        stop_phrases = [
                            "\nL∆∞u √Ω:", "\nGhi ch√∫:", "\nTh√¥ng tin th√™m:",
                            "\nNote:", "\nMetadata:", "\n---"
                        ]
                        
                        for phrase in stop_phrases:
                            if phrase in content:
                                content = content.split(phrase, 1)[0].strip()
                        
                        file_content = content
                        log(f"Extracted content length: {len(file_content)} characters")
                        log(f"Content preview: {file_content[:200]}...")
                        break
            
            # Finally, look for classification from file classification agent
            for message in reversed(state["messages"]):
                if isinstance(message, AIMessage) and ("üè∑Ô∏è" in message.content or "[File Classification Agent]:" in message.content or "K·∫øt qu·∫£ ph√¢n lo·∫°i file" in message.content or "Gi√°o d·ª•c" in message.content):
                    log("Found file classification agent message")
                    # Look for classification label in different possible formats
                    import re
                    
                    # Format 1: "Phƒêi·ªÅu ch·ªânh th·ª© t·ª± agent ƒë·ªÉ ƒë·∫£m b·∫£o workflow ch√≠nh x√°c:n lo·∫°i: Gi√°o d·ª•c"
                    label_pattern1 = r'Ph√¢n lo·∫°i:\s*([^\n\r]+)'
                    # Format 2: "K·∫øt qu·∫£ ph√¢n lo·∫°i file ...: Gi√°o d·ª•c"
                    label_pattern2 = r'K·∫øt qu·∫£ ph√¢n lo·∫°i file[^:]*:\s*([^\n\r]+)'
                    # Format 3: Just the label itself (e.g. "Gi√°o d·ª•c")
                    
                    content = message.content
                    log(f"Analyzing classification content: {content}")
                    
                    # First try the standard patterns
                    label_matches = re.findall(label_pattern1, content)
                    if not label_matches:
                        label_matches = re.findall(label_pattern2, content)
                    
                    # If still no match, check if the content itself is just the label
                    if not label_matches and len(content.strip().split()) <= 3:
                        # If content is just 1-3 words, it might be just the label
                        label_matches = [content.strip()]
                    
                    if label_matches:
                        file_classification = label_matches[0].strip()
                        log(f"Found classification label: {file_classification}")
                        break
            
            # Prepare the metadata parameters
            metadata_params = {}
            
            # X·ª≠ l√Ω nhi·ªÅu file paths
            if file_paths:
                import os
                # ƒê·∫£m b·∫£o file_paths ch·ªâ ch·ª©a c√°c ƒë∆∞·ªùng d·∫´n h·ª£p l·ªá v√† duy nh·∫•t
                valid_file_paths = []
                for path in file_paths:
                    if path and isinstance(path, str) and os.path.exists(path) and path not in valid_file_paths:
                        valid_file_paths.append(path)
                
                # Log ƒë·ªÉ debug
                log(f"Found {len(file_paths)} file paths, {len(valid_file_paths)} valid paths")
                
                # N·∫øu c√≥ nhi·ªÅu file, t·∫°o danh s√°ch t√™n file
                if len(valid_file_paths) > 1:
                    file_names = [os.path.basename(path) for path in valid_file_paths]
                    metadata_params['file_names'] = file_names
                    metadata_params['file_paths'] = valid_file_paths
                    # S·ª≠ d·ª•ng file ƒë·∫ßu ti√™n l√†m file ch√≠nh cho metadata
                    metadata_params['file_name'] = file_names[0] + f" v√† {len(file_names)-1} file kh√°c"
                    metadata_params['file_path'] = valid_file_paths[0]
                    metadata_params['is_multi_file'] = True
                    metadata_params['file_count'] = len(valid_file_paths)
                    
                    # Log ƒë·ªÉ debug
                    log(f"Processing multiple files: {len(valid_file_paths)} files")
                    log(f"File names: {file_names}")
                elif len(valid_file_paths) == 1:
                    # N·∫øu ch·ªâ c√≥ m·ªôt file
                    metadata_params['file_name'] = os.path.basename(valid_file_paths[0])
                    metadata_params['file_path'] = valid_file_paths[0]
                    metadata_params['is_multi_file'] = False
                else:
                    # Kh√¥ng c√≥ file h·ª£p l·ªá
                    log("Warning: No valid file paths found")
                    return state
            
            # Always pass classification labels if available
            if "classification_labels" in state:
                metadata_params['classification_labels'] = state.get("classification_labels", {})
                log(f"Passing classification_labels to metadata agent: {metadata_params['classification_labels']}")
                
            # Set classification if available
            if file_classification and file_classification.lower() not in ["kh√¥ng x√°c ƒë·ªãnh", "ch∆∞a ph√¢n lo·∫°i", "kh√¥ng c√≥ ph√¢n lo·∫°i"]:
                # Clean up the classification label
                label = file_classification.split(':')[-1].strip()
                metadata_params['label'] = label
            else:
                # Check if we can extract classification from state
                if "classified_files" in state and "classification_labels" in state:
                    # Get labels from state
                    labels = state.get("classification_labels", {})
                    if labels:
                        # For multiple files, store individual labels
                        if 'is_multi_file' in metadata_params and metadata_params['is_multi_file']:
                            file_labels = {}
                            for file_path in metadata_params.get('file_paths', []):
                                file_name = os.path.basename(file_path)
                                # Try to find label by file name or path
                                if file_name in labels:
                                    file_labels[file_name] = labels[file_name]
                                    log(f"Found label for {file_name}: {labels[file_name]}")
                                elif file_path in labels:
                                    file_labels[file_name] = labels[file_path]
                                    log(f"Found label for {file_path}: {labels[file_path]}")
                            
                            if file_labels:
                                metadata_params['file_labels'] = file_labels
                                log(f"Using individual labels for files: {file_labels}")
                                log(f"DEBUG: file_labels dictionary contents: {file_labels}")
                                log(f"DEBUG: metadata_params structure: {metadata_params}")
                                
                                # Use the first file's label as the main label
                                first_file_name = os.path.basename(metadata_params.get('file_paths', ['unknown'])[0])
                                if first_file_name in file_labels:
                                    metadata_params['label'] = file_labels[first_file_name]
                                    log(f"Using first file's label as main label: {file_labels[first_file_name]}")
                                else:
                                    # Fallback to first label in the dictionary
                                    first_label = next(iter(labels.values()))
                                    metadata_params['label'] = first_label
                                    log(f"Using first available label as main label: {first_label}")
                        else:
                            # For single file, use the matching label if available
                            file_name = metadata_params.get('file_name')
                            file_path = metadata_params.get('file_path')
                            
                            if file_name in labels:
                                metadata_params['label'] = labels[file_name]
                                log(f"Using label for {file_name}: {labels[file_name]}")
                            elif file_path in labels:
                                metadata_params['label'] = labels[file_path]
                                log(f"Using label for {file_path}: {labels[file_path]}")
                            else:
                                # Fallback to first label
                                first_label = next(iter(labels.values()))
                                metadata_params['label'] = first_label
                                log(f"Using first available label as fallback: {first_label}")
            
            # Check if we have individual file extraction results in the state
            individual_contents = {}
            if "text_extraction_results" in state:
                extraction_results = state["text_extraction_results"]
                log(f"Found individual text extraction results for {len(extraction_results)} files")
                
                # Convert file paths to file names for easier lookup
                for file_path, content in extraction_results.items():
                    file_name = os.path.basename(file_path)
                    individual_contents[file_name] = content
                    log(f"Found content for {file_name}: {len(content)} characters")
            
            # Set content if available
            if 'is_multi_file' in metadata_params and metadata_params['is_multi_file']:
                # For multi-file case, we'll still use the combined content for the preview
                if file_content:
                    # Ensure content is properly formatted and not too long
                    content = file_content.strip()
                    if len(content) > 4000:  # Truncate if too long for the model
                        content = content[:4000] + "... [n·ªôi dung b·ªã c·∫Øt b·ªõt]"
                    metadata_params['content'] = content
                    log(f"Content length for metadata preview: {len(content)} characters")
                    
                    # Also store individual contents if we have them
                    if individual_contents:
                        metadata_params['individual_contents'] = individual_contents
                        log(f"Added individual contents for {len(individual_contents)} files")
                else:
                    # Provide a placeholder when no content is available
                    log("Warning: No content found for metadata. Using placeholder.")
                    file_names = metadata_params.get('file_names', [])
                    placeholder = f"Multiple files: {', '.join(file_names[:3])}{'...' if len(file_names) > 3 else ''} (no content extracted)"
                    metadata_params['content'] = placeholder
                    log(f"Using placeholder content: {placeholder}")
            else:
                # Single file case
                file_name = metadata_params.get('file_name', 'unknown_file')
                
                # Try to get content from individual extraction results first
                if file_name in individual_contents:
                    content = individual_contents[file_name]
                    log(f"Using individual content for {file_name}: {len(content)} characters")
                    metadata_params['content'] = content
                elif file_content:
                    # Fall back to general content if available
                    content = file_content.strip()
                    if len(content) > 4000:  # Truncate if too long for the model
                        content = content[:4000] + "... [n·ªôi dung b·ªã c·∫Øt b·ªõt]"
                    metadata_params['content'] = content
                    log(f"Using general content for {file_name}: {len(content)} characters")
                else:
                    # No content available, use placeholder
                    placeholder = f"File: {file_name} (no content extracted)"
                    metadata_params['content'] = placeholder
                    log(f"Using placeholder content: {placeholder}")
            
            # Build the enhanced query for the metadata agent
            enhanced_query = "T√¥i c·∫ßn t·∫°o v√† l∆∞u metadata v·ªõi c√°c th√¥ng tin sau:\n\n"
            
            # Add file information if available
            if 'is_multi_file' in metadata_params and metadata_params['is_multi_file']:
                # Th√¥ng tin cho nhi·ªÅu file
                enhanced_query += f"- NH√ìM FILE: {metadata_params['file_count']} files\n"
                enhanced_query += f"- T√äN FILE CH√çNH: {metadata_params['file_name']}\n"
                
                # Th√™m danh s√°ch t·∫•t c·∫£ c√°c file v√† ph√¢n lo·∫°i c·ªßa ch√∫ng
                file_list = []
                for i, name in enumerate(metadata_params['file_names']):
                    file_entry = f"  + {i+1}. {name}"
                    # Th√™m ph√¢n lo·∫°i ri√™ng cho t·ª´ng file n·∫øu c√≥
                    if 'file_labels' in metadata_params and name in metadata_params['file_labels']:
                        file_entry += f" - Ph√¢n lo·∫°i: {metadata_params['file_labels'][name]}"
                    file_list.append(file_entry)
                
                enhanced_query += f"- DANH S√ÅCH FILES:\n{chr(10).join(file_list)}\n"
                
                # Th√™m ƒë∆∞·ªùng d·∫´n file ch√≠nh
                enhanced_query += f"- ƒê∆Ø·ªúNG D·∫™N CH√çNH: {metadata_params['file_path']}\n"
            else:
                # Th√¥ng tin cho m·ªôt file
                if 'file_name' in metadata_params:
                    enhanced_query += f"- T√äN FILE: {metadata_params['file_name']}\n"
                if 'file_path' in metadata_params:
                    enhanced_query += f"- ƒê∆Ø·ªúNG D·∫™N: {metadata_params['file_path']}\n"
            
            # Th√™m ph√¢n lo·∫°i n·∫øu c√≥
            if 'label' in metadata_params:
                enhanced_query += f"- PH√ÇN LO·∫†I: {metadata_params['label']} (t·ª± ƒë·ªông)\n"
            
            # Add content preview if available
            if 'content' in metadata_params and metadata_params['content']:
                content = metadata_params['content']
                preview_length = min(200, len(content))
                preview = content[:preview_length]
                
                enhanced_query += f"\nN·ªòI DUNG (XEM TR∆Ø·ªöC {preview_length}/{len(content)} k√Ω t·ª±):\n"
                enhanced_query += f"""
================================================================================
{preview}
... [N·ªòI DUNG ƒê·∫¶Y ƒê·ª¶ ƒê∆Ø·ª¢C CUNG C·∫§P ·ªû PH·∫¶N D∆Ø·ªöI]
================================================================================
"""
            
            # Add clear instructions for the metadata agent
            enhanced_query += """

H∆Ø·ªöNG D·∫™N QUAN TR·ªåNG:
1. ƒê·ªåC K·ª∏: To√†n b·ªô n·ªôi dung ƒë√£ ƒë∆∞·ª£c cung c·∫•p ƒë·∫ßy ƒë·ªß ·ªü ph·∫ßn d∆∞·ªõi
2. KH√îNG y√™u c·∫ßu th√™m n·ªôi dung v√¨ ƒë√£ c√≥ s·∫µn
3. Th·ª±c hi·ªán c√°c b∆∞·ªõc sau:
   - G·ªçi create_metadata v·ªõi ƒë·∫ßy ƒë·ªß th√¥ng tin
   - L∆∞u metadata b·∫±ng save_metadata_to_mcp
   - Tr·∫£ v·ªÅ metadata_id ƒë√£ t·∫°o

TH√îNG TIN CHI TI·∫æT:
"""
            
            # Include all metadata params in a clear format
            for key, value in metadata_params.items():
                if key == 'content':
                    enhanced_query += f"\nN·ªòI DUNG ƒê·∫¶Y ƒê·ª¶ ({len(value)} k√Ω t·ª±):\n"
                    enhanced_query += "="*80 + "\n"
                    enhanced_query += value[:4000]  # Truncate to avoid token limits
                    if len(value) > 4000:
                        enhanced_query += "\n... [ƒê√É C·∫ÆT B·ªöT N·ªòI DUNG DO QU√Å D√ÄI]"
                    enhanced_query += "\n" + "="*80 + "\n"
                else:
                    enhanced_query += f"{key.upper()}: {value}\n"
            
            # Final reminder
            enhanced_query += """

L∆ØU √ù CU·ªêI C√ôNG:
- S·ª≠ d·ª•ng N·ªòI DUNG ƒê·∫¶Y ƒê·ª¶ ·ªü tr√™n ƒë·ªÉ t·∫°o metadata
- KH√îNG y√™u c·∫ßu th√™m n·ªôi dung
- Tr·∫£ v·ªÅ metadata_id sau khi l∆∞u th√†nh c√¥ng
"""
            
            log(f"Metadata parameters: {metadata_params}")
            log(f"Enhanced metadata query: {enhanced_query[:300]}...")

            # Get the metadata agent
            metadata_agent = self.agents["metadata"]

            # Initialize MCP connection if needed
            if not hasattr(metadata_agent, 'mcp_initialized') or not metadata_agent.mcp_initialized:
                log("Initializing MCP connection...")
                if not metadata_agent.initialize_mcp_sync():
                    error_msg = "‚ùå Failed to initialize MCP connection for metadata agent"
                    log(error_msg, level='error')
                    state["messages"].append(AIMessage(content=error_msg))
                    return state
            
            # Initialize variables
            metadata_id = None
            response_content = ""
            
            try:
                # Log metadata parameters for debugging
                log("Preparing to invoke MetadataAgent with the following parameters:")
                log(f"- File: {metadata_params.get('file_name', 'N/A')}")
                log(f"- Path: {metadata_params.get('file_path', 'N/A')}")
                log(f"- Label: {metadata_params.get('label', 'N/A')}")
                log(f"- Content length: {len(metadata_params.get('content', ''))} characters")
                
                # Call the metadata agent with the enhanced query and metadata
                log("Invoking MetadataAgent...")
                
                # Chu·∫©n b·ªã metadata cho agent
                metadata_for_agent = {
                    'file_name': metadata_params.get('file_name'),
                    'file_path': metadata_params.get('file_path'),
                    'label': metadata_params.get('label'),
                    'content': metadata_params.get('content', '')
                }
                
                # Th√™m th√¥ng tin v·ªÅ nhi·ªÅu file n·∫øu c√≥
                if 'is_multi_file' in metadata_params and metadata_params['is_multi_file']:
                    metadata_for_agent['is_multi_file'] = True
                    metadata_for_agent['file_count'] = metadata_params.get('file_count')
                    metadata_for_agent['file_names'] = metadata_params.get('file_names', [])
                    metadata_for_agent['file_paths'] = metadata_params.get('file_paths', [])
                
                # Th√™m classification_labels t·ª´ state n·∫øu c√≥
                if 'classification_labels' in state:
                    metadata_for_agent['classification_labels'] = state['classification_labels']
                    log(f"Adding classification_labels from state: {state['classification_labels']}")
                else:
                    log("No classification_labels found in state")
                
                # In ra metadata_for_agent ƒë·ªÉ debug
                log(f"Final metadata_for_agent: {metadata_for_agent}")
                
                response = metadata_agent.invoke(
                    query=enhanced_query,
                    metadata=metadata_for_agent,
                    sessionId=self.session_id
                )
                log("MetadataAgent completed successfully")
                
                # Process the response
                if not response or not response.strip():
                    response_content = "T√¥i ƒë√£ x·ª≠ l√Ω metadata nh∆∞ng kh√¥ng c√≥ k·∫øt qu·∫£ ƒë√°ng ch√∫ √Ω."
                    log("No response content from MetadataAgent")
                else:
                    # Clean up the response
                    response = response.strip()
                    log(f"Raw metadata agent response: {response}")
                    
                    # Try to extract metadata ID from the response
                    import re
                    
                    # Look for various possible ID formats in the response
                    id_patterns = [
                        r'metadata[_-]?id[\s:]*([a-f0-9-]+)',  # metadata-id: xxxx
                        r'id[\s:]*([a-f0-9]{8,})',            # id: xxxxxxxx-xxxx-...
                        r'([a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12})'  # UUID format
                    ]
                    
                    for pattern in id_patterns:
                        match = re.search(pattern, response, re.IGNORECASE)
                        if match:
                            metadata_id = match.group(1)
                            log(f"Found metadata ID using pattern {pattern}: {metadata_id}")
                            break
                    
                    if metadata_id:
                        # T·∫°o ph·∫£n h·ªìi d·ª±a tr√™n s·ªë l∆∞·ª£ng file
                        if 'is_multi_file' in metadata_params and metadata_params['is_multi_file']:
                            file_count = metadata_params.get('file_count', 0)
                            file_names = metadata_params.get('file_names', [])
                            
                            # T·∫°o danh s√°ch t√™n file ng·∫Øn g·ªçn
                            if len(file_names) > 3:
                                file_list = f"{', '.join(file_names[:2])} v√† {len(file_names)-2} file kh√°c"
                            else:
                                file_list = ", ".join(file_names)
                                
                            response_content = f"‚úÖ ƒê√£ l∆∞u metadata cho {file_count} files ({file_list}). ID: {metadata_id}"
                        else:
                            file_name = metadata_params.get('file_name', 'kh√¥ng x√°c ƒë·ªãnh')
                            response_content = f"‚úÖ ƒê√£ l∆∞u metadata cho file {file_name} th√†nh c√¥ng. ID: {metadata_id}"
                            
                        log(f"Metadata saved with ID: {metadata_id}")
                        
                        # Also check if the metadata was actually saved to MCP
                        try:
                            metadata_agent = self.agents["metadata"]
                            if hasattr(metadata_agent, 'mcp_connection'):
                                result = metadata_agent.mcp_connection.call_tool_sync(
                                    "get_metadata_by_id", 
                                    {"metadata_id": metadata_id}
                                )
                                if result and 'error' not in result:
                                    log(f"Verified metadata exists in MCP: {metadata_id}")
                                else:
                                    log(f"Warning: Metadata ID {metadata_id} not found in MCP", level='warning')
                        except Exception as e:
                            log(f"Error verifying metadata in MCP: {str(e)}", level='error')
                    else:
                        # If no ID found, check if this is an error message
                        error_keywords = ['l·ªói', 'error', 'failed', 'th·∫•t b·∫°i', 'kh√¥ng t√¨m th·∫•y', 'not found']
                        
                        # T·∫°o ph·∫£n h·ªìi d·ª±a tr√™n s·ªë l∆∞·ª£ng file khi c√≥ l·ªói
                        if 'is_multi_file' in metadata_params and metadata_params['is_multi_file']:
                            file_count = metadata_params.get('file_count', 0)
                            file_names = metadata_params.get('file_names', [])
                            
                            # T·∫°o danh s√°ch t√™n file ng·∫Øn g·ªçn
                            if len(file_names) > 3:
                                file_list = f"{', '.join(file_names[:2])} v√† {len(file_names)-2} file kh√°c"
                            else:
                                file_list = ", ".join(file_names)
                                
                            if any(keyword in response.lower() for keyword in error_keywords):
                                response_content = f"‚ùå L·ªói khi x·ª≠ l√Ω metadata cho {file_count} files ({file_list}): {response}"
                            else:
                                response_content = f"‚ÑπÔ∏è ƒê√£ x·ª≠ l√Ω metadata cho {file_count} files ({file_list}), nh∆∞ng kh√¥ng t√¨m th·∫•y ID: {response}"
                        else:
                            file_name = metadata_params.get('file_name', 'kh√¥ng x√°c ƒë·ªãnh')
                            if any(keyword in response.lower() for keyword in error_keywords):
                                response_content = f"‚ùå L·ªói khi x·ª≠ l√Ω metadata cho file {file_name}: {response}"
                            else:
                                response_content = f"‚ÑπÔ∏è ƒê√£ x·ª≠ l√Ω metadata cho file {file_name}, nh∆∞ng kh√¥ng t√¨m th·∫•y ID: {response}"
                        
                        log(f"Metadata agent response (no ID found): {response}")
                        
                # Add the response to the conversation
                formatted_response = f"üìã {response_content}"
                log(f"MetadataAgent response: {formatted_response[:200]}...")
                state["messages"].append(AIMessage(content=formatted_response))
                
                # Store result in agent_results even if no metadata ID was found
                if "agent_results" not in state:
                    state["agent_results"] = {}
                    
                state["agent_results"]["metadata"] = {
                    "metadata_id": metadata_id,
                    "response": response_content,
                    "is_multi_file": metadata_params.get('is_multi_file', False),
                    "file_count": metadata_params.get('file_count', 1) if metadata_params.get('file_name') else 0,
                    "success": metadata_id is not None
                }
                
                # Store metadata info in the state for future reference
                if 'metadata' not in state:
                    state['metadata'] = {}
                
                if 'metadata_ids' not in state['metadata']:
                    state['metadata']['metadata_ids'] = []
                    
                if metadata_id:  # Use the metadata_id variable that we defined earlier
                    state['metadata']['metadata_ids'].append(metadata_id)
                    log(f"Added metadata ID to state: {metadata_id}")
                    
                    # L∆∞u th√¥ng tin v·ªÅ c√°c file ƒë√£ x·ª≠ l√Ω metadata
                    if 'is_multi_file' in metadata_params and metadata_params['is_multi_file']:
                        # L∆∞u danh s√°ch c√°c file ƒë√£ x·ª≠ l√Ω
                        if 'processed_files' not in state['metadata']:
                            state['metadata']['processed_files'] = []
                            
                        # Th√™m c√°c file v√†o danh s√°ch ƒë√£ x·ª≠ l√Ω
                        file_paths = metadata_params.get('file_paths', [])
                        state['metadata']['processed_files'].extend(file_paths)
                        log(f"Added {len(file_paths)} files to processed_files in state")
                        
                        # L∆∞u th√¥ng tin v·ªÅ nh√≥m file
                        if 'file_groups' not in state['metadata']:
                            state['metadata']['file_groups'] = {}
                            
                        # T·∫°o nh√≥m file v·ªõi metadata_id l√†m key
                        state['metadata']['file_groups'][metadata_id] = {
                            'file_count': metadata_params.get('file_count', 0),
                            'file_paths': file_paths,
                            'file_names': metadata_params.get('file_names', []),
                            'label': metadata_params.get('label', 'kh√¥ng x√°c ƒë·ªãnh')
                        }
                    else:
                        # L∆∞u th√¥ng tin cho m·ªôt file
                        if 'processed_files' not in state['metadata']:
                            state['metadata']['processed_files'] = []
                            
                        file_path = metadata_params.get('file_path')
                        if file_path:
                            state['metadata']['processed_files'].append(file_path)
                            log(f"Added file {file_path} to processed_files in state")
                else:
                    log("No metadata ID to add to state", level='warning')
                
                # L∆∞u th√¥ng tin v·ªÅ agent_results
                if "agent_results" not in state:
                    state["agent_results"] = {}
                    
                state["agent_results"]["metadata"] = {
                    "metadata_id": metadata_id,
                    "response": response_content,
                    "is_multi_file": metadata_params.get('is_multi_file', False),
                    "file_count": metadata_params.get('file_count', 1) if metadata_params.get('file_name') else 0
                }
                
                return state
                
            except Exception as e:
                error_msg = f"L·ªói khi ch·∫°y MetadataAgent: {str(e)}"
                log(error_msg, level='error')
                state["messages"].append(AIMessage(
                    content=f"[L·ªói] {error_msg}. Vui l√≤ng th·ª≠ l·∫°i ho·∫∑c ki·ªÉm tra k·∫øt n·ªëi MCP server."
                ))
                return state

        except Exception as e:
            import traceback
            print(f"Error running metadata agent: {e}")
            print(traceback.format_exc())
            # Add an error message to the state
            error_message = f"Xin l·ªói, t√¥i g·∫∑p l·ªói khi x·ª≠ l√Ω metadata: {str(e)}"
            state["messages"].append(AIMessage(content=error_message))
            return state

    async def run_text_extraction_agent(self, state: AgentState) -> AgentState:
        """
        Run the text extraction agent on the current query.
        """
        def clean_invalid_unicode(text):
            """X·ª≠ l√Ω v√† lo·∫°i b·ªè c√°c k√Ω t·ª± Unicode kh√¥ng h·ª£p l·ªá"""
            if not text:
                return ""
            # Thay th·∫ø c√°c k√Ω t·ª± surrogate ƒë∆°n l·∫ª v√† k√Ω t·ª± kh√¥ng h·ª£p l·ªá kh√°c
            return text.encode('utf-8', errors='ignore').decode('utf-8')
            
        try:
            # T√¨m file paths t·ª´ state tr∆∞·ªõc ti√™n n·∫øu c√≥
            file_paths = []
            if "processed_files" in state and state["processed_files"]:
                file_paths = state["processed_files"]
                log(f"Using {len(file_paths)} file paths from state[processed_files]: {file_paths}")
            
            # N·∫øu kh√¥ng c√≥ trong state, t√¨m t·ª´ c√°c tin nh·∫Øn tr∆∞·ªõc ƒë√≥
            if not file_paths:
                for message in reversed(state["messages"]):
                    if isinstance(message, AIMessage):
                        log(f"Checking message for file paths: {message.content[:100]}...")
                        
                        # Ki·ªÉm tra xem tin nh·∫Øn c√≥ ph·∫£i l√† t·ª´ RAG agent kh√¥ng (c√≥ th·ªÉ c√≥ tr∆∞·ªùng file_paths)
                        if hasattr(message, '_additional_kwargs') and 'file_paths' in message._additional_kwargs:
                            log(f"Found RAG agent message with file_paths field")
                            paths = message._additional_kwargs['file_paths']
                            if paths and isinstance(paths, list) and len(paths) > 0:
                                file_paths.extend(paths)
                                log(f"Extracted {len(paths)} file paths from RAG agent")
                                break
                    
                    # T√¨m ki·∫øm c√¢u "T√¥i ƒë√£ t√¨m th·∫•y file:" ho·∫∑c "T√¥i ƒë√£ t√¨m th·∫•y {n} files:" trong tin nh·∫Øn
                    if "T√¥i ƒë√£ t√¨m th·∫•y file:" in message.content:
                        log(f"Found agent message with standard format for single file")
                        
                        # T√¨m ƒë∆∞·ªùng d·∫´n file sau c√¢u "T√¥i ƒë√£ t√¨m th·∫•y file:"
                        import re
                        
                        # T√¨m sau "T√¥i ƒë√£ t√¨m th·∫•y file:" - ki·ªÉm tra c·∫£ ƒë∆∞·ªùng d·∫´n ƒë·∫ßy ƒë·ªß
                        full_path_pattern = r'T√¥i ƒë√£ t√¨m th·∫•y file:\s*([A-Z]:\\[^\s\n\r]+)'
                        full_path_matches = re.findall(full_path_pattern, message.content)
                        
                        if full_path_matches:
                            # L·∫•y ƒë∆∞·ªùng d·∫´n v√† lo·∫°i b·ªè c√°c k√Ω t·ª± kh√¥ng mong mu·ªën ·ªü cu·ªëi
                            raw_path = full_path_matches[0]
                            # Lo·∫°i b·ªè c√°c k√Ω t·ª± kh√¥ng mong mu·ªën c√≥ th·ªÉ c√≥ ·ªü cu·ªëi ƒë∆∞·ªùng d·∫´n
                            if raw_path.endswith("'}"):
                                file_paths.append(raw_path[:-2])
                            else:
                                file_paths.append(raw_path)
                            log(f"Extracted full file path: {file_paths[-1]}")
                            break
                    
                    # T√¨m nhi·ªÅu file t·ª´ ƒë·ªãnh d·∫°ng "T√¥i ƒë√£ t√¨m th·∫•y {n} files:"
                    elif "files:" in message.content and "T√¥i ƒë√£ t√¨m th·∫•y" in message.content:
                        log(f"Found agent message with multiple files format")
                        import re
                        
                        # T√¨m ƒë∆∞·ªùng d·∫´n file t·ª´ danh s√°ch ƒë√°nh s·ªë
                        multi_file_pattern = r'\d+\.\s*([A-Z]:\\[^\s\n\r]+)'
                        multi_file_matches = re.findall(multi_file_pattern, message.content)
                        
                        if multi_file_matches:
                            for raw_path in multi_file_matches:
                                if raw_path.endswith("'}"):
                                    file_paths.append(raw_path[:-2])
                                else:
                                    file_paths.append(raw_path)
                            log(f"Extracted {len(multi_file_matches)} file paths from numbered list")
                            break
                    
                    # D·ª± ph√≤ng: N·∫øu kh√¥ng t√¨m th·∫•y c√¢u chu·∫©n, th·ª≠ t√¨m b·∫•t k·ª≥ ƒë∆∞·ªùng d·∫´n Windows n√†o
                    elif any(indicator in message.content for indicator in ["ƒê√£ t√¨m th·∫•y file:", "t√¨m th·∫•y file", "[Filesystem Agent]:", "[RAG Agent]:", "üóÇÔ∏è", "üîç"]):
                        log(f"Found agent message with non-standard format")
                        
                        # T√¨m b·∫•t k·ª≥ ƒë∆∞·ªùng d·∫´n n√†o trong tin nh·∫Øn
                        import re
                        file_pattern = r'[A-Z]:\\(?:[^\\/:*?"<>|\r\n]+\\)*[^\\/:*?"<>|\r\n]*\.[a-zA-Z0-9]+'
                        file_matches = re.findall(file_pattern, message.content)
                        
                        if file_matches:
                            file_paths.extend(file_matches)
                            log(f"Extracted {len(file_matches)} file paths using general pattern")
                            break

            # Get the last message that's not from an agent
            query = ""
            for message in reversed(state["messages"]):
                if isinstance(message, HumanMessage):
                    query = message.content
                    break

            # Ki·ªÉm tra quy·ªÅn truy c·∫≠p file n·∫øu t√¨m th·∫•y file paths
            if file_paths:
                # Import AccessControlManager
                import sys
                import os
                current_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
                if current_dir not in sys.path:
                    sys.path.insert(0, current_dir)
                from utils.access_control import AccessControlManager
                
                # L·∫•y vai tr√≤ ng∆∞·ªùi d√πng t·ª´ state ho·∫∑c session
                user_role = state.get("user_role", "user")  # M·∫∑c ƒë·ªãnh l√† "user" n·∫øu kh√¥ng c√≥
                
                # Kh·ªüi t·∫°o AccessControlManager
                access_control_file = os.path.join(current_dir, "config", "access_control.json")
                access_manager = AccessControlManager(access_control_file)
                
                # Ki·ªÉm tra quy·ªÅn truy c·∫≠p cho t·ª´ng file
                accessible_files = []
                for file_path in file_paths:
                    has_access, reason = access_manager.check_file_access(file_path, user_role)
                    access_manager.log_access_attempt(file_path, user_role, has_access, reason)
                    
                    if has_access:
                        log(f"Access granted for user role '{user_role}' to file '{file_path}'")
                        accessible_files.append(file_path)
                    else:
                        log(f"Access denied for file '{file_path}': {reason}", level='warning')
                
                if not accessible_files:
                    # Kh√¥ng c√≥ quy·ªÅn truy c·∫≠p v√†o b·∫•t k·ª≥ file n√†o, th√¥ng b√°o cho ng∆∞·ªùi d√πng
                    error_message = f"‚ö†Ô∏è Kh√¥ng th·ªÉ tr√≠ch xu·∫•t n·ªôi dung: B·∫°n kh√¥ng c√≥ quy·ªÅn truy c·∫≠p v√†o c√°c file n√†y"
                    state["messages"].append(AIMessage(content=error_message))
                    log(f"Access denied to all files", level='warning')
                    
                    # ƒê√°nh d·∫•u d·ª´ng x·ª≠ l√Ω c√°c agent ti·∫øp theo
                    state["stop_processing"] = True
                    state["stop_reason"] = "access_denied"
                    log(f"Setting stop_processing flag due to access denied", level='warning')
                    return state
                
                # C√≥ quy·ªÅn truy c·∫≠p √≠t nh·∫•t m·ªôt file, ti·∫øp t·ª•c v·ªõi tr√≠ch xu·∫•t
                if len(accessible_files) == 1:
                    enhanced_query = f"Extract text from the file at path {accessible_files[0]}"
                else:
                    # N·∫øu c√≥ nhi·ªÅu file, t·∫°o danh s√°ch ƒë∆∞·ªùng d·∫´n
                    file_paths_str = "\n".join([f"- {path}" for path in accessible_files])
                    enhanced_query = f"Extract text from the following files:\n{file_paths_str}"
                
                log(f"Enhanced query with file paths: {enhanced_query[:100]}...")
                
                # L∆∞u danh s√°ch file c√≥ quy·ªÅn truy c·∫≠p v√†o state ƒë·ªÉ s·ª≠ d·ª•ng sau n√†y
                state["accessible_files"] = accessible_files
            else:
                # Kh√¥ng t√¨m th·∫•y file path, s·ª≠ d·ª•ng query g·ªëc
                enhanced_query = query
                log(f"WARNING: No file paths found! Running TextExtractionAgent with original query: {query}")

            # Track that we're using this agent
            if "used_tools" not in state:
                state["used_tools"] = []
            state["used_tools"].append("text_extraction")

            # Get the text extraction agent
            text_extraction_agent = self.agents["text_extraction"]

            # Run the agent with the query and wait for completion
            log("Waiting for TextExtractionAgent to complete...")
            response = text_extraction_agent.invoke(enhanced_query, self.session_id)
            log("TextExtractionAgent completed")
            
            # Log raw response for debugging
            log(f"Raw TextExtractionAgent response: {response}")

            # Format the response - ch·∫•p nh·∫≠n nhi·ªÅu ƒë·ªãnh d·∫°ng tr·∫£ v·ªÅ kh√°c nhau
            content = ""
            
            # Tr∆∞·ªùng h·ª£p 1: Response l√† dict v·ªõi key 'content'
            if isinstance(response, dict) and 'content' in response:
                content = clean_invalid_unicode(response['content'])
                log(f"Extracted content from response dict with key 'content': {content[:100]}...")
            
            # Tr∆∞·ªùng h·ª£p 2: Response l√† string
            elif isinstance(response, str):
                content = clean_invalid_unicode(response)
                log(f"Response is already a string: {content[:100]}...")
            
            # Tr∆∞·ªùng h·ª£p 3: Response l√† dict nh∆∞ng kh√¥ng c√≥ 'content', th·ª≠ t√¨m c√°c key kh√°c
            elif isinstance(response, dict):
                log(f"Response keys: {list(response.keys())}")
                
                # Th·ª≠ l·∫•y t·ª´ key 'response_type' tr∆∞·ªõc
                if 'response_type' in response and 'content' in response:
                    content = clean_invalid_unicode(response['content'])
                    log(f"Using content from standard response format: {content[:100]}...")
                
                # Th·ª≠ l·∫•y gi√° tr·ªã t·ª´ c√°c key kh√°c n·∫øu l√† string d√†i
                else:
                    for key in response.keys():
                        if isinstance(response[key], str) and len(response[key]) > 20:
                            content = clean_invalid_unicode(response[key])
                            log(f"Using content from key '{key}': {content[:100]}...")
                            break
            
            # Tr∆∞·ªùng h·ª£p 4: C√°c tr∆∞·ªùng h·ª£p kh√°c, chuy·ªÉn v·ªÅ string
            else:
                content = clean_invalid_unicode(str(response))
                log(f"Converted response to string: {content[:100]}...")
                
            # Ki·ªÉm tra n·∫øu content ch·ª©a k·∫øt qu·∫£ tr√≠ch xu·∫•t
            if "I'll extract the text from" in content or "Here's the extracted text" in content:
                # T√¨m ph·∫ßn n·ªôi dung tr√≠ch xu·∫•t sau c√°c c√¢u m·ªü ƒë·∫ßu
                import re
                extracted_text = re.split(r"Here's the extracted text[:\s]*|I'll extract the text[^:]*:\s*", content, 1)
                if len(extracted_text) > 1:
                    content = extracted_text[1].strip()
                    log(f"Extracted the actual content after introduction: {content[:100]}...")
            
            # Ki·ªÉm tra n·∫øu content ch·ª©a "I'll use the extract_text_from" (c√¢u tr·∫£ l·ªùi c·ªßa agent) ho·∫∑c n·∫øu n·ªôi dung tr√≠ch xu·∫•t tr√πng v·ªõi query
            if ("I'll use the extract_text_from" in content or content.strip() == query.strip()) and "accessible_files" in state:
                log("Agent response contains tool usage description but no actual extraction result or returned the query")
                # Th·ª≠ tr·ª±c ti·∫øp c√°c h√†m tr√≠ch xu·∫•t d·ª±a v√†o ƒë·ªãnh d·∫°ng file
                from agents.text_extraction_agent import extract_text_from_pdf, extract_text_from_word, extract_text_from_powerpoint
                
                # Tr√≠ch xu·∫•t n·ªôi dung t·ª´ t·ª´ng file c√≥ quy·ªÅn truy c·∫≠p
                extracted_contents = []
                extraction_results = {}
                for file_path in state["accessible_files"]:
                    try:
                        if file_path.lower().endswith('.pdf'):
                            extracted_text = extract_text_from_pdf(file_path)
                            extraction_results[file_path] = clean_invalid_unicode(extracted_text)
                            log(f"Directly extracted text from PDF: {file_path}")
                        elif file_path.lower().endswith('.docx'):
                            extracted_text = extract_text_from_word(file_path)
                            extraction_results[file_path] = clean_invalid_unicode(extracted_text)
                            log(f"Directly extracted text from Word document: {file_path}")
                        elif file_path.lower().endswith(('.ppt', '.pptx')):
                            extracted_text = extract_text_from_powerpoint(file_path)
                            extraction_results[file_path] = clean_invalid_unicode(extracted_text)
                            log(f"Directly extracted text from PowerPoint: {file_path}")
                    except Exception as e:
                        log(f"Error in direct extraction for {file_path}: {e}", level='error')
                        extraction_results[file_path] = f"L·ªói khi tr√≠ch xu·∫•t: {str(e)}"
                
                # N·∫øu c√≥ k·∫øt qu·∫£ tr√≠ch xu·∫•t, g·ªôp l·∫°i
                if extraction_results:
                    content = ""
                    for file_path, extracted_text in extraction_results.items():
                        content += f"\n\n--- T·ª´ file {os.path.basename(file_path)} ---\n{clean_invalid_unicode(extracted_text)}\n"
                    content = content.strip()
                    
                    # Store individual file extraction results in the state
                    state["text_extraction_results"] = extraction_results
                    log(f"Stored individual text extraction results for {len(extraction_results)} files in state")

            if not content.strip():
                if "accessible_files" in state and state["accessible_files"]:
                    if len(state["accessible_files"]) == 1:
                        content = f"T√¥i ƒë√£ c·ªë g·∫Øng tr√≠ch xu·∫•t n·ªôi dung t·ª´ file {state['accessible_files'][0]} nh∆∞ng kh√¥ng c√≥ k·∫øt qu·∫£ ƒë√°ng ch√∫ √Ω."
                    else:
                        content = f"T√¥i ƒë√£ c·ªë g·∫Øng tr√≠ch xu·∫•t n·ªôi dung t·ª´ {len(state['accessible_files'])} files nh∆∞ng kh√¥ng c√≥ k·∫øt qu·∫£ ƒë√°ng ch√∫ √Ω."
                else:
                    content = "T√¥i ƒë√£ c·ªë g·∫Øng tr√≠ch xu·∫•t n·ªôi dung nh∆∞ng kh√¥ng c√≥ k·∫øt qu·∫£ ƒë√°ng ch√∫ √Ω."

            # Add the agent's response to the state with clear indication of extraction results
            if "accessible_files" in state and state["accessible_files"]:
                if len(state["accessible_files"]) == 1:
                    response_content = f"üìù K·∫øt qu·∫£ tr√≠ch xu·∫•t t·ª´ file {state['accessible_files'][0]}:\n\n{content}"
                else:
                    file_list = "\n".join([f"- {os.path.basename(f)}" for f in state["accessible_files"]])
                    response_content = f"üìù K·∫øt qu·∫£ tr√≠ch xu·∫•t t·ª´ {len(state['accessible_files'])} files:\n{file_list}\n\n{content}"
            else:
                response_content = f"üìù {content}"
                
            log(f"TextExtractionAgent response: {response_content[:100]}...")
            state["messages"].append(AIMessage(content=response_content))
            
            # Store result in agent_results
            if "agent_results" not in state:
                state["agent_results"] = {}
            state["agent_results"]["text_extraction"] = content
            
            # ƒê·∫£m b·∫£o file_count ƒë∆∞·ª£c l∆∞u v√†o state
            if "accessible_files" in state:
                state["file_count"] = len(state["accessible_files"])
                log(f"Set file_count in state to {state['file_count']}")
                
                # L∆∞u danh s√°ch file ƒë√£ x·ª≠ l√Ω v√†o state n·∫øu ch∆∞a c√≥
                if "processed_files" not in state:
                    state["processed_files"] = state["accessible_files"]
                    log(f"Set processed_files in state with {len(state['processed_files'])} files")
            
            # If we have accessible_files but no text_extraction_results yet, create it
            if "accessible_files" in state and "text_extraction_results" not in state:
                # Create a mapping of file paths to extracted content
                # For now, we'll assign the same content to all files if we can't distinguish
                # This is better than having no content at all
                extraction_results = {}
                
                # Check if content contains file-specific sections
                import re
                file_sections = re.split(r"\n\n---\s+T·ª´ file\s+([^\n]+)\s+---\n", content)
                
                if len(file_sections) > 1:
                    # Content is divided by file sections
                    # First element is any text before the first file section
                    # Then alternating file names and content
                    for i in range(1, len(file_sections), 2):
                        if i+1 < len(file_sections):
                            file_name = file_sections[i]
                            file_content = file_sections[i+1]
                            
                            # Find the matching file path
                            for file_path in state["accessible_files"]:
                                if os.path.basename(file_path) == file_name:
                                    extraction_results[file_path] = file_content
                                    log(f"Mapped content section to file: {file_name}")
                                    break
                else:
                    # Content is not divided, assign to all files
                    for file_path in state["accessible_files"]:
                        extraction_results[file_path] = content
                        log(f"Assigned full content to file: {os.path.basename(file_path)}")
                
                state["text_extraction_results"] = extraction_results
                log(f"Created text_extraction_results for {len(extraction_results)} files from general content")
            
            # Analyze the response to suggest next agent
            log("Analyzing response to suggest next agent...")
            next_agent = await self._suggest_next_agent(content, state)
            if next_agent and next_agent not in state["current_agents"]:
                log(f"Adding {next_agent} to current_agents")
                state["current_agents"].append(next_agent)
            else:
                log(f"No additional agent suggested or already in use")
            
            if "text_extraction_results" in state:
                state["extracted_contents"] = state["text_extraction_results"]
                log(f"Stored extracted contents for data analysis: {len(state['extracted_contents'])} files")

            return state

        except Exception as e:
            log(f"Error running text extraction agent: {e}", level='error')
            # Add an error message to the state
            error_message = f"Xin l·ªói, t√¥i g·∫∑p l·ªói khi tr√≠ch xu·∫•t n·ªôi dung: {str(e)}"
            state["messages"].append(AIMessage(content=error_message))
            return state
            
    async def run_file_classification_agent(self, state: AgentState):
        """
        Run the file classification agent on the current query.
        """
        try:
            # T√¨m file paths t·ª´ state tr∆∞·ªõc ti√™n n·∫øu c√≥
            file_paths = []
            if "processed_files" in state and state["processed_files"]:
                file_paths = state["processed_files"]
                log(f"Using {len(file_paths)} file paths from state[processed_files]: {file_paths}")
            
            # T√¨m n·ªôi dung c·∫ßn ph√¢n lo·∫°i t·ª´ TextExtractionAgent
            content_to_classify = None
            
            # N·∫øu kh√¥ng c√≥ file paths trong state, t√¨m t·ª´ c√°c tin nh·∫Øn
            if not file_paths:
                # T√¨m k·∫øt qu·∫£ t·ª´ TextExtractionAgent
                for message in reversed(state["messages"]):
                    if isinstance(message, AIMessage) and ("üìù" in message.content or "[Text Extraction Agent]:" in message.content):
                        # Tr√≠ch xu·∫•t n·ªôi dung sau ph·∫ßn gi·ªõi thi·ªáu
                        text_parts = message.content.split(":\n\n", 1)
                        if len(text_parts) > 1:
                            content_to_classify = text_parts[1].strip()
                            log(f"Found content to classify from TextExtractionAgent: {content_to_classify[:100]}...")
                            
                            # Ki·ªÉm tra n·∫øu l√† nhi·ªÅu file
                            
                            # T√¨m ki·∫øm chu·ªói "K·∫øt qu·∫£ tr√≠ch xu·∫•t t·ª´ X files:"
                            multi_file_pattern = r'K·∫øt qu·∫£ tr√≠ch xu·∫•t t·ª´ (\d+) files:'
                            multi_file_match = re.search(multi_file_pattern, text_parts[0])
                            
                            if multi_file_match:
                                # ƒê√¢y l√† k·∫øt qu·∫£ t·ª´ nhi·ªÅu file
                                file_list_pattern = r'- ([^\n]+)'
                                file_names = re.findall(file_list_pattern, text_parts[0])
                                log(f"Found file names in extraction: {file_names}")
                                
                                # N·∫øu c√≥ accessible_files trong state, l·∫•y ƒë∆∞·ªùng d·∫´n ƒë·∫ßy ƒë·ªß
                                if "accessible_files" in state and state["accessible_files"]:
                                    # L·ªçc c√°c file paths d·ª±a tr√™n t√™n file ƒë√£ t√¨m th·∫•y
                                    for file_path in state["accessible_files"]:
                                        file_name = os.path.basename(file_path)
                                        # Ki·ªÉm tra xem file_name c√≥ trong danh s√°ch file_names kh√¥ng
                                        if any(name.strip() == file_name for name in file_names):
                                            file_paths.append(file_path)
                                    log(f"Found {len(file_paths)} matching file paths from accessible_files")
                            else:
                                # T√¨m file path ƒë∆°n
                                file_pattern = r't·ª´ file ([A-Z]:\\[^\s\n\r]+)'
                                file_matches = re.findall(file_pattern, text_parts[0])
                                if file_matches:
                                    file_paths.append(file_matches[0])
                                    log(f"Found file path: {file_paths[0]}")
                            break
            
            # N·∫øu kh√¥ng t√¨m th·∫•y n·ªôi dung t·ª´ TextExtractionAgent ho·∫∑c kh√¥ng c√≥ file paths, t√¨m t·ª´ c√°c ngu·ªìn kh√°c
            if not content_to_classify or not file_paths:
                # Ki·ªÉm tra n·∫øu c√≥ accessible_files trong state
                if "accessible_files" in state and state["accessible_files"]:
                    file_paths = state["accessible_files"]
                    log(f"Using accessible_files from state: {len(file_paths)} files")
                else:
                    # T√¨m file path t·ª´ c√°c tin nh·∫Øn
                    for message in reversed(state["messages"]):
                        if isinstance(message, AIMessage):
                            # Ki·ªÉm tra n·∫øu l√† tin nh·∫Øn t·ª´ RAG agent v·ªõi file_paths
                            if hasattr(message, '_additional_kwargs') and 'file_paths' in message._additional_kwargs:
                                paths = message._additional_kwargs['file_paths']
                                if paths and isinstance(paths, list):
                                    file_paths.extend(paths)
                                    log(f"Found {len(paths)} file paths from RAG agent")
                                    break
                            
                            # T√¨m ki·∫øm c√¢u "T√¥i ƒë√£ t√¨m th·∫•y file:" trong tin nh·∫Øn
                            elif "T√¥i ƒë√£ t√¨m th·∫•y file:" in message.content:
                                # Tr√≠ch xu·∫•t ƒë∆∞·ªùng d·∫´n file t·ª´ tin nh·∫Øn
                                file_pattern = r'T√¥i ƒë√£ t√¨m th·∫•y file:\s*([A-Z]:\\[^\s\n\r]+)'
                                file_matches = re.findall(file_pattern, message.content)
                                if file_matches:
                                    raw_path = file_matches[0]
                                    # Lo·∫°i b·ªè c√°c k√Ω t·ª± kh√¥ng mong mu·ªën c√≥ th·ªÉ c√≥ ·ªü cu·ªëi ƒë∆∞·ªùng d·∫´n
                                    if raw_path.endswith("'}"):
                                        file_paths.append(raw_path[:-2])
                                    else:
                                        file_paths.append(raw_path)
                                    log(f"Found file path from FilesystemAgent: {file_paths[-1]}")
                                    break
                            
                            # T√¨m nhi·ªÅu file t·ª´ ƒë·ªãnh d·∫°ng "T√¥i ƒë√£ t√¨m th·∫•y {n} files:"
                            elif "files:" in message.content and "T√¥i ƒë√£ t√¨m th·∫•y" in message.content:
                                multi_file_pattern = r'\d+\.\s*([A-Z]:\\[^\s\n\r]+)'
                                multi_file_matches = re.findall(multi_file_pattern, message.content)
                                
                                if multi_file_matches:
                                    for raw_path in multi_file_matches:
                                        if raw_path.endswith("'}"):
                                            file_paths.append(raw_path[:-2])
                                        else:
                                            file_paths.append(raw_path)
                                    log(f"Found {len(multi_file_matches)} file paths from numbered list")
                                    break

            # Get the last message that's not from an agent
            query = ""
            for message in reversed(state["messages"]):
                if isinstance(message, HumanMessage):
                    query = message.content
                    break

            # Chu·∫©n b·ªã query cho FileClassificationAgent
            if content_to_classify:
                # N·∫øu c√≥ n·ªôi dung, s·ª≠ d·ª•ng n·ªôi dung ƒë√≥ ƒë·ªÉ ph√¢n lo·∫°i
                classification_query = f"Ph√¢n lo·∫°i t·ªáp theo n·ªôi dung: '{content_to_classify[:1000]}'"  # Gi·ªõi h·∫°n ƒë·ªô d√†i
                log(f"Using extracted content for classification")
            elif file_paths:
                # N·∫øu c√≥ ƒë∆∞·ªùng d·∫´n file
                if len(file_paths) == 1:
                    # N·∫øu ch·ªâ c√≥ m·ªôt file, y√™u c·∫ßu agent ph√¢n lo·∫°i d·ª±a tr√™n file path
                    file_name = os.path.basename(file_paths[0])
                    classification_query = f"H√£y ph√¢n lo·∫°i file: {file_name} (path: {file_paths[0]})"
                    log(f"Using file path for classification: {file_paths[0]}")
                else:
                    # N·∫øu c√≥ nhi·ªÅu file, t·∫°o danh s√°ch ƒë∆∞·ªùng d·∫´n v√† t√™n file
                    file_items = []
                    for path in file_paths:
                        file_name = os.path.basename(path)
                        file_items.append(f"- {file_name} (path: {path})")
                    
                    file_paths_str = "\n".join(file_items)
                    classification_query = f"H√£y ph√¢n lo·∫°i t·ª´ng file sau v√† tr·∫£ v·ªÅ k·∫øt qu·∫£ theo ƒë·ªãnh d·∫°ng 't√™n_file - ph√¢n_lo·∫°i':\n{file_paths_str}"
                    log(f"Using multiple file paths for classification: {len(file_paths)} files")
            else:
                # Kh√¥ng c√≥ c·∫£ n·ªôi dung v√† ƒë∆∞·ªùng d·∫´n, s·ª≠ d·ª•ng query g·ªëc
                classification_query = query
                log(f"No content or file paths found. Using original query: {query}")
            
            # Track that we're using this agent
            if "used_tools" not in state:
                state["used_tools"] = []
            state["used_tools"].append("file_classification")

            # Check if we have stored classifications from feedback memory first
            from agents.human_feedback_agent import HumanFeedbackAgent
            human_feedback_agent = HumanFeedbackAgent(session_id=self.session_id)
            
            # Check if any of the files have stored classifications
            stored_classifications = {}
            all_files_have_stored_classifications = False
            
            if file_paths:
                all_files_have_stored_classifications = True
                for file_path in file_paths:
                    file_name = os.path.basename(file_path)
                    
                    # Try to get stored classification by file path or file name
                    stored_classification = human_feedback_agent.get_stored_classification(file_path)
                    
                    # If not found by path, try by filename
                    if not stored_classification:
                        stored_classification = human_feedback_agent.get_stored_classification(file_name)
                    
                    if stored_classification:
                        log(f"‚úÖ Found stored classification for {file_name}: {stored_classification}", level='info')
                        stored_classifications[file_path] = stored_classification
                    else:
                        log(f"‚ùå No stored classification found for {file_name}", level='info')
                        all_files_have_stored_classifications = False
            
            # Handle stored classifications
            if stored_classifications:
                log(f"Found stored classifications for {len(stored_classifications)} out of {len(file_paths)} files", level='info')
                
                # If we have stored classifications for all files, use them instead of calling the agent
                if all_files_have_stored_classifications:
                    log(f"Using stored classifications for all {len(file_paths)} files", level='info')
                    
                    # Format the classification result
                    if len(stored_classifications) == 1:
                        file_path = list(stored_classifications.keys())[0]
                        classification_result = stored_classifications[file_path]
                        response_content = f"üè∑Ô∏è K·∫øt qu·∫£ ph√¢n lo·∫°i file {os.path.basename(file_path)}: {classification_result} (t·ª´ ph·∫£n h·ªìi ng∆∞·ªùi d√πng)"
                    else:
                        # Multiple files
                        classifications = []
                        for file_path, classification in stored_classifications.items():
                            classifications.append(f"{os.path.basename(file_path)}: {classification}")
                        
                        formatted_classifications = "\n- ".join(classifications)
                        response_content = f"üè∑Ô∏è K·∫øt qu·∫£ ph√¢n lo·∫°i {len(stored_classifications)} files (t·ª´ ph·∫£n h·ªìi ng∆∞·ªùi d√πng):\n- {formatted_classifications}"
                    
                    # Add the response to the state
                    state["messages"].append(AIMessage(content=response_content))
                    
                    # Store result in agent_results
                    if "agent_results" not in state:
                        state["agent_results"] = {}
                    
                    if len(stored_classifications) == 1:
                        state["agent_results"]["file_classification"] = list(stored_classifications.values())[0]
                    else:
                        state["agent_results"]["file_classification"] = "\n".join([f"{os.path.basename(k)}: {v}" for k, v in stored_classifications.items()])
                    
                    # Store classification labels
                    classification_labels = {}
                    for file_path, classification in stored_classifications.items():
                        classification_labels[os.path.basename(file_path)] = classification
                    
                    state["classification_labels"] = classification_labels
                    log(f"Stored classification labels in state: {classification_labels}")
                    
                    return state
                else:
                    # We have some stored classifications but not for all files
                    # We'll run the classification agent for the remaining files and then merge the results
                    log(f"Using stored classifications for some files and running classification agent for others", level='info')
                    
                    # Keep track of which files need classification
                    files_needing_classification = []
                    for file_path in file_paths:
                        if file_path not in stored_classifications:
                            files_needing_classification.append(file_path)
                    
                    log(f"Files needing classification: {[os.path.basename(f) for f in files_needing_classification]}", level='info')
                    
                    # Modify the query to only classify the files that need classification
                    if files_needing_classification:
                        file_items = []
                        for file_path in files_needing_classification:
                            file_name = os.path.basename(file_path)
                            file_items.append(f"- {file_name}")
                        
                        file_paths_str = "\n".join(file_items)
                        classification_query = f"H√£y ph√¢n lo·∫°i t·ª´ng file sau v√† tr·∫£ v·ªÅ k·∫øt qu·∫£ theo ƒë·ªãnh d·∫°ng 't√™n_file - ph√¢n_lo·∫°i':\n{file_paths_str}"
                        log(f"Modified query to classify only {len(files_needing_classification)} files that need classification")
            
            # If we don't have stored classifications for all files, run the agent
            log("Running file classification agent for files without stored classifications")
            file_classification_agent = self.agents["file_classification"]
            
            # Keep track of which files need classification and which already have stored classifications
            files_needing_classification = []
            final_classifications = {}
            
            # First, add all stored classifications to our final result
            for file_path in file_paths:
                file_name = os.path.basename(file_path)
                if file_path in stored_classifications:
                    final_classifications[file_name] = stored_classifications[file_path]
                    log(f"Using stored classification for {file_name}: {stored_classifications[file_path]}", level='info')
                else:
                    files_needing_classification.append(file_path)
                    
            # If all files have stored classifications, we can skip running the classification agent
            if not files_needing_classification:
                log("All files have stored classifications, skipping classification agent", level='info')
                all_files_have_stored_classifications = True

            # Run the agent with the prepared query only if there are files that need classification
            if files_needing_classification:
                # Modify the query based on the number of files that need classification
                if len(files_needing_classification) == 1:
                    # If only one file needs classification, use a simpler query format
                    file_name = os.path.basename(files_needing_classification[0])
                    classification_query = f"H√£y ph√¢n lo·∫°i file: {file_name}"
                    log(f"Running FileClassificationAgent with query for single file: {classification_query}")
                else:
                    # If multiple files need classification
                    file_items = []
                    for file_path in files_needing_classification:
                        file_name = os.path.basename(file_path)
                        file_items.append(f"- {file_name}")
                    
                    file_paths_str = "\n".join(file_items)
                    classification_query = f"H√£y ph√¢n lo·∫°i t·ª´ng file sau v√† tr·∫£ v·ªÅ k·∫øt qu·∫£ theo ƒë·ªãnh d·∫°ng 't√™n_file - ph√¢n_lo·∫°i':\n{file_paths_str}"
                    log(f"Running FileClassificationAgent with query for {len(files_needing_classification)} files: {classification_query[:100]}...")
                
                response = file_classification_agent.invoke(classification_query, self.session_id)
                log("FileClassificationAgent completed")
                
                # Log raw response for debugging
                log(f"Raw FileClassificationAgent response: {response}")
            else:
                log("Skipping FileClassificationAgent as all files have stored classifications")
                response = None

            # X·ª≠ l√Ω k·∫øt qu·∫£ t·ª´ FileClassificationAgent
            classification_result = ""
            
            # Only process response if we ran the classification agent
            if files_needing_classification and response is not None:
                # Tr∆∞·ªùng h·ª£p 1: Response l√† dict v·ªõi key 'content'
                if isinstance(response, dict) and 'content' in response:
                    classification_result = response['content']
                    log(f"Extracted classification from response dict: {classification_result}")
                
                # Tr∆∞·ªùng h·ª£p 2: Response l√† string
                elif isinstance(response, str):
                    classification_result = response
                    log(f"Response is already a string: {classification_result}")
            else:
                # If we didn't run the classification agent, we'll just use the stored classifications
                log("Using only stored classifications")
                classification_result = ""
                
            # Tr√≠ch xu·∫•t k·∫øt qu·∫£ ph√¢n lo·∫°i th·ª±c s·ª± t·ª´ ph·∫£n h·ªìi
            # T√¨m ki·∫øm m·∫´u "K·∫øt qu·∫£ ph√¢n lo·∫°i file" ho·∫∑c c√°c m·∫´u t∆∞∆°ng t·ª±
            if classification_result:
                import re
                # M·∫´u 1: K·∫øt qu·∫£ ph√¢n lo·∫°i file: XYZ
                pattern1 = r'K·∫øt qu·∫£ ph√¢n lo·∫°i file[^:]*:\s*([^\n\r]+)'
                # M·∫´u 2: XYZ (n·∫øu ph·∫£n h·ªìi ch·ªâ l√† k·∫øt qu·∫£ ph√¢n lo·∫°i)
                pattern2 = r'^([^\n\r:]+)$'
                
                match = re.search(pattern1, classification_result)
                if match:
                    classification_result = match.group(1).strip()
                    log(f"Extracted classification using pattern1: {classification_result}")
                else:
                    match = re.search(pattern2, classification_result)
                    if match and len(classification_result.split()) <= 5:  # N·∫øu ng·∫Øn g·ªçn (‚â§ 5 t·ª´)
                        classification_result = match.group(1).strip()
                        log(f"Extracted classification using pattern2: {classification_result}")
                    else:
                        log(f"Could not extract classification pattern from result, using as-is")
                        
                # Lo·∫°i b·ªè c√°c ph·∫ßn th·ª´a nh∆∞ "Ph√¢n lo·∫°i:", "K·∫øt qu·∫£:", v.v.
                prefixes_to_remove = ["ph√¢n lo·∫°i:", "k·∫øt qu·∫£:", "nh√£n:"]
                lower_result = classification_result.lower()
                for prefix in prefixes_to_remove:
                    if lower_result.startswith(prefix):
                        classification_result = classification_result[len(prefix):].strip()
                        log(f"Removed prefix '{prefix}' from result: {classification_result}")
                        break
            
            # Tr∆∞·ªùng h·ª£p 3: C√°c tr∆∞·ªùng h·ª£p kh√°c, chuy·ªÉn v·ªÅ string
            else:
                classification_result = str(response)
                log(f"Converted response to string: {classification_result}")

            # Ki·ªÉm tra k·∫øt qu·∫£ ph√¢n lo·∫°i v√† x·ª≠ l√Ω tr√πng l·∫∑p
            if not classification_result.strip():
                classification_result = "Kh√¥ng th·ªÉ ph√¢n lo·∫°i"
            else:
                # X·ª≠ l√Ω k·∫øt qu·∫£ ph√¢n lo·∫°i
                lines = classification_result.strip().split('\n')
                
                # Ki·ªÉm tra s·ªë l∆∞·ª£ng file v√† s·ªë l∆∞·ª£ng d√≤ng ph√¢n lo·∫°i
                if len(file_paths) > 1 and len(lines) > 1:
                    # N·∫øu c√≥ nhi·ªÅu file v√† nhi·ªÅu d√≤ng ph√¢n lo·∫°i, gi·ªØ nguy√™n k·∫øt qu·∫£
                    # v√¨ m·ªói d√≤ng c√≥ th·ªÉ l√† ph√¢n lo·∫°i cho m·ªôt file
                    log(f"Keeping multiple classification results for {len(file_paths)} files")
                elif len(lines) > 1 and len(set(lines)) == 1:
                    # N·∫øu t·∫•t c·∫£ c√°c d√≤ng gi·ªëng nhau, ch·ªâ gi·ªØ l·∫°i m·ªôt d√≤ng
                    classification_result = lines[0]
                    log(f"Removed duplicate classification results, using: {classification_result}")

            # Process any new classifications from the agent response
            if files_needing_classification and classification_result:
                log(f"Processing classification result: {classification_result}", level='info')
                
                # Check if the response is just the query repeated back
                if "H√£y ph√¢n lo·∫°i t·ª´ng file" in classification_result or "H√£y ph√¢n lo·∫°i file:" in classification_result:
                    log("Classification agent returned the query instead of results, using smart default classification", level='info')
                    # Use a smart default classification based on file name and content
                    for file_path in files_needing_classification:
                        file_name = os.path.basename(file_path)
                        # Try to determine a better default classification based on file name
                        default_classification = "T√†i li·ªáu kh√°c"
                        
                        # Check file name for common keywords
                        file_name_lower = file_name.lower()
                        if any(keyword in file_name_lower for keyword in ["admin", "qu·∫£n tr·ªã", "user", "permission", "quy·ªÅn", "role", "vai tr√≤"]):
                            default_classification = "T√†i li·ªáu qu·∫£n tr·ªã n·ªôi b·ªô"
                        elif any(keyword in file_name_lower for keyword in ["t√†i ch√≠nh", "finance", "budget", "ng√¢n s√°ch", "chi ph√≠", "cost", "revenue", "doanh thu"]):
                            default_classification = "T√†i li·ªáu t√†i ch√≠nh"
                        elif any(keyword in file_name_lower for keyword in ["tech", "k·ªπ thu·∫≠t", "code", "api", "system", "h·ªá th·ªëng", "c·∫•u h√¨nh"]):
                            default_classification = "T√†i li·ªáu k·ªπ thu·∫≠t"
                        elif any(keyword in file_name_lower for keyword in ["edu", "gi√°o d·ª•c", "h·ªçc", "training", "ƒë√†o t·∫°o", "course", "kh√≥a h·ªçc"]):
                            default_classification = "T√†i li·ªáu gi√°o d·ª•c"
                        
                        final_classifications[file_name] = default_classification
                        log(f"Using smart default classification for {file_name}: {default_classification}", level='info')
                else:
                    # Try to parse the classification results
                    lines = classification_result.strip().split('\n')
                    classification_found = False
                    
                    # First try to find lines with the format "filename - classification"
                    for line in lines:
                        if '-' in line:
                            parts = line.split('-', 1)
                            if len(parts) == 2:
                                file_name = parts[0].strip()
                                classification = parts[1].strip()
                                final_classifications[file_name] = classification
                                classification_found = True
                                log(f"Added new classification for {file_name}: {classification}", level='info')
                    
                    # If no classifications were found and we only have one file, use the entire response
                    if not classification_found and len(files_needing_classification) == 1:
                        file_name = os.path.basename(files_needing_classification[0])
                        
                        # Check for common patterns in the response
                        if "ph√¢n lo·∫°i:" in classification_result.lower():
                            # Try to extract the classification after "ph√¢n lo·∫°i:"
                            match = re.search(r'ph√¢n lo·∫°i:\s*([^\n]+)', classification_result.lower())
                            if match:
                                classification = match.group(1).strip()
                                final_classifications[file_name] = classification
                                log(f"Extracted classification after 'ph√¢n lo·∫°i:' for {file_name}: {classification}", level='info')
                                classification_found = True
                        
                        # If still no classification found, use the entire response
                        if not classification_found:
                            final_classifications[file_name] = classification_result.strip()
                            log(f"Added single classification for {file_name}: {classification_result.strip()}", level='info')
            
            # Format the response with all classifications (stored + new)
            if final_classifications:
                if len(final_classifications) == 1:
                    file_name = list(final_classifications.keys())[0]
                    classification = final_classifications[file_name]
                    response_content = f"üè∑Ô∏è K·∫øt qu·∫£ ph√¢n lo·∫°i file {file_name}: {classification}"
                else:
                    # Multiple files
                    classifications = []
                    for file_name, classification in final_classifications.items():
                        # Mark stored classifications
                        is_stored = any(file_name == os.path.basename(k) for k in stored_classifications)
                        source = " (t·ª´ ph·∫£n h·ªìi ng∆∞·ªùi d√πng)" if is_stored else ""
                        classifications.append(f"{file_name}: {classification}{source}")
                    
                    formatted_classifications = "\n- ".join(classifications)
                    response_content = f"üè∑Ô∏è K·∫øt qu·∫£ ph√¢n lo·∫°i {len(final_classifications)} files:\n- {formatted_classifications}"
            else:
                response_content = f"üè∑Ô∏è Kh√¥ng c√≥ k·∫øt qu·∫£ ph√¢n lo·∫°i"
            
            log(f"Final classification response: {response_content}")
            
            # Add the response to the state
            state["messages"].append(AIMessage(content=response_content))
            
            # Store result in agent_results
            if "agent_results" not in state:
                state["agent_results"] = {}
            
            if len(final_classifications) == 1:
                state["agent_results"]["file_classification"] = list(final_classifications.values())[0]
            else:
                state["agent_results"]["file_classification"] = "\n".join([f"{k}: {v}" for k, v in final_classifications.items()])
            
            # Store classified files in state
            if file_paths:
                state["classified_files"] = file_paths
            
            # Store classification labels in state
            # Make sure we store both filename and full path as keys for better matching
            classification_labels = {}
            for file_name, classification in final_classifications.items():
                classification_labels[file_name] = classification
                # Also try to find the full path for this file name
                for file_path in file_paths:
                    if os.path.basename(file_path) == file_name:
                        classification_labels[file_path] = classification
                        break
            
            state["classification_labels"] = classification_labels
            log(f"Final classification labels stored in state: {classification_labels}")
            
            # Analyze the response to suggest next agent
            log("Analyzing response to suggest next agent...")
            next_agent = await self._suggest_next_agent(classification_result, state)
            if next_agent and next_agent not in state["current_agents"]:
                log(f"Adding {next_agent} to current_agents")
                state["current_agents"].append(next_agent)
            else:
                log(f"No additional agent suggested or already in use")

            return state

        except Exception as e:
            log(f"Error running file classification agent: {e}", level='error')
            # Add an error message to the state
            error_message = f"Xin l·ªói, t√¥i g·∫∑p l·ªói khi ph√¢n lo·∫°i t·ªáp: {str(e)}"
            state["messages"].append(AIMessage(content=error_message))
            return state

    async def plan_agents(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """Enhanced agent planning that includes data analysis for comparison queries."""
        last_message = state["messages"][-1]
        query = last_message.content
        
        try:
            # Enhanced planning prompt that includes data analysis
            planning_prompt = f"""
            B·∫°n l√† m·ªôt h·ªá th·ªëng ƒëi·ªÅu ph·ªëi c√°c agent AI chuy√™n bi·ªát. D·ª±a tr√™n y√™u c·∫ßu c·ªßa ng∆∞·ªùi d√πng, h√£y l·∫≠p k·∫ø ho·∫°ch s·ª≠ d·ª•ng c√°c agent ph√π h·ª£p.
            
            Y√™u c·∫ßu c·ªßa ng∆∞·ªùi d√πng: "{query}"
        
            C√°c agent c√≥ s·∫µn:
            1. filesystem - T√¨m ki·∫øm, li·ªát k√™ v√† qu·∫£n l√Ω t·ªáp v√† th∆∞ m·ª•c theo t√™n file
            2. rag - T√¨m ki·∫øm t√†i li·ªáu theo n·ªôi dung ho·∫∑c ng·ªØ nghƒ©a
            3. metadata - T·∫°o v√† qu·∫£n l√Ω metadata cho t√†i li·ªáu
            4. text_extraction - Tr√≠ch xu·∫•t vƒÉn b·∫£n t·ª´ t·ªáp PDF, Word ho·∫∑c PowerPoint
            5. file_classification - Ph√¢n lo·∫°i n·ªôi dung t√†i li·ªáu
            6. data_analysis - Ph√¢n t√≠ch v√† so s√°nh d·ªØ li·ªáu t·ª´ nhi·ªÅu ngu·ªìn (ƒë·∫∑c bi·ªát cho d·ªØ li·ªáu t√†i ch√≠nh)
            
            QUAN TR·ªåNG - LU·∫¨T S·ª¨ D·ª§NG DATA_ANALYSIS:
            - N·∫øu y√™u c·∫ßu c√≥ ch·ª©a t·ª´ kh√≥a "so s√°nh", "ph√¢n t√≠ch", "compare", "analysis", "xu h∆∞·ªõng", "tƒÉng tr∆∞·ªüng" th√¨ PH·∫¢I s·ª≠ d·ª•ng data_analysis
            - Th·ª© t·ª± b·∫Øt bu·ªôc cho ph√¢n t√≠ch d·ªØ li·ªáu: rag -> text_extraction -> data_analysis
            - KH√îNG s·ª≠ d·ª•ng file_classification ho·∫∑c metadata trong workflow ph√¢n t√≠ch d·ªØ li·ªáu tr·ª´ khi ƒë∆∞·ª£c y√™u c·∫ßu c·ª• th·ªÉ
        
            L∆ØU √ù QUAN TR·ªåNG:
            - N·∫øu y√™u c·∫ßu ch·ªâ li√™n quan ƒë·∫øn t√¨m ki·∫øm file th√¨ ch·ªâ s·ª≠ d·ª•ng rag ho·∫∑c filesystem
            - N·∫øu y√™u c·∫ßu li√™n quan ƒë·∫øn so s√°nh d·ªØ li·ªáu t√†i ch√≠nh, s·ª≠ d·ª•ng: rag, text_extraction, data_analysis
            - N·∫øu y√™u c·∫ßu li√™n quan ƒë·∫øn vi·ªác l∆∞u metadata, th·ª© t·ª±: rag/filesystem -> text_extraction -> file_classification -> metadata
        
            H√£y l·∫≠p k·∫ø ho·∫°ch s·ª≠ d·ª•ng c√°c agent. ƒê·∫ßu ti√™n, tr·∫£ l·ªùi v·ªõi danh s√°ch c√°c agent c·∫ßn s·ª≠ d·ª•ng theo th·ª© t·ª±, ch·ªâ li·ªát k√™ t√™n c√°c agent, c√°ch nhau b·∫±ng d·∫•u ph·∫©y.
        
            Sau ƒë√≥, vi·∫øt m·ªôt ƒëo·∫°n vƒÉn ng·∫Øn gi·∫£i th√≠ch k·∫ø ho·∫°ch c·ªßa b·∫°n b·∫±ng ti·∫øng Vi·ªát.
        """
        
        # Use LLM to plan
            from config.llm import gemini
            response = await gemini.ainvoke(planning_prompt)
            plan_response = response.content.strip()
            
            # Parse agent list and explanation
            parts = plan_response.split('\n', 1)
            agent_list = parts[0].strip().lower()
            plan_message = parts[1].strip() if len(parts) > 1 else f"T√¥i s·∫Ω gi√∫p b·∫°n v·ªõi y√™u c·∫ßu: '{query}'."
            
            # Process agent list
            needed_agents = []
            valid_agents = ["filesystem", "rag", "metadata", "text_extraction", "file_classification", "data_analysis"]
            
            for agent in valid_agents:
                if agent in agent_list:
                    needed_agents.append(agent)
            
            # Special handling for comparison queries
            comparison_keywords = ["so s√°nh", "compare", "ph√¢n t√≠ch", "analysis", "xu h∆∞·ªõng", "tƒÉng tr∆∞·ªüng"]
            if any(keyword in query.lower() for keyword in comparison_keywords):
                # Force the correct order for data analysis
                if "data_analysis" in needed_agents:
                    # Ensure correct order: rag -> text_extraction -> data_analysis
                    ordered_agents = []
                    if "rag" in needed_agents or not any(agent in needed_agents for agent in ["filesystem", "rag"]):
                        ordered_agents.append("rag")
                    elif "filesystem" in needed_agents:
                        ordered_agents.append("filesystem")
                    
                    if "text_extraction" not in needed_agents:
                        ordered_agents.append("text_extraction")
                    else:
                        ordered_agents.append("text_extraction")
                    
                    ordered_agents.append("data_analysis")
                    needed_agents = ordered_agents
                    
                    plan_message = f"T√¥i s·∫Ω th·ª±c hi·ªán ph√¢n t√≠ch so s√°nh d·ªØ li·ªáu theo th·ª© t·ª±: {', '.join(needed_agents)}."
            
            if not needed_agents:
                needed_agents.append("rag")
                plan_message += "\nT√¥i s·∫Ω b·∫Øt ƒë·∫ßu v·ªõi RAG Agent ƒë·ªÉ t√¨m ki·∫øm th√¥ng tin."
            
            log(f"Enhanced agent plan: {needed_agents}")
            
        except Exception as e:
            log(f"Error in enhanced agent planning: {e}", level='error')
            # Default for comparison queries
            if any(keyword in query.lower() for keyword in ["so s√°nh", "compare", "ph√¢n t√≠ch"]):
                needed_agents = ["rag", "text_extraction", "data_analysis"]
                plan_message = f"T√¥i s·∫Ω th·ª±c hi·ªán ph√¢n t√≠ch so s√°nh d·ªØ li·ªáu: t√¨m ki·∫øm file, tr√≠ch xu·∫•t n·ªôi dung, v√† ph√¢n t√≠ch d·ªØ li·ªáu."
            else:
                needed_agents = ["rag"]
                plan_message = f"T√¥i s·∫Ω gi√∫p b·∫°n v·ªõi y√™u c·∫ßu: '{query}'. B·∫Øt ƒë·∫ßu v·ªõi RAG Agent."
    
    # Update state with the plan
        state["current_agents"] = needed_agents
        state["messages"].append(AIMessage(content=plan_message))
        
        return state
        
    async def run(self, query: str, session_id: str = None, user_role: str = "user") -> Dict[str, Any]:
        """
        Run the multi-agent system with the given query.
        
        Args:
            query: C√¢u truy v·∫•n c·ªßa ng∆∞·ªùi d√πng
            session_id: ID phi√™n l√†m vi·ªác, ƒë∆∞·ª£c t·∫°o t·ª± ƒë·ªông n·∫øu kh√¥ng cung c·∫•p
            user_role: Vai tr√≤ c·ªßa ng∆∞·ªùi d√πng, m·∫∑c ƒë·ªãnh l√† "user"
        
        Returns:
            Dict ch·ª©a k·∫øt qu·∫£ v√† tr·∫°ng th√°i c·ªßa h·ªá th·ªëng
        """
        try:
            # Set session ID
            self.session_id = session_id or str(uuid.uuid4())
            
            # Reinitialize human_feedback_agent with the correct session_id
            from agents.human_feedback_agent import HumanFeedbackAgent
            self.human_feedback_agent = HumanFeedbackAgent(session_id=self.session_id)
            
            # Initialize state
            state = {
                "messages": [HumanMessage(content=query)],
                "current_agents": [],
                "task_complete": False,
                "require_user_input": False,
                "feedback_on_work": None,
                "success_criteria_met": False,
                "completed": False,
                "used_tools": [],
                "chain_of_thought": ["üîç1. B·∫Øt ƒë·∫ßu x·ª≠ l√Ω y√™u c·∫ßu: " + query],
                "agent_results": {},
                "original_query": query,
                "user_role": user_role  # Th√™m vai tr√≤ ng∆∞·ªùi d√πng v√†o state
            }
            
            # Ki·ªÉm tra xem tin nh·∫Øn c√≥ ph·∫£i l√† ph·∫£n h·ªìi kh√¥ng tr∆∞·ªõc khi l·∫≠p k·∫ø ho·∫°ch
            message_lower = query.lower()
            is_feedback = False
            
            # Ki·ªÉm tra tr·ª±c ti·∫øp c√°c pattern ph·ªï bi·∫øn
            if ".pdf" in message_lower and "ph√¢n lo·∫°i ƒë√∫ng l√†" in message_lower:
                log("üéØ [RUN] Ph√°t hi·ªán pattern '.pdf ph√¢n lo·∫°i ƒë√∫ng l√†', x·ª≠ l√Ω nh∆∞ feedback", level='info')
                is_feedback = True
            elif ".pdf" in message_lower and "kh√¥ng ph·∫£i lo·∫°i" in message_lower:
                log("üéØ [RUN] Ph√°t hi·ªán pattern '.pdf kh√¥ng ph·∫£i lo·∫°i', x·ª≠ l√Ω nh∆∞ feedback", level='info')
                is_feedback = True
            elif "finance2023.pdf kh√¥ng ph·∫£i lo·∫°i" in message_lower:
                log("üéØ [RUN] Ph√°t hi·ªán pattern 'finance2023.pdf kh√¥ng ph·∫£i lo·∫°i', x·ª≠ l√Ω nh∆∞ feedback", level='info')
                is_feedback = True
            elif "kh√¥ng ph·∫£i lo·∫°i" in message_lower and "ph·∫£i c·ª• th·ªÉ h∆°n" in message_lower:
                log("üéØ [RUN] Ph√°t hi·ªán pattern 'kh√¥ng ph·∫£i lo·∫°i' + 'ph·∫£i c·ª• th·ªÉ h∆°n', x·ª≠ l√Ω nh∆∞ feedback", level='info')
                is_feedback = True
            
            # Ki·ªÉm tra th√¥ng qua human_feedback_agent n·∫øu c√≥
            if not is_feedback and self.human_feedback_agent:
                try:
                    is_feedback = await self.human_feedback_agent.is_feedback_message(query)
                    log(f"üîç [RUN] K·∫øt qu·∫£ ki·ªÉm tra feedback t·ª´ human_feedback_agent: {is_feedback}", level='info')
                except Exception as e:
                    log(f"‚ö†Ô∏è [RUN] L·ªói khi ki·ªÉm tra feedback: {str(e)}", level='error')
            
            # N·∫øu l√† ph·∫£n h·ªìi, x·ª≠ l√Ω tr·ª±c ti·∫øp
            if is_feedback:
                log("‚úÖ [RUN] Ph√°t hi·ªán ph·∫£n h·ªìi, x·ª≠ l√Ω tr·ª±c ti·∫øp", level='info')
                state["is_feedback"] = True
                state["chain_of_thought"].append("üîÑ Ph√°t hi·ªán ph·∫£n h·ªìi t·ª´ ng∆∞·ªùi d√πng, chuy·ªÉn sang x·ª≠ l√Ω ph·∫£n h·ªìi")
                try:
                    state = await self.process_human_feedback(state)
                except Exception as e:
                    log(f"‚ö†Ô∏è [RUN] L·ªói khi x·ª≠ l√Ω ph·∫£n h·ªìi: {str(e)}", level='error')
                    import traceback
                    traceback.print_exc()
                    # Th√™m th√¥ng b√°o l·ªói v√†o state
                    state["messages"].append(AIMessage(content=f"‚ùå ƒê√£ x·∫£y ra l·ªói khi x·ª≠ l√Ω ph·∫£n h·ªìi: {str(e)}"))
                
                # T·∫°o ph·∫£n h·ªìi cu·ªëi c√πng
                final_content = "C·∫£m ∆°n b·∫°n ƒë√£ cung c·∫•p ph·∫£n h·ªìi. T√¥i ƒë√£ ghi nh·∫≠n v√† c·∫≠p nh·∫≠t th√¥ng tin ph√¢n lo·∫°i."
                state["messages"].append(AIMessage(content=final_content))
                
                return {
                    "response_type": "data",
                    "content": final_content,
                    "is_task_complete": True,
                    "require_user_input": False,
                    "chain_of_thought": state["chain_of_thought"]
                }
            
            # N·∫øu kh√¥ng ph·∫£i ph·∫£n h·ªìi, ti·∫øp t·ª•c quy tr√¨nh b√¨nh th∆∞·ªùng
            # Plan which agents to use
            state = await self.plan_agents(state)
            log(f"K·∫ø ho·∫°ch agent ban ƒë·∫ßu: {state['current_agents']}")
            
            # Validate and fix agent sequence if needed
            state = await self._validate_agent_sequence(state)
            log(f"K·∫ø ho·∫°ch agent sau khi ki·ªÉm tra: {state['current_agents']}")
            state["chain_of_thought"].append(f"üß†2. L·∫≠p k·∫ø ho·∫°ch s·ª≠ d·ª•ng c√°c agent: {', '.join(state['current_agents'])}")
            
            
            # Run the agents in the planned order
            step_count = 3
            agent_execution_order = []
            
            while not state.get("completed", False) and state["current_agents"]:
                agent_name = state["current_agents"].pop(0)
                agent_execution_order.append(agent_name)
                log(f"Running {agent_name} agent...")
                state["chain_of_thought"].append(f"‚ö°{step_count}. ƒêang ch·∫°y agent: {agent_name}")
                
                # Track agent execution order
                if "agent_execution_order" not in state:
                    state["agent_execution_order"] = []
                state["agent_execution_order"].append(agent_name)
                
                # Count messages before running the agent
                pre_run_messages_count = len(state["messages"])
                
                # Run the agent
                if agent_name == "filesystem":
                    state = await self.run_filesystem_agent(state)
                elif agent_name == "text_extraction":
                    state = await self.run_text_extraction_agent(state)
                    
                    # Ki·ªÉm tra c·ªù stop_processing sau khi ch·∫°y text_extraction
                    if state.get("stop_processing", False):
                        log(f"Stopping processing due to: {state.get('stop_reason', 'unknown reason')}", level='warning')
                        state["chain_of_thought"].append(f"üõë D·ª´ng x·ª≠ l√Ω: {state.get('stop_reason', 'L·ªói kh√¥ng x√°c ƒë·ªãnh')}")
                        break
                        
                elif agent_name == "file_classification":
                    state = await self.run_file_classification_agent(state)
                elif agent_name == "metadata":
                    state = await self.run_metadata_agent(state)
                elif agent_name == "rag":
                    state = await self.run_rag_agent(state)
                elif agent_name == "data_analysis":
                    state = await self.run_data_analysis_agent(state)
                else:
                    log(f"Unknown agent: {agent_name}")
                    
                # Ki·ªÉm tra c·ªù stop_processing sau khi ch·∫°y b·∫•t k·ª≥ agent n√†o
                if state.get("stop_processing", False):
                    log(f"Stopping processing due to: {state.get('stop_reason', 'unknown reason')}", level='warning')
                    state["chain_of_thought"].append(f"üõë D·ª´ng x·ª≠ l√Ω: {state.get('stop_reason', 'L·ªói kh√¥ng x√°c ƒë·ªãnh')}")
                    break
                
                # L·∫•y k·∫øt qu·∫£ m·ªõi nh·∫•t t·ª´ agent
                if len(state["messages"]) > pre_run_messages_count:
                    latest_message = state["messages"][-1].content
                    # R√∫t g·ªçn n·ªôi dung ƒë·ªÉ hi·ªÉn th·ªã trong chain of thought
                    if len(latest_message) > 200:
                        summary = latest_message[:197] + "..."
                    else:
                        summary = latest_message
                    state["chain_of_thought"].append(f"‚ú®{step_count}a. K·∫øt qu·∫£ t·ª´ {agent_name}: {summary}")
                
                step_count += 1
            
            # Run reflection agent to create final response
            log("Running reflection agent for final response...")
            state["chain_of_thought"].append(f"ü§î{step_count}. ƒêang t·∫°o c√¢u tr·∫£ l·ªùi cu·ªëi c√πng...")
            state = await self.run_reflection_agent(state)
            
            # Mark as completed
            state["completed"] = True
            state["chain_of_thought"].append(f"üöÄ{step_count + 1}. Ho√†n th√†nh x·ª≠ l√Ω")
            
            # # Generate execution summary
            # agent_summary = ""
            # if "agent_execution_order" in state:
            #     agent_summary = f"Th·ª© t·ª± th·ª±c thi c√°c agent: {', '.join(state['agent_execution_order'])}"
            #     log(f"Agent execution summary: {agent_summary}")
            #     state["chain_of_thought"].append(f"üîçT√≥m t·∫Øt th·ª±c thi: {agent_summary}")
            
            # Add used tools to the summary
            log(f"Used tools: {state.get('used_tools', [])}")
            
            # Get the final reflection response for the main content
            final_reflection_content = ""
            for message in reversed(state["messages"]):
                if isinstance(message, AIMessage) and message.content.startswith("üí≠"):
                    final_reflection_content = message.content[2:].strip()  # Remove üí≠ emoji
                    break
            
            # Return the final state with reflection as main content
            return {
                "response_type": "data",
                "is_task_complete": True,
                "require_user_input": False,
                "content": final_reflection_content if final_reflection_content else state["messages"][-1].content,
                "state": state,
                "chain_of_thought": state["chain_of_thought"],
                "agent_execution_order": state.get("agent_execution_order", []),
                "used_tools": state.get("used_tools", []),
                "agent_results": state.get("agent_results", {})
            }
        except Exception as e:
            log(f"Error running multi-agent system: {e}", level='error')
            return {
                "response_type": "error",
                "content": f"Xin l·ªói, ƒë√£ x·∫£y ra l·ªói: {str(e)}",
                "is_task_complete": False,
                "require_user_input": False,
                "chain_of_thought": [f"‚ùåL·ªói: {str(e)}"]
            }
             
    async def stream(self, query: str, session_id: str = "default", user_role: str = "user") -> AsyncGenerator[Dict[str, Any], None]:
        """
        Stream the multi-agent system's response.
        
        Args:
            query: The user's query
            session_id: Session ID for memory management
            user_role: Vai tr√≤ c·ªßa ng∆∞·ªùi d√πng, m·∫∑c ƒë·ªãnh l√† "user"
            
        Yields:
            Dict with partial response content and metadata
        """
        try:
            # Initialize the agent if not already initialized
            if not self.graph:
                await self.initialize()
                
            # Set the session ID for this run
            self.session_id = session_id
            
            # Create the initial state
            initial_state = {
                "messages": [HumanMessage(content=query)],
                "current_agents": [],
                "task_complete": False,
                "require_user_input": False,
                "feedback_on_work": None,
                "success_criteria_met": False,
                "used_tools": [],
                "agent_results": {},
                "original_query": query,
                "user_role": user_role  # Th√™m vai tr√≤ ng∆∞·ªùi d√πng v√†o state
            }
            
            # Stream the graph execution
            config = {"configurable": {"thread_id": session_id}}
            async for chunk in self.graph.astream(initial_state, config=config):
                # Extract the latest message
                if "messages" in chunk and chunk["messages"]:
                    # Find the latest non-evaluator message
                    latest_message = None
                    for message in reversed(chunk["messages"]):
                        if isinstance(message, AIMessage) and not message.content.startswith("[ƒê√°nh gi√° n·ªôi b·ªô:"):
                            latest_message = message
                            break
                    
                    if latest_message:
                        # Check if this is the final reflection message
                        is_reflection = latest_message.content.startswith("üí≠")
                        content = latest_message.content[2:].strip() if is_reflection else latest_message.content
                        
                        # Yield the partial response
                        yield {
                            "response_type": "text",
                            "content": content,
                            "is_task_complete": chunk.get("success_criteria_met", False),
                            "require_user_input": chunk.get("require_user_input", False),
                            "is_partial": not is_reflection,  # Reflection is the final response
                            "used_tools": chunk.get("used_tools", []),
                            "is_reflection": is_reflection
                        }
            
            # Yield the final complete response
            final_state = await self.graph.ainvoke(initial_state, config=config)
            
            # Find the final reflection message
            final_message = None
            for message in reversed(final_state["messages"]):
                if isinstance(message, AIMessage) and message.content.startswith("üí≠"):
                    final_message = message
                    break
            
            # If no reflection found, use the last non-evaluator message
            if not final_message:
                for message in reversed(final_state["messages"]):
                    if isinstance(message, AIMessage) and not message.content.startswith("[ƒê√°nh gi√° n·ªôi b·ªô:"):
                        final_message = message
                        break
            
            if not final_message:
                final_message = final_state["messages"][-1] if final_state["messages"] else AIMessage(content="Kh√¥ng c√≥ ph·∫£n h·ªìi t·ª´ h·ªá th·ªëng.")
            
            # Extract content, removing emoji if it's a reflection
            content = final_message.content
            if content.startswith("üí≠"):
                content = content[2:].strip()
            
            yield {
                "response_type": "text",
                "content": content,
                "is_task_complete": final_state.get("success_criteria_met", False),
                "require_user_input": final_state.get("require_user_input", False),
                "is_partial": False,
                "used_tools": final_state.get("used_tools", []),
                "is_reflection": True
            }
            
        except Exception as e:
            print(f"Error streaming multi-agent system: {e}")
            yield {
                "response_type": "error",
                "content": f"Xin l·ªói, ƒë√£ x·∫£y ra l·ªói: {str(e)}",
                "is_task_complete": False,
                "require_user_input": False,
                "is_partial": False
            }

# Business domain-specific agents (placeholders for future implementation)
class BusinessAnalysisAgent:
    """Agent specialized in business analysis tasks."""
    pass

class FinanceAgent:
    """Agent specialized in finance and accounting tasks."""
    pass

class HRAgent:
    """Agent specialized in HR and personnel management tasks."""
    pass


async def main():
    """
    Test the enhanced worker-evaluator multi-agent system with reflection.
    """
    try:
        # Initialize the multi-agent system
        multi_agent = await MultiAgentSystem().initialize()
        session_id = "test_session_reflection_123"
        
        # Test v·ªõi c√¢u truy v·∫•n metadata v√† vai tr√≤ ng∆∞·ªùi d√πng
        query1 = "T√¨m file c√≥ n·ªôi dung K·∫ø ho·∫°ch sau ƒë√≥ l∆∞u metadata"
        print(f"\nTest Query 1: {query1}")
        print("Running with reflection agent...")
        
        # Test v·ªõi vai tr√≤ admin
        result1 = await multi_agent.run(query1, session_id=f"{session_id}_admin", user_role="admin")
        print(f"\nMain Response: {result1.get('content', 'No content')}")
        print(f"Used tools: {result1.get('used_tools', [])}")
        print(f"Agent execution order: {result1.get('agent_execution_order', [])}")
        
        if result1.get('chain_of_thought'):
            print("\nChain of Thought:")
            for i, thought in enumerate(result1['chain_of_thought'], 1):
                print(f"{i}. {thought}")
        
        
    except Exception as e:
        print(f"Error in main: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    import uuid
    import asyncio
    
    async def test_feedback_detection():
        print("=== Test ph√°t hi·ªán ph·∫£n h·ªìi t·ª´ ng∆∞·ªùi d√πng ===\n")
        
        # Kh·ªüi t·∫°o h·ªá th·ªëng ƒëa t√°c t·ª≠
        system = MultiAgentSystem()
        await system.initialize()
        
        # C√°c v√≠ d·ª• ph·∫£n h·ªìi c·∫ßn ki·ªÉm tra
        test_messages = [
            "finance2023.pdf kh√¥ng ph·∫£i lo·∫°i B√°o c√°o doanh thu m√† ph·∫£i c·ª• th·ªÉ h∆°n v√≠ d·ª• B√°o c√°o doanh thu 2023",

            "T√¨m file c√≥ n·ªôi dung Doanh thu",  # Kh√¥ng ph·∫£i feedback
        ]
        
        # Ki·ªÉm tra t·ª´ng tin nh·∫Øn
        for i, message in enumerate(test_messages, 1):
            is_feedback = await system.human_feedback_agent.is_feedback_message(message)
            print(f"Tin nh·∫Øn {i}: '{message}'")
            print(f"‚Üí Ph√°t hi·ªán l√† feedback: {is_feedback}\n")
        
        # Test x·ª≠ l√Ω ph·∫£n h·ªìi c·ª• th·ªÉ
        print("\n=== Test x·ª≠ l√Ω ph·∫£n h·ªìi ===\n")
        
        # T·∫°o tr·∫°ng th√°i ban ƒë·∫ßu v·ªõi k·∫øt qu·∫£ ph√¢n lo·∫°i
        test_state = {
            "messages": [
                SystemMessage(content="H·ªá th·ªëng ph√¢n lo·∫°i t√†i li·ªáu"),
                AIMessage(content="üóÇÔ∏è Ch√†o b·∫°n, m√¨nh ƒë√£ t√¨m th·∫•y 2 file ch·ª©a n·ªôi dung li√™n quan ƒë·∫øn \"Doanh thu\" v√† ch√∫ng ƒë·ªÅu ƒë∆∞·ª£c ph√¢n lo·∫°i l√† \"B√°o c√°o doanh thu\", bao g·ªìm finance2024.pdf v√† finance2023.pdf.")
            ],
            "classification_results": {
                "finance2024.pdf": {"label": "B√°o c√°o doanh thu", "confidence": 0.9},
                "finance2023.pdf": {"label": "B√°o c√°o doanh thu", "confidence": 0.85}
            },
            "current_agents": [],
            "used_tools": ["rag_agent", "file_classification_agent"],
            "chain_of_thought": []
        }
        
        # Th√™m ph·∫£n h·ªìi t·ª´ ng∆∞·ªùi d√πng
        feedback = "finance2023.pdf kh√¥ng ph·∫£i lo·∫°i B√°o c√°o doanh thu m√† ph·∫£i c·ª• th·ªÉ h∆°n v√≠ d·ª• B√°o c√°o doanh thu 2023"
        test_state["messages"].append(HumanMessage(content=feedback))
        
        print("Tr·∫°ng th√°i ban ƒë·∫ßu:")
        for file, info in test_state["classification_results"].items():
            print(f"- {file}: {info['label']} ({info['confidence']:.0%} tin c·∫≠y)")
        
        # X·ª≠ l√Ω ph·∫£n h·ªìi tr·ª±c ti·∫øp
        updated_state = await system.process_human_feedback(test_state)
        
        print("\nTr·∫°ng th√°i sau khi x·ª≠ l√Ω ph·∫£n h·ªìi:")
        for file, info in updated_state["classification_results"].items():
            print(f"- {file}: {info['label']} ({info.get('confidence', 1.0):.0%} tin c·∫≠y)")
        
        if "chain_of_thought" in updated_state:
            print("\nChain of thought:")
            for thought in updated_state["chain_of_thought"]:
                print(f"- {thought}")
                
        # Ki·ªÉm tra worker_router
        print("\n=== Test worker_router ===\n")
        route = await system.worker_router(updated_state)
        print(f"Route t·ª´ worker_router: {route}")
        
        print("\n=== Test ho√†n th√†nh ===")

    asyncio.run(test_feedback_detection())  # Ch·∫°y test ph√°t hi·ªán feedback
    #