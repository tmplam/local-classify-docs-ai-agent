import os
import sys
import asyncio
import re
from typing import Dict, List, Any, Optional, Annotated, Tuple, Union

from typing import Dict, Any, List, AsyncIterable, TypedDict, Annotated, Optional
from langchain_mcp_adapters.client import MultiServerMCPClient
from typing_extensions import AsyncGenerator
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from utils.logger import log

from langchain_core.messages import AIMessage, HumanMessage, SystemMessage
from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langchain_mcp_adapters.client import MultiServerMCPClient
from pydantic import BaseModel, Field

from config.llm import gemini
from agents.filesystem_agent import FilesystemAgent
from agents.metadata_agent import MetadataAgent
from agents.text_extraction_agent import TextExtractionAgent
from agents.file_classification_agent import FileClassificationAgent
from agents.rag_agent import RAGAgent

# Global MemorySaver instance shared by all agents
memory = MemorySaver()

# Setup MCP client for filesystem access
mcp_client = MultiServerMCPClient({
    "document_search": {
        "command": "cmd",
        "args": [
            "/c",
            "npx",
            "-y",
            "@modelcontextprotocol/server-filesystem",
            "C:\\Users\\dhuu3\\Desktop\\local-classify-docs-ai-agent\\data",
        ],
        "transport": "stdio",
    }
})

# Define the state for our multi-agent system
class AgentState(TypedDict):
    messages: Annotated[List[Any], add_messages]  # Messages in the conversation
    current_agents: List[str]  # Which agents are currently active or have been used
    task_complete: bool  # Whether the task is complete
    require_user_input: bool  # Whether user input is needed
    feedback_on_work: Optional[str]  # Feedback from evaluator
    success_criteria_met: bool  # Whether success criteria have been met
    used_tools: List[str]  # Tools that have been used
    chain_of_thought: List[str]  # Detailed execution steps
    agent_results: Dict[str, str]  # Results from each agent
    original_query: str  # Original user query for reflection

class ReflectionAgent:
    """
    Agent chuyÃªn vá» reflection - tá»•ng há»£p vÃ  tráº£ lá»i cuá»‘i cÃ¹ng cho ngÆ°á»i dÃ¹ng
    dá»±a trÃªn káº¿t quáº£ tá»« cÃ¡c agent khÃ¡c vÃ  query ban Ä‘áº§u.
    """
    
    def __init__(self):
        """Initialize the ReflectionAgent."""
        self.model = gemini
    
    async def reflect_and_respond(self, state: AgentState) -> str:
        """
        PhÃ¢n tÃ­ch káº¿t quáº£ tá»« cÃ¡c agent vÃ  táº¡o cÃ¢u tráº£ lá»i cuá»‘i cÃ¹ng cÃ³ ngá»¯ nghÄ©a tá»‘t.
        
        Args:
            state: Tráº¡ng thÃ¡i hiá»‡n táº¡i cá»§a há»‡ thá»‘ng
            
        Returns:
            CÃ¢u tráº£ lá»i cuá»‘i cÃ¹ng Ä‘Æ°á»£c tá»‘i Æ°u hÃ³a cho ngÆ°á»i dÃ¹ng
        """
        try:
            # Láº¥y query ban Ä‘áº§u
            original_query = state.get("original_query", "")
            if not original_query:
                # Fallback: tÃ¬m trong messages
                for message in state["messages"]:
                    if isinstance(message, HumanMessage):
                        original_query = message.content
                        break
            
            # Thu tháº­p káº¿t quáº£ tá»« cÃ¡c agent
            agent_results = state.get("agent_results", {})
            used_tools = state.get("used_tools", [])
            chain_of_thought = state.get("chain_of_thought", [])
            
            # Táº¡o tÃ³m táº¯t cÃ¡c káº¿t quáº£ quan trá»ng
            key_findings = []
            file_found = None
            extraction_result = None
            classification_result = None
            metadata_ids = []
            
            # Thu tháº­p thÃ´ng tin chi tiáº¿t vá» file - Sá»¬ Dá»¤NG Má»˜T NGUá»’N DUY NHáº¤T
            detailed_files = []
            classification_labels = state.get("classification_labels", {})
            
            # Láº¥y file count tá»« state trÆ°á»›c tiÃªn (Ä‘Ã¢y lÃ  nguá»“n tin cáº­y nháº¥t)
            file_count = state.get("file_count", 0)
            actual_files = []
            
            # XÃ¡c Ä‘á»‹nh nguá»“n file paths chÃ­nh xÃ¡c
            if "accessible_files" in state and state["accessible_files"]:
                actual_files = state["accessible_files"]
                file_count = len(actual_files)
                log(f"ReflectionAgent debug - Using accessible_files: {len(actual_files)} files")
            elif "classified_files" in state and state["classified_files"]:
                actual_files = state["classified_files"]
                file_count = len(actual_files)
                log(f"ReflectionAgent debug - Using classified_files: {len(actual_files)} files")
            elif "processed_files" in state and state["processed_files"]:
                actual_files = state["processed_files"]
                file_count = len(actual_files)
                log(f"ReflectionAgent debug - Using processed_files: {len(actual_files)} files")
            else:
                # Fallback: tÃ¬m tá»« agent results
                if "agent_results" in state and "rag" in state["agent_results"]:
                    rag_result = state["agent_results"]["rag"]
                    if isinstance(rag_result, dict) and "file_paths" in rag_result:
                        actual_files = rag_result["file_paths"]
                        file_count = len(actual_files)
                        log(f"ReflectionAgent debug - Using rag agent results: {len(actual_files)} files")
            
            # Táº¡o detailed_files Má»˜T Láº¦N DUY NHáº¤T tá»« actual_files
            if actual_files:
                for file_path in actual_files:
                    file_name = os.path.basename(file_path)
                    file_info = {
                        "file_name": file_name,
                        "file_path": file_path,
                        "label": classification_labels.get(file_name, ""),
                        "metadata_id": ""
                    }
                    detailed_files.append(file_info)
                
                log(f"ReflectionAgent debug - Created detailed_files for {len(detailed_files)} files")
            
            # Cáº­p nháº­t file_count trong state
            state["file_count"] = file_count
            
            # PhÃ¢n tÃ­ch káº¿t quáº£ tá»« tá»«ng agent chá»‰ Ä‘á»ƒ láº¥y thÃ´ng tin bá»• sung
            for message in state["messages"]:
                if not isinstance(message, AIMessage):
                    continue
                    
                content = message.content
                
                # Káº¿t quáº£ tá»« RAG/Filesystem agent - chá»‰ Ä‘á»ƒ xÃ¡c nháº­n
                if any(indicator.lower() in content.lower() for indicator in [
                    "TÃ´i Ä‘Ã£ tÃ¬m tháº¥y file:", "TÃ¬m tháº¥y cÃ¡c file sau:", "ÄÃ£ tÃ¬m tháº¥y cÃ¡c file:",
                    "TÃ¬m tháº¥y nhiá»u file:", "files found:", "found files:"
                ]):
                    if file_count == 1:
                        key_findings.append(f"ÄÃ£ tÃ¬m tháº¥y 1 file")
                        file_found = f"1 file: {detailed_files[0]['file_name']}" if detailed_files else "1 file"
                    elif file_count > 1:
                        key_findings.append(f"ÄÃ£ tÃ¬m tháº¥y {file_count} files")
                        if detailed_files:
                            if file_count <= 3:
                                file_names = [f["file_name"] for f in detailed_files]
                                file_found = f"{file_count} files: {', '.join(file_names)}"
                            else:
                                file_names = [f["file_name"] for f in detailed_files[:2]]
                                file_found = f"{file_count} files: {', '.join(file_names)} vÃ  {file_count - 2} file khÃ¡c"
                    break
                
                # Káº¿t quáº£ tá»« Text Extraction agent
                elif "ğŸ“" in content and ("Káº¿t quáº£ trÃ­ch xuáº¥t tá»« file" in content or "Káº¿t quáº£ trÃ­ch xuáº¥t tá»« cÃ¡c file" in content):
                    if file_count > 1:
                        key_findings.append(f"ÄÃ£ trÃ­ch xuáº¥t ná»™i dung tá»« {file_count} files")
                    else:
                        key_findings.append(f"ÄÃ£ trÃ­ch xuáº¥t ná»™i dung tá»« file")
                
                # Káº¿t quáº£ tá»« File Classification agent
                elif "ğŸ·ï¸" in content and "Káº¿t quáº£ phÃ¢n loáº¡i file" in content:
                    if file_count > 1:
                        key_findings.append(f"ÄÃ£ phÃ¢n loáº¡i {file_count} files")
                    else:
                        key_findings.append(f"ÄÃ£ phÃ¢n loáº¡i file")
                
                # Káº¿t quáº£ tá»« Metadata agent
                elif "ğŸ“‹" in content and "ÄÃ£ lÆ°u metadata thÃ nh cÃ´ng" in content:
                    # TrÃ­ch xuáº¥t metadata ID tá»« message content
                    import re
                    id_pattern = r'ID:\s*([a-f0-9-]+)'
                    id_matches = re.findall(id_pattern, content)
                    if id_matches:
                        metadata_ids.extend(id_matches)
            
            # Kiá»ƒm tra metadata IDs tá»« state (nguá»“n tin cáº­y nháº¥t)
            if 'metadata' in state and 'metadata_ids' in state['metadata']:
                stored_metadata_ids = state['metadata']['metadata_ids']
                if stored_metadata_ids:
                    # Sá»­ dá»¥ng metadata IDs tá»« state thay vÃ¬ tá»« message content
                    metadata_ids = stored_metadata_ids
                    log(f"ReflectionAgent debug - Found {len(metadata_ids)} metadata IDs in state: {metadata_ids}")
                    
                    # Cáº­p nháº­t metadata ID cho cÃ¡c file trong detailed_files
                    for i, file_info in enumerate(detailed_files):
                        if i < len(metadata_ids):
                            file_info["metadata_id"] = metadata_ids[i]
                    
                    if file_count > 1:
                        key_findings.append(f"ÄÃ£ lÆ°u metadata cho {file_count} files")
                    else:
                        key_findings.append(f"ÄÃ£ lÆ°u metadata vá»›i ID: {metadata_ids[0]}")
            elif metadata_ids:
                # Fallback: sá»­ dá»¥ng metadata IDs tá»« message content náº¿u khÃ´ng cÃ³ trong state
                for i, file_info in enumerate(detailed_files):
                    if i < len(metadata_ids):
                        file_info["metadata_id"] = metadata_ids[i]
                
                if file_count > 1:
                    key_findings.append(f"ÄÃ£ lÆ°u metadata cho {file_count} files")
                else:
                    key_findings.append(f"ÄÃ£ lÆ°u metadata vá»›i ID: {metadata_ids[0]}")
            
            # Táº¡o pháº§n mÃ´ táº£ chi tiáº¿t vá» cÃ¡c file Ä‘Ã£ tÃ¬m tháº¥y
            file_info = ""
            if detailed_files:
                if len(detailed_files) == 1:
                    file_detail = f"File: {detailed_files[0]['file_name']}"
                    if detailed_files[0].get("label"):
                        file_detail += f", PhÃ¢n loáº¡i: {detailed_files[0]['label']}"
                    if detailed_files[0].get("metadata_id"):
                        file_detail += f", Metadata ID: {detailed_files[0]['metadata_id']}"
                    file_info = f"ÄÃ£ tÃ¬m tháº¥y 1 file:\n- {file_detail}"
                else:
                    file_list = []
                    for file_detail in detailed_files[:3]:  # Giá»›i háº¡n hiá»ƒn thá»‹ chi tiáº¿t 3 file Ä‘áº§u tiÃªn
                        detail_str = f"File: {file_detail['file_name']}"
                        if file_detail.get("label"):
                            detail_str += f", PhÃ¢n loáº¡i: {file_detail['label']}"
                        if file_detail.get("metadata_id"):
                            detail_str += f", Metadata ID: {file_detail['metadata_id']}"
                        file_list.append(detail_str)
                    
                    file_info = f"ÄÃ£ tÃ¬m tháº¥y {len(detailed_files)} files:\n- " + "\n- ".join(file_list)
                    if len(detailed_files) > 3:
                        file_info += f"\n- vÃ  {len(detailed_files) - 3} file khÃ¡c"
            elif file_found:
                file_info = file_found
            
            # Táº¡o prompt vá»›i thÃ´ng tin rÃµ rÃ ng hÆ¡n
            reflection_prompt = f"""
            Báº¡n lÃ  má»™t AI assistant chuyÃªn vá» tá»•ng há»£p káº¿t quáº£ vÃ  tráº£ lá»i ngÆ°á»i dÃ¹ng má»™t cÃ¡ch tá»± nhiÃªn, thÃ¢n thiá»‡n.
            
            YÃŠU Cáº¦U BAN Äáº¦U Cá»¦A NGÆ¯á»œI DÃ™NG:
            "{original_query}"
            
            CÃC CÃ”NG Cá»¤ ÄÃƒ Sá»¬ Dá»¤NG:
            {', '.join(used_tools) if used_tools else 'KhÃ´ng cÃ³'}
            
            Káº¾T QUáº¢ CHÃNH:
            {chr(10).join(f"- {finding}" for finding in key_findings) if key_findings else "- KhÃ´ng cÃ³ káº¿t quáº£ nÃ o Ä‘Æ°á»£c ghi nháº­n"}
            
            THÃ”NG TIN CHI TIáº¾T Vá»€ FILE:
            {file_info if file_info else "- KhÃ´ng tÃ¬m tháº¥y file nÃ o phÃ¹ há»£p"}
            
            QUAN TRá»ŒNG: ÄÃ£ tÃ¬m tháº¥y CHÃNH XÃC {file_count} file{'s' if file_count > 1 else ''}.
            
            YÃŠU Cáº¦U:
            HÃ£y táº¡o má»™t cÃ¢u tráº£ lá»i ngáº¯n gá»n, tá»± nhiÃªn vÃ  há»¯u Ã­ch dá»±a trÃªn thÃ´ng tin trÃªn.
            
            HÆ¯á»šNG DáºªN TRáº¢ Lá»œI:
            1. Náº¿u Ä‘Ã£ tÃ¬m tháº¥y file:
               - XÃ¡c nháº­n Ä‘Ã£ tÃ¬m tháº¥y {file_count} file{'s' if file_count > 1 else ''}
               - Liá»‡t kÃª tÃªn cÃ¡c file chÃ­nh (náº¿u Ã­t hÆ¡n 5 file) hoáº·c sá»‘ lÆ°á»£ng file (náº¿u nhiá»u hÆ¡n 5)
               - MÃ´ táº£ ngáº¯n gá»n vá» cÃ¡c file Ä‘Ã£ tÃ¬m tháº¥y
               
            2. Náº¿u khÃ´ng tÃ¬m tháº¥y file:
               - ThÃ´ng bÃ¡o khÃ´ng tÃ¬m tháº¥y file phÃ¹ há»£p
               - Äá» xuáº¥t cÃ¡c tá»« khÃ³a tÃ¬m kiáº¿m khÃ¡c náº¿u cÃ³ thá»ƒ
            
            3. Náº¿u cÃ³ lá»—i hoáº·c váº¥n Ä‘á»:
               - Giáº£i thÃ­ch ngáº¯n gá»n váº¥n Ä‘á»
               - Äá» xuáº¥t hÆ°á»›ng kháº¯c phá»¥c náº¿u cÃ³
            
            LÆ¯U Ã QUAN TRá»ŒNG:
            - LuÃ´n Ä‘á» cáº­p Ä‘áº¿n ÄÃšNG sá»‘ lÆ°á»£ng file Ä‘Ã£ tÃ¬m tháº¥y ({file_count} file{'s' if file_count > 1 else ''})
            - Sá»­ dá»¥ng ngÃ´n ngá»¯ tá»± nhiÃªn, gáº§n gÅ©i
            - Giá»›i háº¡n trong 2-3 cÃ¢u
            - KhÃ´ng cáº§n giáº£i thÃ­ch thÃªm sau cÃ¢u tráº£ lá»i
            
            CÃ‚U TRáº¢ Lá»œI (chá»‰ tráº£ vá» cÃ¢u tráº£ lá»i, khÃ´ng cÃ³ pháº§n giáº£i thÃ­ch):
            """
            
            # Gá»i LLM Ä‘á»ƒ táº¡o reflection response
            response = await self.model.ainvoke(reflection_prompt)
            reflection_response = response.content.strip()
            
            log(f"ReflectionAgent debug - Final file count for response: {file_count}, detailed_files: {len(detailed_files)}")
            log(f"Reflection response generated: {reflection_response}")
            return reflection_response
            
        except Exception as e:
            log(f"Error in reflection agent: {str(e)}", level='error')
            # Fallback response
            return f"TÃ´i Ä‘Ã£ hoÃ n thÃ nh yÃªu cáº§u cá»§a báº¡n. ÄÃ£ sá»­ dá»¥ng {len(state.get('used_tools', []))} cÃ´ng cá»¥ Ä‘á»ƒ xá»­ lÃ½ vÃ  Ä‘áº¡t Ä‘Æ°á»£c káº¿t quáº£ mong muá»‘n."

class MultiAgentSystem:
    """
    Multi-Agent System that orchestrates specialized agents using a worker-evaluator pattern.
    
    This system can use multiple specialized agents in sequence (FilesystemAgent, MetadataAgent,
    TextExtractionAgent, FileClassificationAgent) based on the user's query and includes
    an evaluator component to assess if the task has been completed successfully.
    """
    def __init__(self):
        """
        Initialize the MultiAgentSystem.
        """
        self.model = gemini
        self.graph = None
        self.agents = {}
        self.session_id = None
        self.all_tools = []
        self.reflection_agent = ReflectionAgent()  # ThÃªm reflection agent
        
    async def initialize(self):
        """
        Asynchronously initialize all specialized agents and create the workflow graph.
        
        Returns:
            MultiAgentSystem: The initialized multi-agent system.
        """
        try:
            # Initialize specialized agents
            print("Initializing specialized agents...")
            
           
            mcp_client = MultiServerMCPClient({
                "document_search": {
                    "command": "cmd",
                    "args": [
                        "/c",
                        "npx",
                        "-y",
                        "@modelcontextprotocol/server-filesystem",
                        "C:\\Users\\dhuu3\\Desktop\\local-classify-docs-ai-agent\\data",
                    ],
                    "transport": "stdio"
                }
            })
            print("Using provided MCP client for FilesystemAgent")
            
            self.agents["filesystem"] = await FilesystemAgent.create(mcp_client=mcp_client)
            self.agents["metadata"] = MetadataAgent()
            self.agents["text_extraction"] = TextExtractionAgent()
            self.agents["file_classification"] = FileClassificationAgent()
            self.agents["rag"] = RAGAgent()
            
            # Build RAG index for data directory
            data_dir = "C:\\Users\\dhuu3\\Desktop\\local-classify-docs-ai-agent\\data"
            await self.agents["rag"].build_index(data_dir)
            print("All specialized agents initialized successfully")
            
            # Collect tools from all agents
            # This would require each agent to expose its tools
            # For now, we'll use a placeholder approach
            self.all_tools = []
            
            # Build the graph
            await self.build_graph()
            
            return self
            
        except Exception as e:
            print(f"Error initializing multi-agent system: {e}")
            import traceback
            traceback.print_exc()
            raise
    
    async def build_graph(self):
        """
        Build the state graph for the multi-agent system using a worker-evaluator pattern.
        """
        # Create a state graph with our AgentState
        graph_builder = StateGraph(AgentState)
        
        # Add nodes for each component
        graph_builder.add_node("worker", self.worker)
        graph_builder.add_node("router", self.route_query)
        graph_builder.add_node("filesystem_agent", self.run_filesystem_agent)
        graph_builder.add_node("metadata_agent", self.run_metadata_agent)
        graph_builder.add_node("text_extraction_agent", self.run_text_extraction_agent)
        graph_builder.add_node("file_classification_agent", self.run_file_classification_agent)
        graph_builder.add_node("rag_agent", self.run_rag_agent)
        graph_builder.add_node("evaluator", self.evaluator)
        graph_builder.add_node("reflection", self.run_reflection_agent)  # ThÃªm reflection node
        
        # Add edges
        graph_builder.add_edge(START, "worker")
        
        # Worker can route to specific agents or directly to evaluator
        graph_builder.add_conditional_edges(
            "worker", 
            self.worker_router,
            {
                "router": "router",
                "evaluator": "evaluator"
            }
        )
        
        # Router determines which agent to use
        graph_builder.add_conditional_edges(
            "router",
            self.determine_agent,
            {
                "filesystem": "filesystem_agent",
                "metadata": "metadata_agent",
                "text_extraction": "text_extraction_agent",
                "file_classification": "file_classification_agent",
                "rag": "rag_agent",
                "evaluator": "evaluator"
            }
        )
        
        # Connect all agent nodes back to worker
        graph_builder.add_edge("filesystem_agent", "worker")
        graph_builder.add_edge("metadata_agent", "worker")
        graph_builder.add_edge("text_extraction_agent", "worker")
        graph_builder.add_edge("file_classification_agent", "worker")
        graph_builder.add_edge("rag_agent", "worker")
        
        # Evaluator routes to reflection instead of directly to END
        graph_builder.add_conditional_edges(
            "evaluator",
            self.route_based_on_evaluation,
            {"complete": "reflection", "continue": "worker"}  # Thay Ä‘á»•i: complete -> reflection
        )
        
        # Reflection agent ends the workflow
        graph_builder.add_edge("reflection", END)
        
        # Compile the graph
        self.graph = graph_builder.compile(checkpointer=memory)
        log("Multi-agent graph built successfully with reflection agent")
    
    async def run_reflection_agent(self, state: AgentState) -> AgentState:
        """
        Run the reflection agent to create final response for user.
        """
        try:
            log("Running ReflectionAgent...")
            
            # Track that we're using reflection agent
            if "used_tools" not in state:
                state["used_tools"] = []
            state["used_tools"].append("reflection")
            
            # Generate reflection response
            reflection_response = await self.reflection_agent.reflect_and_respond(state)
            
            # Add reflection response to messages
            state["messages"].append(AIMessage(content=f"ğŸ’­ {reflection_response}"))
            
            # Add to chain of thought
            if "chain_of_thought" not in state:
                state["chain_of_thought"] = []
            state["chain_of_thought"].append(f"ğŸ¤” Reflection: Táº¡o cÃ¢u tráº£ lá»i cuá»‘i cÃ¹ng cho ngÆ°á»i dÃ¹ng")
            
            # Mark task as complete
            state["task_complete"] = True
            state["success_criteria_met"] = True
            
            log(f"ReflectionAgent completed: {reflection_response}")
            return state
            
        except Exception as e:
            log(f"Error in reflection agent: {str(e)}", level='error')
            # Fallback response
            fallback_response = "TÃ´i Ä‘Ã£ hoÃ n thÃ nh yÃªu cáº§u cá»§a báº¡n thÃ nh cÃ´ng."
            state["messages"].append(AIMessage(content=f"ğŸ’­ {fallback_response}"))
            state["task_complete"] = True
            state["success_criteria_met"] = True
            return state

    async def worker(self, state: AgentState) -> AgentState:
        """
        Worker node that processes the user's query and determines next steps.
        """
        # Create or update system message with task information
        system_message = f"""
        Báº¡n lÃ  má»™t trá»£ lÃ½ AI thÃ´ng minh cÃ³ thá»ƒ sá»­ dá»¥ng nhiá»u cÃ´ng cá»¥ vÃ  tÃ¡c tá»­ chuyÃªn biá»‡t Ä‘á»ƒ hoÃ n thÃ nh nhiá»‡m vá»¥.
        Báº¡n cÃ³ thá»ƒ tiáº¿p tá»¥c lÃ m viá»‡c vá»›i má»™t nhiá»‡m vá»¥ cho Ä‘áº¿n khi hoÃ n thÃ nh hoáº·c cáº§n thÃªm thÃ´ng tin tá»« ngÆ°á»i dÃ¹ng.
        
        Báº¡n cÃ³ quyá»n truy cáº­p vÃ o cÃ¡c tÃ¡c tá»­ chuyÃªn biá»‡t sau:
        1. Filesystem Agent: Sá»­ dá»¥ng khi cáº§n tÃ¬m kiáº¿m, liá»‡t kÃª hoáº·c quáº£n lÃ½ tá»‡p vÃ  thÆ° má»¥c theo tÃªn file.
        2. RAG Agent: Sá»­ dá»¥ng khi cáº§n tÃ¬m kiáº¿m tÃ i liá»‡u theo ná»™i dung hoáº·c ngá»¯ nghÄ©a.
        3. Metadata Agent: Sá»­ dá»¥ng khi cáº§n táº¡o hoáº·c quáº£n lÃ½ metadata cho tÃ i liá»‡u.
        4. Text Extraction Agent: Sá»­ dá»¥ng khi cáº§n trÃ­ch xuáº¥t vÄƒn báº£n tá»« cÃ¡c tá»‡p PDF, Word hoáº·c PowerPoint.
        5. File Classification Agent: Sá»­ dá»¥ng khi cáº§n phÃ¢n loáº¡i ná»™i dung tÃ i liá»‡u.
        
        Báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng nhiá»u tÃ¡c tá»­ trong cÃ¹ng má»™t nhiá»‡m vá»¥ náº¿u cáº§n thiáº¿t.
        VÃ­ dá»¥: TÃ¬m tá»‡p vá»›i Filesystem Agent, sau Ä‘Ã³ trÃ­ch xuáº¥t ná»™i dung vá»›i Text Extraction Agent.
        
        HÃ£y phÃ¢n tÃ­ch yÃªu cáº§u cá»§a ngÆ°á»i dÃ¹ng vÃ  quyáº¿t Ä‘á»‹nh sá»­ dá»¥ng tÃ¡c tá»­ nÃ o hoáº·c káº¿t há»£p cÃ¡c tÃ¡c tá»­ Ä‘á»ƒ hoÃ n thÃ nh nhiá»‡m vá»¥.
        """
        
        # Add feedback if available
        if state.get("feedback_on_work"):
            system_message += f"""
        
TrÆ°á»›c Ä‘Ã³, báº¡n Ä‘Ã£ thá»­ giáº£i quyáº¿t nhiá»‡m vá»¥ nhÆ°ng chÆ°a hoÃ n thÃ nh. ÄÃ¢y lÃ  pháº£n há»“i:
{state['feedback_on_work']}

HÃ£y Ä‘iá»u chá»‰nh cÃ¡ch tiáº¿p cáº­n cá»§a báº¡n dá»±a trÃªn pháº£n há»“i nÃ y.
        """
        
        # Add system message if not already present
        found_system_message = False
        messages = state["messages"]
        for i, message in enumerate(messages):
            if isinstance(message, SystemMessage):
                messages[i] = SystemMessage(content=system_message)
                found_system_message = True
                break
        
        if not found_system_message:
            state["messages"] = [SystemMessage(content=system_message)] + state["messages"]
        
        # Store original query if not already stored
        if not state.get("original_query"):
            for message in state["messages"]:
                if isinstance(message, HumanMessage):
                    state["original_query"] = message.content
                    break
        
        # Analyze the query to determine next steps
        last_message = state["messages"][-1]
        if not isinstance(last_message, HumanMessage):
            # If the last message is not from a human, we're in a continuation
            # Just return the state for routing
            return state
            
        # Sá»­ dá»¥ng LLM Ä‘á»ƒ láº­p káº¿ hoáº¡ch sá»­ dá»¥ng agent
        query = last_message.content
        
        try:
            # Táº¡o prompt cho LLM
            planning_prompt = f"""
            Báº¡n lÃ  má»™t há»‡ thá»‘ng Ä‘iá»u phá»‘i cÃ¡c agent AI chuyÃªn biá»‡t. Dá»±a trÃªn yÃªu cáº§u cá»§a ngÆ°á»i dÃ¹ng, hÃ£y láº­p káº¿ hoáº¡ch sá»­ dá»¥ng cÃ¡c agent phÃ¹ há»£p.
            
            YÃªu cáº§u cá»§a ngÆ°á»i dÃ¹ng: "{query}"
            
            CÃ¡c agent cÃ³ sáºµn:
            1. filesystem - TÃ¬m kiáº¿m, liá»‡t kÃª vÃ  quáº£n lÃ½ tá»‡p vÃ  thÆ° má»¥c
            2. metadata - Táº¡o vÃ  quáº£n lÃ½ metadata cho tÃ i liá»‡u
            3. text_extraction - TrÃ­ch xuáº¥t vÄƒn báº£n tá»« tá»‡p PDF, Word hoáº·c PowerPoint
            4. file_classification - PhÃ¢n loáº¡i ná»™i dung tÃ i liá»‡u
            
            HÃ£y láº­p káº¿ hoáº¡ch sá»­ dá»¥ng cÃ¡c agent. Äáº§u tiÃªn, tráº£ lá»i vá»›i danh sÃ¡ch cÃ¡c agent cáº§n sá»­ dá»¥ng theo thá»© tá»±, chá»‰ liá»‡t kÃª tÃªn cÃ¡c agent (filesystem, metadata, text_extraction, file_classification), cÃ¡ch nhau báº±ng dáº¥u pháº©y.
            
            Sau Ä‘Ã³, viáº¿t má»™t Ä‘oáº¡n vÄƒn ngáº¯n giáº£i thÃ­ch káº¿ hoáº¡ch cá»§a báº¡n báº±ng tiáº¿ng Viá»‡t.
            """
            
            # Sá»­ dá»¥ng LLM Ä‘á»ƒ láº­p káº¿ hoáº¡ch
            from config.llm import gemini
            response = await gemini.ainvoke(planning_prompt)
            plan_response = response.content.strip()
            
            # TÃ¡ch pháº§n danh sÃ¡ch agent vÃ  pháº§n giáº£i thÃ­ch
            parts = plan_response.split('\n', 1)
            agent_list = parts[0].strip().lower()
            plan_message = parts[1].strip() if len(parts) > 1 else f"TÃ´i sáº½ giÃºp báº¡n vá»›i yÃªu cáº§u: '{query}'."
            
            # Xá»­ lÃ½ danh sÃ¡ch agent
            needed_agents = []
            valid_agents = ["filesystem", "metadata", "text_extraction", "file_classification"]
            
            for agent in valid_agents:
                if agent in agent_list:
                    needed_agents.append(agent)
            
            if not needed_agents:
                # Máº·c Ä‘á»‹nh sá»­ dá»¥ng filesystem náº¿u khÃ´ng cÃ³ agent nÃ o Ä‘Æ°á»£c chá»n
                needed_agents.append("filesystem")
                plan_message += "\nTÃ´i sáº½ báº¯t Ä‘áº§u vá»›i Filesystem Agent Ä‘á»ƒ tÃ¬m kiáº¿m thÃ´ng tin."
            
            print(f"Káº¿ hoáº¡ch agent: {needed_agents}")
            
        except Exception as e:
            print(f"Lá»—i khi láº­p káº¿ hoáº¡ch sá»­ dá»¥ng agent: {e}")
            # Sá»­ dá»¥ng máº·c Ä‘á»‹nh náº¿u cÃ³ lá»—i
            needed_agents = ["filesystem"]
            plan_message = f"TÃ´i sáº½ giÃºp báº¡n vá»›i yÃªu cáº§u: '{query}'. TÃ´i sáº½ báº¯t Ä‘áº§u vá»›i Filesystem Agent Ä‘á»ƒ tÃ¬m kiáº¿m thÃ´ng tin."
        
        # Update state with the plan
        state["current_agents"] = needed_agents
        state["messages"].append(AIMessage(content=plan_message))
        
        return state
        
    def worker_router(self, state: AgentState) -> str:
        """
        Route from worker node to either router or evaluator.
        """
        # Náº¿u khÃ´ng cÃ²n agent nÃ o trong káº¿ hoáº¡ch, chuyá»ƒn sang evaluator
        if not state["current_agents"]:
            log("KhÃ´ng cÃ²n agent nÃ o trong káº¿ hoáº¡ch, chuyá»ƒn sang evaluator")
            return "evaluator"
            
        # Náº¿u Ä‘Ã£ sá»­ dá»¥ng quÃ¡ nhiá»u agent, chuyá»ƒn sang evaluator Ä‘á»ƒ trÃ¡nh vÃ²ng láº·p vÃ´ háº¡n
        if len(state.get("used_tools", [])) >= 3:
            log("ÄÃ£ sá»­ dá»¥ng quÃ¡ nhiá»u agent, chuyá»ƒn sang evaluator")
            return "evaluator"
            
        # Kiá»ƒm tra xem cÃ³ Ä‘ang láº·p láº¡i agent khÃ´ng
        if len(state.get("used_tools", [])) >= 2:
            last_two_tools = state["used_tools"][-2:]
            if last_two_tools[0] == last_two_tools[1]:
                log("PhÃ¡t hiá»‡n láº·p láº¡i agent, chuyá»ƒn sang evaluator")
                return "evaluator"
                
        # Tiáº¿p tá»¥c vá»›i router
        return "router"
    
    def determine_agent(self, state: AgentState) -> str:
        """
        Determine which agent to use next based on the current_agents list.
        """
        if not state["current_agents"]:
            log("KhÃ´ng cÃ²n agent nÃ o trong danh sÃ¡ch, chuyá»ƒn sang evaluator")
            return "evaluator"
        
        # Kiá»ƒm tra xem agent tiáº¿p theo Ä‘Ã£ Ä‘Æ°á»£c sá»­ dá»¥ng chÆ°a
        next_agent = state["current_agents"][0]
        used_tools = state.get("used_tools", [])
        
        # Náº¿u agent tiáº¿p theo Ä‘Ã£ Ä‘Æ°á»£c sá»­ dá»¥ng, bá» qua vÃ  kiá»ƒm tra agent tiáº¿p theo
        if next_agent in used_tools:
            log(f"Agent {next_agent} Ä‘Ã£ Ä‘Æ°á»£c sá»­ dá»¥ng, bá» qua")
            # XÃ³a agent nÃ y khá»i danh sÃ¡ch
            state["current_agents"] = state["current_agents"][1:]
            # Gá»i Ä‘á»‡ quy Ä‘á»ƒ tÃ¬m agent tiáº¿p theo
            return self.determine_agent(state)
        
        # Láº¥y agent tiáº¿p theo tá»« danh sÃ¡ch
        log(f"Sá»­ dá»¥ng agent {next_agent} tiáº¿p theo")
        
        # XÃ³a nÃ³ khá»i danh sÃ¡ch Ä‘á»ƒ khÃ´ng sá»­ dá»¥ng láº¡i
        state["current_agents"] = state["current_agents"][1:]
        
        # Kiá»ƒm tra náº¿u lÃ  RAG agent
        if next_agent == "rag":
            return "run_rag_agent"
        
        return next_agent
        
    async def _validate_agent_sequence(self, state: AgentState) -> AgentState:
        """
        Validate and fix the agent sequence to ensure proper workflow, especially for metadata operations.
        
        Args:
            state: Current agent state with planned agents
            
        Returns:
            Updated state with corrected agent sequence
        """
        current_agents = state.get("current_agents", [])
        log(f"Validating agent sequence: {current_agents}")
        
        # If no agents or only one agent, no need to validate sequence
        if len(current_agents) <= 1:
            return state
            
        # Check if metadata agent is included in the plan
        if "metadata" in current_agents:
            log("PhÃ¡t hiá»‡n metadata agent trong káº¿ hoáº¡ch, kiá»ƒm tra thá»© tá»±")
            
            # Define the correct sequence for metadata operations
            metadata_workflow = []
            
            # Step 1: First agent should be filesystem or rag (search agent)
            if "filesystem" in current_agents or "rag" in current_agents:
                search_agent = "rag" if "rag" in current_agents else "filesystem"
                metadata_workflow.append(search_agent)
                log(f"Sá»­ dá»¥ng {search_agent} lÃ m agent tÃ¬m kiáº¿m trong workflow metadata")
            else:
                # If no search agent is specified, add rag as default
                metadata_workflow.append("rag")
                log("ThÃªm rag agent vÃ o Ä‘áº§u workflow vÃ¬ khÃ´ng tÃ¬m tháº¥y agent tÃ¬m kiáº¿m")
                # Also add it to current_agents to ensure it's included in the final sequence
                current_agents.append("rag")
                
            # Step 2: Add text_extraction agent
            metadata_workflow.append("text_extraction")
            
            # Step 3: Add file_classification agent
            metadata_workflow.append("file_classification")
            
            # Step 4: Finally add metadata agent
            metadata_workflow.append("metadata")
            
            # Create a new agent sequence with correct order
            # Remove any agents that are already in the metadata workflow
            new_agents = [agent for agent in current_agents if agent not in metadata_workflow]
            
            # Add the metadata workflow agents in correct order
            new_agents.extend([agent for agent in metadata_workflow if agent in current_agents])
            
            # If metadata is in the plan but required agents are missing, add them
            if "metadata" in new_agents:
                metadata_index = new_agents.index("metadata")
                missing_agents = []
                
                # Check for missing required agents
                if "text_extraction" not in new_agents:
                    missing_agents.append("text_extraction")
                    log("ThÃªm text_extraction agent vÃ o workflow vÃ¬ cáº§n thiáº¿t cho metadata")
                    
                if "file_classification" not in new_agents:
                    missing_agents.append("file_classification")
                    log("ThÃªm file_classification agent vÃ o workflow vÃ¬ cáº§n thiáº¿t cho metadata")
                
                # Insert missing agents in the correct order before metadata
                for agent in reversed(missing_agents):
                    new_agents.insert(metadata_index, agent)
            
            # Update the state with the corrected sequence
            if new_agents != current_agents:
                log(f"ÄÃ£ Ä‘iá»u chá»‰nh thá»© tá»± agent: {current_agents} -> {new_agents}")
                # state["chain_of_thought"].append(f"Äiá»u chá»‰nh thá»© tá»± agent Ä‘á»ƒ Ä‘áº£m báº£o workflow chÃ­nh xÃ¡c: {', '.join(new_agents)}")
                state["current_agents"] = new_agents
        
        return state
        
    async def evaluator(self, state: AgentState) -> AgentState:
        """
        Evaluator node that assesses if the task has been completed successfully.
        """
        # Format the conversation history
        conversation = "Lá»‹ch sá»­ há»™i thoáº¡i:\n\n"
        for message in state["messages"]:
            if isinstance(message, HumanMessage):
                conversation += f"NgÆ°á»i dÃ¹ng: {message.content}\n"
            elif isinstance(message, AIMessage):
                conversation += f"Trá»£ lÃ½: {message.content}\n"
            elif isinstance(message, SystemMessage):
                # Skip system messages in the conversation history
                pass
        
        # Get the original query
        original_query = ""
        for message in state["messages"]:
            if isinstance(message, HumanMessage):
                original_query = message.content
                break
        
        # Get the last response
        last_response = ""
        for message in reversed(state["messages"]):
            if isinstance(message, AIMessage):
                last_response = message.content
                break
        
        # Create evaluator prompt
        evaluator_prompt = f"""
        Báº¡n lÃ  má»™t Ä‘Ã¡nh giÃ¡ viÃªn xÃ¡c Ä‘á»‹nh xem má»™t nhiá»‡m vá»¥ Ä‘Ã£ Ä‘Æ°á»£c hoÃ n thÃ nh thÃ nh cÃ´ng hay chÆ°a.
        ÄÃ¡nh giÃ¡ pháº£n há»“i cuá»‘i cÃ¹ng cá»§a Trá»£ lÃ½ dá»±a trÃªn yÃªu cáº§u ban Ä‘áº§u cá»§a ngÆ°á»i dÃ¹ng.
        
        YÃªu cáº§u ban Ä‘áº§u cá»§a ngÆ°á»i dÃ¹ng lÃ :
        {original_query}
        
        Lá»‹ch sá»­ há»™i thoáº¡i:
        {conversation}
        
        Pháº£n há»“i cuá»‘i cÃ¹ng cá»§a Trá»£ lÃ½:
        {last_response}
        
        HÃ£y Ä‘Ã¡nh giÃ¡ xem nhiá»‡m vá»¥ Ä‘Ã£ hoÃ n thÃ nh chÆ°a vÃ  liá»‡u cÃ³ cáº§n thÃªm thÃ´ng tin tá»« ngÆ°á»i dÃ¹ng khÃ´ng.
        Náº¿u nhiá»‡m vá»¥ chÆ°a hoÃ n thÃ nh, hÃ£y giáº£i thÃ­ch táº¡i sao vÃ  Ä‘á» xuáº¥t cÃ¡ch tiáº¿p cáº­n khÃ¡c.
        """
        
        # For now, we'll use a simple heuristic to determine if the task is complete
        # In a real implementation, you would use the LLM to evaluate this
        
        # Check if we've used at least one agent
        task_complete = len(state.get("used_tools", [])) > 0
        
        # Check if the last response contains certain keywords indicating completion
        completion_indicators = ["Ä‘Ã£ hoÃ n thÃ nh", "Ä‘Ã£ tÃ¬m tháº¥y", "káº¿t quáº£", "Ä‘Ã£ xá»­ lÃ½", "Ä‘Ã£ trÃ­ch xuáº¥t", "Ä‘Ã£ phÃ¢n loáº¡i"]
        for indicator in completion_indicators:
            if indicator in last_response.lower():
                task_complete = True
                break
        
        # Check if the response addresses the original query
        query_keywords = original_query.lower().split()
        response_keywords = last_response.lower().split()
        common_keywords = set(query_keywords).intersection(set(response_keywords))
        if len(common_keywords) > 2:  # If there are at least 3 common keywords
            task_complete = True
        
        # Set the evaluation results
        feedback = ""
        if task_complete:
            feedback = "Nhiá»‡m vá»¥ Ä‘Ã£ Ä‘Æ°á»£c hoÃ n thÃ nh thÃ nh cÃ´ng. Pháº£n há»“i Ä‘Ã£ giáº£i quyáº¿t yÃªu cáº§u cá»§a ngÆ°á»i dÃ¹ng."
            state["success_criteria_met"] = True
        else:
            feedback = "Nhiá»‡m vá»¥ chÆ°a hoÃ n thÃ nh. Cáº§n sá»­ dá»¥ng thÃªm tÃ¡c tá»­ hoáº·c cÃ´ng cá»¥ Ä‘á»ƒ giáº£i quyáº¿t yÃªu cáº§u cá»§a ngÆ°á»i dÃ¹ng."
            state["success_criteria_met"] = False
        
        # Add the feedback to the state
        state["feedback_on_work"] = feedback
        
        # Add evaluator message to the conversation
        state["messages"].append(AIMessage(content=f"[ÄÃ¡nh giÃ¡ ná»™i bá»™: {feedback}]"))
        
        return state
    
    def route_based_on_evaluation(self, state: AgentState) -> str:
        """
        Determine next steps based on the evaluator's assessment.
        """
        if state["success_criteria_met"] or state["require_user_input"]:
            return "complete"
        else:
            # If not complete and we don't need user input, try again with other agents
            return "continue"
    async def route_query(self, state: AgentState) -> AgentState:
        """
        Route the query to the appropriate agent.
        """
        # Just pass through the state, the routing is done in determine_agent
        return state
    
    async def _determine_search_intent(self, query: str) -> str:
        """
        XÃ¡c Ä‘á»‹nh má»¥c Ä‘Ã­ch tÃ¬m kiáº¿m dá»±a trÃªn cÃ¢u truy váº¥n.
        
        Args:
            query: CÃ¢u truy váº¥n cá»§a ngÆ°á»i dÃ¹ng
            
        Returns:
            "filesystem" náº¿u lÃ  tÃ¬m kiáº¿m theo tÃªn file, "rag" náº¿u tÃ¬m kiáº¿m theo ná»™i dung
        """
        query = query.lower()
        
        # Keywords indicating file name search
        file_name_keywords = [
            "tÃªn file", "tÃ¬m file", "Ä‘Æ°á»ng dáº«n", "thÆ° má»¥c",
            "trong folder", "trong thÆ° má»¥c", "tÃ¬m kiáº¿m file", "file tÃªn"
        ]
        
        # Keywords indicating content search
        content_keywords = [
            "ná»™i dung", "cÃ³ chá»©a", "liÃªn quan Ä‘áº¿n", "nÃ³i vá»",
            "thÃ´ng tin vá»", "tÃ¬m kiáº¿m thÃ´ng tin", "tÃ i liá»‡u vá»", "vÄƒn báº£n"
        ]
        
        # Check for explicit content search
        if any(keyword in query for keyword in content_keywords):
            log(f"PhÃ¡t hiá»‡n tÃ¬m kiáº¿m theo ná»™i dung: {query}")
            return "rag"
            
        # Check for explicit file search
        if any(keyword in query for keyword in file_name_keywords):
            log(f"PhÃ¡t hiá»‡n tÃ¬m kiáº¿m theo tÃªn file: {query}")
            return "filesystem"
            
        # Default to content search for natural language queries
        if len(query.split()) > 3:  # Longer queries are likely content searches
            log(f"Máº·c Ä‘á»‹nh tÃ¬m kiáº¿m theo ná»™i dung cho cÃ¢u dÃ i: {query}")
            return "rag"
            
        # Default to file system search for short queries
        log(f"Máº·c Ä‘á»‹nh tÃ¬m kiáº¿m theo tÃªn file cho cÃ¢u ngáº¯n: {query}")
        return "filesystem"

    async def run_filesystem_agent(self, state: AgentState) -> AgentState:
        """
        Run the filesystem agent on the current query.
        """
        try:
            # Get the last message that's not from an agent
            query = ""
            for message in reversed(state["messages"]):
                if isinstance(message, HumanMessage):
                    query = message.content
                    break

            log(f"Running FilesystemAgent with query: {query}")

            # Track that we're using this agent
            if "used_tools" not in state:
                state["used_tools"] = []
            state["used_tools"].append("filesystem")

            # Get the filesystem agent graph
            filesystem_agent = self.agents["filesystem"]

            # Run the agent with the query and wait for completion
            config = {"configurable": {"thread_id": self.session_id}}
            log("Waiting for FilesystemAgent to complete...")
            response = await filesystem_agent.graph.ainvoke({"messages": state["messages"]}, config=config)
            log("FilesystemAgent completed")

            # Get the agent's response
            agent_response = None
            for message in reversed(response["messages"]):
                if isinstance(message, AIMessage):
                    agent_response = message
                    break

            if not agent_response or not agent_response.content.strip():
                # If there's no response or it's empty, create a default one
                agent_response = AIMessage(content="TÃ´i Ä‘Ã£ tÃ¬m kiáº¿m nhÆ°ng khÃ´ng tÃ¬m tháº¥y káº¿t quáº£ phÃ¹ há»£p.")

            # Add the agent's response to the state
            response_content = f"ğŸ—‚ï¸ {agent_response.content}"
            print(f"FilesystemAgent response: {response_content}")
            log(f"FilesystemAgent response: {response_content}")
            state["messages"].append(AIMessage(content=response_content))
            
            # Store result in agent_results
            if "agent_results" not in state:
                state["agent_results"] = {}
            state["agent_results"]["filesystem"] = agent_response.content
            
            # Check if filesystem agent found any results
            if "KhÃ´ng tÃ¬m tháº¥y" in agent_response.content or "khÃ´ng biáº¿t" in agent_response.content.lower() or "khÃ´ng tÃ¬m tháº¥y" in agent_response.content.lower():
                print("Filesystem agent didn't find results. Trying RAG agent...")
                
                # Call RAG agent for content-based search
                rag_agent = self.agents["rag"]
                rag_result = await rag_agent.invoke(query, self.session_id)
                
                if isinstance(rag_result, dict) and 'content' in rag_result:
                    # Add RAG response to messages
                    rag_content = f"ğŸ” TÃ¬m kiáº¿m theo ná»™i dung file:\n\n{rag_result['content']}"
                    state["messages"].append(AIMessage(content=rag_content))
                    
                    # Store RAG result
                    state["agent_results"]["rag"] = rag_result['content']
                    
                    # Add RAG to used tools
                    if "rag" not in state["used_tools"]:
                        state["used_tools"].append("rag")
                        
                    print(f"RAG agent found results: {rag_content[:100]}...")
            
            # Analyze the response to suggest next agent
            print("Analyzing response to suggest next agent...")
            next_agent = await self._suggest_next_agent(agent_response.content, state)
            if next_agent and next_agent not in state["current_agents"]:
                print(f"Adding {next_agent} to current_agents")
                state["current_agents"].append(next_agent)
            else:
                print(f"No additional agent suggested or already in use")

            return state

        except Exception as e:
            print(f"Error running filesystem agent: {e}")
            # Add an error message to the state
            error_message = f"Xin lá»—i, tÃ´i gáº·p lá»—i khi tÃ¬m kiáº¿m tá»‡p: {str(e)}"
            state["messages"].append(AIMessage(content=error_message))
            return state

    async def _suggest_next_agent(self, response_content: str, state: AgentState) -> str:
        """
        Sá»­ dá»¥ng LLM Ä‘á»ƒ phÃ¢n tÃ­ch pháº£n há»“i cá»§a agent vÃ  Ä‘á» xuáº¥t agent tiáº¿p theo.
        
        Args:
            response_content: Ná»™i dung pháº£n há»“i cá»§a agent
            state: Tráº¡ng thÃ¡i hiá»‡n táº¡i
            
        Returns:
            TÃªn cá»§a agent tiáº¿p theo, hoáº·c None náº¿u khÃ´ng cÃ³ Ä‘á» xuáº¥t
        """
        # Láº¥y yÃªu cáº§u ban Ä‘áº§u cá»§a ngÆ°á»i dÃ¹ng
        original_query = ""
        for message in state["messages"]:
            if isinstance(message, HumanMessage):
                original_query = message.content
                break
        
        # Danh sÃ¡ch cÃ¡c agent Ä‘Ã£ sá»­ dá»¥ng
        used_agents = state.get("used_tools", [])
        
        # Náº¿u Ä‘Ã£ sá»­ dá»¥ng quÃ¡ nhiá»u agent, khÃ´ng Ä‘á» xuáº¥t thÃªm
        if len(used_agents) >= 3:
            print("ÄÃ£ sá»­ dá»¥ng quÃ¡ nhiá»u agent, khÃ´ng Ä‘á» xuáº¥t thÃªm")
            return None
        
        # Táº¡o prompt cho LLM
        prompt = f"""
        Báº¡n lÃ  má»™t há»‡ thá»‘ng Ä‘iá»u phá»‘i cÃ¡c agent AI chuyÃªn biá»‡t. Dá»±a trÃªn thÃ´ng tin sau, hÃ£y quyáº¿t Ä‘á»‹nh agent nÃ o nÃªn Ä‘Æ°á»£c sá»­ dá»¥ng tiáº¿p theo.
        
        YÃªu cáº§u ban Ä‘áº§u cá»§a ngÆ°á»i dÃ¹ng: "{original_query}"
        
        Pháº£n há»“i má»›i nháº¥t tá»« agent: "{response_content}"
        
        CÃ¡c agent Ä‘Ã£ Ä‘Æ°á»£c sá»­ dá»¥ng: {used_agents}
        
        CÃ¡c agent cÃ³ sáºµn:
        1. filesystem - TÃ¬m kiáº¿m, liá»‡t kÃª vÃ  quáº£n lÃ½ tá»‡p vÃ  thÆ° má»¥c
        2. metadata - Táº¡o vÃ  quáº£n lÃ½ metadata cho tÃ i liá»‡u
        3. text_extraction - TrÃ­ch xuáº¥t vÄƒn báº£n tá»« tá»‡p PDF, Word hoáº·c PowerPoint
        4. file_classification - PhÃ¢n loáº¡i ná»™i dung tÃ i liá»‡u
        
        QUAN TRá»ŒNG: Chá»‰ Ä‘á» xuáº¥t má»™t agent tiáº¿p theo náº¿u thá»±c sá»± cáº§n thiáº¿t dá»±a trÃªn yÃªu cáº§u ban Ä‘áº§u vÃ  pháº£n há»“i hiá»‡n táº¡i.
        Náº¿u agent hiá»‡n táº¡i Ä‘Ã£ giáº£i quyáº¿t Ä‘Æ°á»£c váº¥n Ä‘á» hoáº·c khÃ´ng cáº§n agent khÃ¡c, hÃ£y tráº£ lá»i "none".
        
        Tráº£ lá»i chá»‰ vá»›i tÃªn cá»§a agent (filesystem, metadata, text_extraction, file_classification) hoáº·c "none" náº¿u khÃ´ng cáº§n agent nÃ o ná»¯a.
        """
        
        try:
            # Sá»­ dá»¥ng LLM Ä‘á»ƒ quyáº¿t Ä‘á»‹nh
            from config.llm import gemini
            response = await gemini.ainvoke(prompt)
            suggestion = response.content.strip().lower()
            
            # Kiá»ƒm tra xem cÃ³ tá»« "none" trong pháº£n há»“i khÃ´ng
            if "none" in suggestion:
                print("LLM Ä‘á» xuáº¥t khÃ´ng cáº§n sá»­ dá»¥ng thÃªm agent")
                return None
            
            # Xá»­ lÃ½ pháº£n há»“i
            valid_agents = ["filesystem", "metadata", "text_extraction", "file_classification"]
            
            # Chá»‰ Ä‘á» xuáº¥t agent chÆ°a Ä‘Æ°á»£c sá»­ dá»¥ng
            for agent in valid_agents:
                if agent in suggestion and agent not in used_agents:
                    print(f"LLM Ä‘á» xuáº¥t sá»­ dá»¥ng {agent} tiáº¿p theo")
                    return agent
            
            # KhÃ´ng cÃ³ Ä‘á» xuáº¥t há»£p lá»‡
            return None
            
        except Exception as e:
            print(f"Lá»—i khi Ä‘á» xuáº¥t agent tiáº¿p theo: {e}")
            return None
    
    async def run_rag_agent(self, state: AgentState) -> AgentState:
        """
        Run the RAG agent to search file contents.
        """
        try:
            # Get the last message that's not from an agent
            query = ""
            for message in reversed(state["messages"]):
                if isinstance(message, HumanMessage):
                    query = message.content
                    break

            log(f"Running RAGAgent with query: {query}")

            # Track that we're using this agent
            if "used_tools" not in state:
                state["used_tools"] = []
            state["used_tools"].append("rag")

            # Get the RAG agent
            rag_agent = self.agents["rag"]

            # Run the agent with the query
            log("Searching with RAGAgent...")
            response = await rag_agent.invoke(query, session_id=self.session_id)
            log("RAGAgent search completed")

            # Format the response
            if isinstance(response, dict) and 'content' in response:
                response_content = response['content']
                # Extract file_paths if present for text extraction compatibility
                file_paths = response.get('file_paths', [])
            else:
                response_content = str(response)
                file_paths = []
                
                # Náº¿u RAG tráº£ vá» chuá»—i vÄƒn báº£n cÃ³ chá»©a Ä‘Æ°á»ng dáº«n file, trÃ­ch xuáº¥t chÃºng
                # Máº«u: "TÃ´i Ä‘Ã£ tÃ¬m tháº¥y cÃ¡c file sau:\n1. C:\path\to\file1.docx\n2. C:\path\to\file2.docx"
                if "\n" in response_content and ("TÃ´i Ä‘Ã£ tÃ¬m tháº¥y" in response_content or "tÃ¬m tháº¥y cÃ¡c file" in response_content):
                    lines = response_content.split("\n")
                    for line in lines:
                        # TÃ¬m cÃ¡c dÃ²ng cÃ³ Ä‘Æ°á»ng dáº«n file
                        if line.strip().startswith("1.") or line.strip().startswith("2.") or line.strip().startswith("3."):
                            # TrÃ­ch xuáº¥t Ä‘Æ°á»ng dáº«n file tá»« dÃ²ng
                            parts = line.strip().split(".", 1)
                            if len(parts) > 1:
                                file_path = parts[1].strip()
                                file_paths.append(file_path)
                    
                    log(f"Extracted {len(file_paths)} file paths from RAG response text: {file_paths}")

            # Add the agent's response to the state with file_paths as additional kwargs if available
            print(f"RAGAgent response: {response_content[:200]}...")
            if file_paths:
                log(f"RAG agent found {len(file_paths)} file paths: {file_paths}")
                state["messages"].append(AIMessage(
                    content=response_content,
                    additional_kwargs={'file_paths': file_paths}
                ))
            else:
                state["messages"].append(AIMessage(content=response_content))
            
            # Store result in agent_results
            if "agent_results" not in state:
                state["agent_results"] = {}
            state["agent_results"]["rag"] = response_content
            
            # LÆ°u Ä‘Æ°á»ng dáº«n file vÃ o state Ä‘á»ƒ cÃ¡c agent khÃ¡c cÃ³ thá»ƒ sá»­ dá»¥ng
            if file_paths:
                state["processed_files"] = file_paths
                
            return state
            
        except Exception as e:
            log(f"Error in RAG agent: {str(e)}", level='error')
            state["messages"].append(AIMessage(
                content=f"CÃ³ lá»—i xáº£y ra khi tÃ¬m kiáº¿m ná»™i dung: {str(e)}"
            ))
            return state

    async def run_metadata_agent(self, state: AgentState) -> AgentState:
        """
        Run the metadata agent on the current query.
        """
        try:
            # Get the last message that's not from an agent
            query = ""
            for message in reversed(state["messages"]):
                if isinstance(message, HumanMessage):
                    query = message.content
                    break

            log(f"Running MetadataAgent with query: {query}")

            # Track that we're using this agent
            if "used_tools" not in state:
                state["used_tools"] = []
            state["used_tools"].append("metadata")

            # Extract file paths from previous agent messages
            file_paths = []
            file_content = None
            file_classification = None
            
            # Kiá»ƒm tra xem cÃ³ file paths Ä‘Ã£ Ä‘Æ°á»£c lÆ°u trong state tá»« cÃ¡c agent trÆ°á»›c Ä‘Ã³ khÃ´ng
            if "accessible_files" in state:
                file_paths = state["accessible_files"]
                log(f"Found {len(file_paths)} file paths from state: {file_paths}")
            elif "classified_files" in state:
                file_paths = state["classified_files"]
                log(f"Found {len(file_paths)} file paths from classified_files: {file_paths}")
            else:
                # First, look for file paths from RAG or filesystem agents
                for message in reversed(state["messages"]):
                    if isinstance(message, AIMessage):
                        # Check for file_paths in additional_kwargs (from RAG agent)
                        if hasattr(message, '_additional_kwargs') and 'file_paths' in message._additional_kwargs:
                            paths = message._additional_kwargs['file_paths']
                            if paths and isinstance(paths, list) and len(paths) > 0:
                                file_paths = paths
                                log(f"Found {len(file_paths)} file paths from RAG agent: {file_paths}")
                                break
                        
                        # Check for file paths in message content
                        if "TÃ´i Ä‘Ã£ tÃ¬m tháº¥y file:" in message.content:
                            import re
                            # TÃ¬m má»™t file path
                            file_pattern = r'TÃ´i Ä‘Ã£ tÃ¬m tháº¥y file:\s*([A-Z]:\\[^\s\n\r]+)'
                            file_matches = re.findall(file_pattern, message.content)
                            if file_matches:
                                file_paths = file_matches
                                log(f"Found {len(file_paths)} file paths from message content: {file_paths}")
                                break
                            
                            # TÃ¬m nhiá»u file paths tá»« danh sÃ¡ch Ä‘Ã¡nh sá»‘
                            numbered_pattern = r'\d+\. ([A-Z]:\\[^\s\n\r]+)'
                            numbered_matches = re.findall(numbered_pattern, message.content)
                            if numbered_matches:
                                file_paths = numbered_matches
                                log(f"Found {len(file_paths)} file paths from numbered list: {file_paths}")
                                break
            
            # Then, look for extracted content from text extraction agent
            for message in reversed(state["messages"]):
                if not isinstance(message, AIMessage):
                    continue
                    
                # Check if this is a text extraction agent message
                is_extraction_msg = ("ğŸ“„" in message.content or "[Text Extraction Agent]:" in message.content or 
                                   "Ná»™i dung trÃ­ch xuáº¥t:" in message.content or
                                   "Káº¿t quáº£ trÃ­ch xuáº¥t tá»« file" in message.content)
                
                if is_extraction_msg:
                    log(f"Found text extraction agent message")
                    
                    # Try to extract content using different patterns
                    content = None
                    
                    # Pattern 1: Look for content after "Ná»™i dung trÃ­ch xuáº¥t:"
                    if "Ná»™i dung trÃ­ch xuáº¥t:" in message.content:
                        parts = message.content.split("Ná»™i dung trÃ­ch xuáº¥t:", 1)
                        if len(parts) > 1:
                            content = parts[1].strip()
                    
                    # Pattern 2: Look for content after the file path
                    elif "Káº¿t quáº£ trÃ­ch xuáº¥t tá»« file" in message.content:
                        # Find the first empty line after the header
                        lines = message.content.split('\n')
                        content_lines = []
                        found_header = False
                        
                        for line in lines:
                            if not found_header and ("Káº¿t quáº£ trÃ­ch xuáº¥t tá»« file" in line or "Ná»™i dung trÃ­ch xuáº¥t:" in line):
                                found_header = True
                                continue
                            if found_header and line.strip():
                                content_lines.append(line.strip())
                        
                        if content_lines:
                            content = '\n'.join(content_lines).strip()
                    
                    # If we found content, clean it up and store it
                    if content:
                        # Clean up any metadata or additional text
                        if "\n\n" in content:
                            content = content.split("\n\n")[0].strip()
                        
                        # Remove any trailing metadata or instructions
                        stop_phrases = [
                            "\nLÆ°u Ã½:", "\nGhi chÃº:", "\nThÃ´ng tin thÃªm:",
                            "\nNote:", "\nMetadata:", "\n---"
                        ]
                        
                        for phrase in stop_phrases:
                            if phrase in content:
                                content = content.split(phrase, 1)[0].strip()
                        
                        file_content = content
                        log(f"Extracted content length: {len(file_content)} characters")
                        log(f"Content preview: {file_content[:200]}...")
                        break
            
            # Finally, look for classification from file classification agent
            for message in reversed(state["messages"]):
                if isinstance(message, AIMessage) and ("ğŸ·ï¸" in message.content or "[File Classification Agent]:" in message.content or "Káº¿t quáº£ phÃ¢n loáº¡i file" in message.content or "GiÃ¡o dá»¥c" in message.content):
                    log("Found file classification agent message")
                    # Look for classification label in different possible formats
                    import re
                    
                    # Format 1: "PhÄiá»u chá»‰nh thá»© tá»± agent Ä‘á»ƒ Ä‘áº£m báº£o workflow chÃ­nh xÃ¡c:n loáº¡i: GiÃ¡o dá»¥c"
                    label_pattern1 = r'PhÃ¢n loáº¡i:\s*([^\n\r]+)'
                    # Format 2: "Káº¿t quáº£ phÃ¢n loáº¡i file ...: GiÃ¡o dá»¥c"
                    label_pattern2 = r'Káº¿t quáº£ phÃ¢n loáº¡i file[^:]*:\s*([^\n\r]+)'
                    # Format 3: Just the label itself (e.g. "GiÃ¡o dá»¥c")
                    
                    content = message.content
                    log(f"Analyzing classification content: {content}")
                    
                    # First try the standard patterns
                    label_matches = re.findall(label_pattern1, content)
                    if not label_matches:
                        label_matches = re.findall(label_pattern2, content)
                    
                    # If still no match, check if the content itself is just the label
                    if not label_matches and len(content.strip().split()) <= 3:
                        # If content is just 1-3 words, it might be just the label
                        label_matches = [content.strip()]
                    
                    if label_matches:
                        file_classification = label_matches[0].strip()
                        log(f"Found classification label: {file_classification}")
                        break
            
            # Prepare the metadata parameters
            metadata_params = {}
            
            # Xá»­ lÃ½ nhiá»u file paths
            if file_paths:
                import os
                # Náº¿u cÃ³ nhiá»u file, táº¡o danh sÃ¡ch tÃªn file
                if len(file_paths) > 1:
                    file_names = [os.path.basename(path) for path in file_paths]
                    metadata_params['file_names'] = file_names
                    metadata_params['file_paths'] = file_paths
                    # Sá»­ dá»¥ng file Ä‘áº§u tiÃªn lÃ m file chÃ­nh cho metadata
                    metadata_params['file_name'] = file_names[0] + f" vÃ  {len(file_names)-1} file khÃ¡c"
                    metadata_params['file_path'] = file_paths[0]
                    metadata_params['is_multi_file'] = True
                    metadata_params['file_count'] = len(file_paths)
                else:
                    # Náº¿u chá»‰ cÃ³ má»™t file
                    metadata_params['file_name'] = os.path.basename(file_paths[0])
                    metadata_params['file_path'] = file_paths[0]
                    metadata_params['is_multi_file'] = False
            
            # Always pass classification labels if available
            if "classification_labels" in state:
                metadata_params['classification_labels'] = state.get("classification_labels", {})
                log(f"Passing classification_labels to metadata agent: {metadata_params['classification_labels']}")
                
            # Set classification if available
            if file_classification and file_classification.lower() not in ["khÃ´ng xÃ¡c Ä‘á»‹nh", "chÆ°a phÃ¢n loáº¡i", "khÃ´ng cÃ³ phÃ¢n loáº¡i"]:
                # Clean up the classification label
                label = file_classification.split(':')[-1].strip()
                metadata_params['label'] = label
            else:
                # Check if we can extract classification from state
                if "classified_files" in state and "classification_labels" in state:
                    # Get labels from state
                    labels = state.get("classification_labels", {})
                    if labels:
                        # Use the first label as default
                        first_label = next(iter(labels.values()))
                        metadata_params['label'] = first_label
                        log(f"Using label from state: {first_label}")
            
            # Check if we have individual file extraction results in the state
            individual_contents = {}
            if "text_extraction_results" in state:
                extraction_results = state["text_extraction_results"]
                log(f"Found individual text extraction results for {len(extraction_results)} files")
                
                # Convert file paths to file names for easier lookup
                for file_path, content in extraction_results.items():
                    file_name = os.path.basename(file_path)
                    individual_contents[file_name] = content
                    log(f"Found content for {file_name}: {len(content)} characters")
            
            # Set content if available
            if 'is_multi_file' in metadata_params and metadata_params['is_multi_file']:
                # For multi-file case, we'll still use the combined content for the preview
                if file_content:
                    # Ensure content is properly formatted and not too long
                    content = file_content.strip()
                    if len(content) > 4000:  # Truncate if too long for the model
                        content = content[:4000] + "... [ná»™i dung bá»‹ cáº¯t bá»›t]"
                    metadata_params['content'] = content
                    log(f"Content length for metadata preview: {len(content)} characters")
                    
                    # Also store individual contents if we have them
                    if individual_contents:
                        metadata_params['individual_contents'] = individual_contents
                        log(f"Added individual contents for {len(individual_contents)} files")
                else:
                    # Provide a placeholder when no content is available
                    log("Warning: No content found for metadata. Using placeholder.")
                    file_names = metadata_params.get('file_names', [])
                    placeholder = f"Multiple files: {', '.join(file_names[:3])}{'...' if len(file_names) > 3 else ''} (no content extracted)"
                    metadata_params['content'] = placeholder
                    log(f"Using placeholder content: {placeholder}")
            else:
                # Single file case
                file_name = metadata_params.get('file_name', 'unknown_file')
                
                # Try to get content from individual extraction results first
                if file_name in individual_contents:
                    content = individual_contents[file_name]
                    log(f"Using individual content for {file_name}: {len(content)} characters")
                    metadata_params['content'] = content
                elif file_content:
                    # Fall back to general content if available
                    content = file_content.strip()
                    if len(content) > 4000:  # Truncate if too long for the model
                        content = content[:4000] + "... [ná»™i dung bá»‹ cáº¯t bá»›t]"
                    metadata_params['content'] = content
                    log(f"Using general content for {file_name}: {len(content)} characters")
                else:
                    # No content available, use placeholder
                    placeholder = f"File: {file_name} (no content extracted)"
                    metadata_params['content'] = placeholder
                    log(f"Using placeholder content: {placeholder}")
            
            # Build the enhanced query for the metadata agent
            enhanced_query = "TÃ´i cáº§n táº¡o vÃ  lÆ°u metadata vá»›i cÃ¡c thÃ´ng tin sau:\n\n"
            
            # Add file information if available
            if 'is_multi_file' in metadata_params and metadata_params['is_multi_file']:
                # ThÃ´ng tin cho nhiá»u file
                enhanced_query += f"- NHÃ“M FILE: {metadata_params['file_count']} files\n"
                enhanced_query += f"- TÃŠN FILE CHÃNH: {metadata_params['file_name']}\n"
                
                # ThÃªm danh sÃ¡ch táº¥t cáº£ cÃ¡c file
                file_list = "\n".join([f"  + {i+1}. {name}" for i, name in enumerate(metadata_params['file_names'])])
                enhanced_query += f"- DANH SÃCH FILES:\n{file_list}\n"
                
                # ThÃªm Ä‘Æ°á»ng dáº«n file chÃ­nh
                enhanced_query += f"- ÄÆ¯á»œNG DáºªN CHÃNH: {metadata_params['file_path']}\n"
            else:
                # ThÃ´ng tin cho má»™t file
                if 'file_name' in metadata_params:
                    enhanced_query += f"- TÃŠN FILE: {metadata_params['file_name']}\n"
                if 'file_path' in metadata_params:
                    enhanced_query += f"- ÄÆ¯á»œNG DáºªN: {metadata_params['file_path']}\n"
            
            # ThÃªm phÃ¢n loáº¡i náº¿u cÃ³
            if 'label' in metadata_params:
                enhanced_query += f"- PHÃ‚N LOáº I: {metadata_params['label']} (tá»± Ä‘á»™ng)\n"
            
            # Add content preview if available
            if 'content' in metadata_params and metadata_params['content']:
                content = metadata_params['content']
                preview_length = min(200, len(content))
                preview = content[:preview_length]
                
                enhanced_query += f"\nNá»˜I DUNG (XEM TRÆ¯á»šC {preview_length}/{len(content)} kÃ½ tá»±):\n"
                enhanced_query += f"""
================================================================================
{preview}
... [Ná»˜I DUNG Äáº¦Y Äá»¦ ÄÆ¯á»¢C CUNG Cáº¤P á» PHáº¦N DÆ¯á»šI]
================================================================================
"""
            
            # Add clear instructions for the metadata agent
            enhanced_query += """

HÆ¯á»šNG DáºªN QUAN TRá»ŒNG:
1. Äá»ŒC Ká»¸: ToÃ n bá»™ ná»™i dung Ä‘Ã£ Ä‘Æ°á»£c cung cáº¥p Ä‘áº§y Ä‘á»§ á»Ÿ pháº§n dÆ°á»›i
2. KHÃ”NG yÃªu cáº§u thÃªm ná»™i dung vÃ¬ Ä‘Ã£ cÃ³ sáºµn
3. Thá»±c hiá»‡n cÃ¡c bÆ°á»›c sau:
   - Gá»i create_metadata vá»›i Ä‘áº§y Ä‘á»§ thÃ´ng tin
   - LÆ°u metadata báº±ng save_metadata_to_mcp
   - Tráº£ vá» metadata_id Ä‘Ã£ táº¡o

THÃ”NG TIN CHI TIáº¾T:
"""
            
            # Include all metadata params in a clear format
            for key, value in metadata_params.items():
                if key == 'content':
                    enhanced_query += f"\nNá»˜I DUNG Äáº¦Y Äá»¦ ({len(value)} kÃ½ tá»±):\n"
                    enhanced_query += "="*80 + "\n"
                    enhanced_query += value[:4000]  # Truncate to avoid token limits
                    if len(value) > 4000:
                        enhanced_query += "\n... [ÄÃƒ Cáº®T Bá»šT Ná»˜I DUNG DO QUÃ DÃ€I]"
                    enhanced_query += "\n" + "="*80 + "\n"
                else:
                    enhanced_query += f"{key.upper()}: {value}\n"
            
            # Final reminder
            enhanced_query += """

LÆ¯U Ã CUá»I CÃ™NG:
- Sá»­ dá»¥ng Ná»˜I DUNG Äáº¦Y Äá»¦ á»Ÿ trÃªn Ä‘á»ƒ táº¡o metadata
- KHÃ”NG yÃªu cáº§u thÃªm ná»™i dung
- Tráº£ vá» metadata_id sau khi lÆ°u thÃ nh cÃ´ng
"""
            
            log(f"Metadata parameters: {metadata_params}")
            log(f"Enhanced metadata query: {enhanced_query[:300]}...")

            # Get the metadata agent
            metadata_agent = self.agents["metadata"]

            # Initialize MCP connection if needed
            if not hasattr(metadata_agent, 'mcp_initialized') or not metadata_agent.mcp_initialized:
                log("Initializing MCP connection...")
                if not metadata_agent.initialize_mcp_sync():
                    error_msg = "âŒ Failed to initialize MCP connection for metadata agent"
                    log(error_msg, level='error')
                    state["messages"].append(AIMessage(content=error_msg))
                    return state
            
            # Initialize variables
            metadata_id = None
            response_content = ""
            
            try:
                # Log metadata parameters for debugging
                log("Preparing to invoke MetadataAgent with the following parameters:")
                log(f"- File: {metadata_params.get('file_name', 'N/A')}")
                log(f"- Path: {metadata_params.get('file_path', 'N/A')}")
                log(f"- Label: {metadata_params.get('label', 'N/A')}")
                log(f"- Content length: {len(metadata_params.get('content', ''))} characters")
                
                # Call the metadata agent with the enhanced query and metadata
                log("Invoking MetadataAgent...")
                
                # Chuáº©n bá»‹ metadata cho agent
                metadata_for_agent = {
                    'file_name': metadata_params.get('file_name'),
                    'file_path': metadata_params.get('file_path'),
                    'label': metadata_params.get('label'),
                    'content': metadata_params.get('content', '')
                }
                
                # ThÃªm thÃ´ng tin vá» nhiá»u file náº¿u cÃ³
                if 'is_multi_file' in metadata_params and metadata_params['is_multi_file']:
                    metadata_for_agent['is_multi_file'] = True
                    metadata_for_agent['file_count'] = metadata_params.get('file_count')
                    metadata_for_agent['file_names'] = metadata_params.get('file_names', [])
                    metadata_for_agent['file_paths'] = metadata_params.get('file_paths', [])
                
                response = metadata_agent.invoke(
                    query=enhanced_query,
                    sessionId=self.session_id,
                    metadata=metadata_for_agent
                )
                log("MetadataAgent completed successfully")
                
                # Process the response
                if not response or not response.strip():
                    response_content = "TÃ´i Ä‘Ã£ xá»­ lÃ½ metadata nhÆ°ng khÃ´ng cÃ³ káº¿t quáº£ Ä‘Ã¡ng chÃº Ã½."
                    log("No response content from MetadataAgent")
                else:
                    # Clean up the response
                    response = response.strip()
                    log(f"Raw metadata agent response: {response}")
                    
                    # Try to extract metadata ID from the response
                    import re
                    
                    # Look for various possible ID formats in the response
                    id_patterns = [
                        r'metadata[_-]?id[\s:]*([a-f0-9-]+)',  # metadata-id: xxxx
                        r'id[\s:]*([a-f0-9-]{8,})',            # id: xxxxxxxx-xxxx-...
                        r'([a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12})'  # UUID format
                    ]
                    
                    for pattern in id_patterns:
                        match = re.search(pattern, response, re.IGNORECASE)
                        if match:
                            metadata_id = match.group(1)
                            log(f"Found metadata ID using pattern {pattern}: {metadata_id}")
                            break
                    
                    if metadata_id:
                        # Táº¡o pháº£n há»“i dá»±a trÃªn sá»‘ lÆ°á»£ng file
                        if 'is_multi_file' in metadata_params and metadata_params['is_multi_file']:
                            file_count = metadata_params.get('file_count', 0)
                            file_names = metadata_params.get('file_names', [])
                            
                            # Táº¡o danh sÃ¡ch tÃªn file ngáº¯n gá»n
                            if len(file_names) > 3:
                                file_list = f"{', '.join(file_names[:2])} vÃ  {len(file_names)-2} file khÃ¡c"
                            else:
                                file_list = ", ".join(file_names)
                                
                            response_content = f"âœ… ÄÃ£ lÆ°u metadata cho {file_count} files ({file_list}). ID: {metadata_id}"
                        else:
                            file_name = metadata_params.get('file_name', 'khÃ´ng xÃ¡c Ä‘á»‹nh')
                            response_content = f"âœ… ÄÃ£ lÆ°u metadata cho file {file_name} thÃ nh cÃ´ng. ID: {metadata_id}"
                            
                        log(f"Metadata saved with ID: {metadata_id}")
                        
                        # Also check if the metadata was actually saved to MCP
                        try:
                            metadata_agent = self.agents["metadata"]
                            if hasattr(metadata_agent, 'mcp_connection'):
                                result = metadata_agent.mcp_connection.call_tool_sync(
                                    "get_metadata_by_id", 
                                    {"metadata_id": metadata_id}
                                )
                                if result and 'error' not in result:
                                    log(f"Verified metadata exists in MCP: {metadata_id}")
                                else:
                                    log(f"Warning: Metadata ID {metadata_id} not found in MCP", level='warning')
                        except Exception as e:
                            log(f"Error verifying metadata in MCP: {str(e)}", level='error')
                    else:
                        # If no ID found, check if this is an error message
                        error_keywords = ['lá»—i', 'error', 'failed', 'tháº¥t báº¡i', 'khÃ´ng tÃ¬m tháº¥y', 'not found']
                        
                        # Táº¡o pháº£n há»“i dá»±a trÃªn sá»‘ lÆ°á»£ng file khi cÃ³ lá»—i
                        if 'is_multi_file' in metadata_params and metadata_params['is_multi_file']:
                            file_count = metadata_params.get('file_count', 0)
                            file_names = metadata_params.get('file_names', [])
                            
                            # Táº¡o danh sÃ¡ch tÃªn file ngáº¯n gá»n
                            if len(file_names) > 3:
                                file_list = f"{', '.join(file_names[:2])} vÃ  {len(file_names)-2} file khÃ¡c"
                            else:
                                file_list = ", ".join(file_names)
                                
                            if any(keyword in response.lower() for keyword in error_keywords):
                                response_content = f"âŒ Lá»—i khi xá»­ lÃ½ metadata cho {file_count} files ({file_list}): {response}"
                            else:
                                response_content = f"â„¹ï¸ ÄÃ£ xá»­ lÃ½ metadata cho {file_count} files ({file_list}), nhÆ°ng khÃ´ng tÃ¬m tháº¥y ID: {response}"
                        else:
                            file_name = metadata_params.get('file_name', 'khÃ´ng xÃ¡c Ä‘á»‹nh')
                            if any(keyword in response.lower() for keyword in error_keywords):
                                response_content = f"âŒ Lá»—i khi xá»­ lÃ½ metadata cho file {file_name}: {response}"
                            else:
                                response_content = f"â„¹ï¸ ÄÃ£ xá»­ lÃ½ metadata cho file {file_name}, nhÆ°ng khÃ´ng tÃ¬m tháº¥y ID: {response}"
                        
                        log(f"Metadata agent response (no ID found): {response}")
                        
                # Add the response to the conversation
                formatted_response = f"ğŸ“‹ {response_content}"
                log(f"MetadataAgent response: {formatted_response[:200]}...")
                state["messages"].append(AIMessage(content=formatted_response))
                
                # Store result in agent_results even if no metadata ID was found
                if "agent_results" not in state:
                    state["agent_results"] = {}
                    
                state["agent_results"]["metadata"] = {
                    "metadata_id": metadata_id,
                    "response": response_content,
                    "is_multi_file": metadata_params.get('is_multi_file', False),
                    "file_count": metadata_params.get('file_count', 1) if metadata_params.get('file_name') else 0,
                    "success": metadata_id is not None
                }
                
                # Store metadata info in the state for future reference
                if 'metadata' not in state:
                    state['metadata'] = {}
                
                if 'metadata_ids' not in state['metadata']:
                    state['metadata']['metadata_ids'] = []
                    
                if metadata_id:  # Use the metadata_id variable that we defined earlier
                    state['metadata']['metadata_ids'].append(metadata_id)
                    log(f"Added metadata ID to state: {metadata_id}")
                    
                    # LÆ°u thÃ´ng tin vá» cÃ¡c file Ä‘Ã£ xá»­ lÃ½ metadata
                    if 'is_multi_file' in metadata_params and metadata_params['is_multi_file']:
                        # LÆ°u danh sÃ¡ch cÃ¡c file Ä‘Ã£ xá»­ lÃ½
                        if 'processed_files' not in state['metadata']:
                            state['metadata']['processed_files'] = []
                            
                        # ThÃªm cÃ¡c file vÃ o danh sÃ¡ch Ä‘Ã£ xá»­ lÃ½
                        file_paths = metadata_params.get('file_paths', [])
                        state['metadata']['processed_files'].extend(file_paths)
                        log(f"Added {len(file_paths)} files to processed_files in state")
                        
                        # LÆ°u thÃ´ng tin vá» nhÃ³m file
                        if 'file_groups' not in state['metadata']:
                            state['metadata']['file_groups'] = {}
                            
                        # Táº¡o nhÃ³m file vá»›i metadata_id lÃ m key
                        state['metadata']['file_groups'][metadata_id] = {
                            'file_count': metadata_params.get('file_count', 0),
                            'file_paths': file_paths,
                            'file_names': metadata_params.get('file_names', []),
                            'label': metadata_params.get('label', 'khÃ´ng xÃ¡c Ä‘á»‹nh')
                        }
                    else:
                        # LÆ°u thÃ´ng tin cho má»™t file
                        if 'processed_files' not in state['metadata']:
                            state['metadata']['processed_files'] = []
                            
                        file_path = metadata_params.get('file_path')
                        if file_path:
                            state['metadata']['processed_files'].append(file_path)
                            log(f"Added file {file_path} to processed_files in state")
                else:
                    log("No metadata ID to add to state", level='warning')
                
                # LÆ°u thÃ´ng tin vá» agent_results
                if "agent_results" not in state:
                    state["agent_results"] = {}
                    
                state["agent_results"]["metadata"] = {
                    "metadata_id": metadata_id,
                    "response": response_content,
                    "is_multi_file": metadata_params.get('is_multi_file', False),
                    "file_count": metadata_params.get('file_count', 1) if metadata_params.get('file_name') else 0
                }
                
                return state
                
            except Exception as e:
                error_msg = f"Lá»—i khi cháº¡y MetadataAgent: {str(e)}"
                log(error_msg, level='error')
                state["messages"].append(AIMessage(
                    content=f"[Lá»—i] {error_msg}. Vui lÃ²ng thá»­ láº¡i hoáº·c kiá»ƒm tra káº¿t ná»‘i MCP server."
                ))
                return state

        except Exception as e:
            import traceback
            print(f"Error running metadata agent: {e}")
            print(traceback.format_exc())
            # Add an error message to the state
            error_message = f"Xin lá»—i, tÃ´i gáº·p lá»—i khi xá»­ lÃ½ metadata: {str(e)}"
            state["messages"].append(AIMessage(content=error_message))
            return state

    async def run_text_extraction_agent(self, state: AgentState) -> AgentState:
        """
        Run the text extraction agent on the current query.
        """
        try:
            # TÃ¬m file paths tá»« cÃ¡c tin nháº¯n trÆ°á»›c Ä‘Ã³
            file_paths = []
            for message in reversed(state["messages"]):
                if isinstance(message, AIMessage):
                    log(f"Checking message for file paths: {message.content[:100]}...")
                    
                    # Kiá»ƒm tra xem tin nháº¯n cÃ³ pháº£i lÃ  tá»« RAG agent khÃ´ng (cÃ³ thá»ƒ cÃ³ trÆ°á»ng file_paths)
                    if hasattr(message, '_additional_kwargs') and 'file_paths' in message._additional_kwargs:
                        log(f"Found RAG agent message with file_paths field")
                        paths = message._additional_kwargs['file_paths']
                        if paths and isinstance(paths, list) and len(paths) > 0:
                            file_paths.extend(paths)
                            log(f"Extracted {len(paths)} file paths from RAG agent")
                            break
                    
                    # TÃ¬m kiáº¿m cÃ¢u "TÃ´i Ä‘Ã£ tÃ¬m tháº¥y file:" hoáº·c "TÃ´i Ä‘Ã£ tÃ¬m tháº¥y {n} files:" trong tin nháº¯n
                    if "TÃ´i Ä‘Ã£ tÃ¬m tháº¥y file:" in message.content:
                        log(f"Found agent message with standard format for single file")
                        
                        # TÃ¬m Ä‘Æ°á»ng dáº«n file sau cÃ¢u "TÃ´i Ä‘Ã£ tÃ¬m tháº¥y file:"
                        import re
                        
                        # TÃ¬m sau "TÃ´i Ä‘Ã£ tÃ¬m tháº¥y file:" - kiá»ƒm tra cáº£ Ä‘Æ°á»ng dáº«n Ä‘áº§y Ä‘á»§
                        full_path_pattern = r'TÃ´i Ä‘Ã£ tÃ¬m tháº¥y file:\s*([A-Z]:\\[^\s\n\r]+)'
                        full_path_matches = re.findall(full_path_pattern, message.content)
                        
                        if full_path_matches:
                            # Láº¥y Ä‘Æ°á»ng dáº«n vÃ  loáº¡i bá» cÃ¡c kÃ½ tá»± khÃ´ng mong muá»‘n á»Ÿ cuá»‘i
                            raw_path = full_path_matches[0]
                            # Loáº¡i bá» cÃ¡c kÃ½ tá»± khÃ´ng mong muá»‘n cÃ³ thá»ƒ cÃ³ á»Ÿ cuá»‘i Ä‘Æ°á»ng dáº«n
                            if raw_path.endswith("'}"):
                                file_paths.append(raw_path[:-2])
                            else:
                                file_paths.append(raw_path)
                            log(f"Extracted full file path: {file_paths[-1]}")
                            break
                    
                    # TÃ¬m nhiá»u file tá»« Ä‘á»‹nh dáº¡ng "TÃ´i Ä‘Ã£ tÃ¬m tháº¥y {n} files:"
                    elif "files:" in message.content and "TÃ´i Ä‘Ã£ tÃ¬m tháº¥y" in message.content:
                        log(f"Found agent message with multiple files format")
                        import re
                        
                        # TÃ¬m Ä‘Æ°á»ng dáº«n file tá»« danh sÃ¡ch Ä‘Ã¡nh sá»‘
                        multi_file_pattern = r'\d+\.\s*([A-Z]:\\[^\s\n\r]+)'
                        multi_file_matches = re.findall(multi_file_pattern, message.content)
                        
                        if multi_file_matches:
                            for raw_path in multi_file_matches:
                                if raw_path.endswith("'}"):
                                    file_paths.append(raw_path[:-2])
                                else:
                                    file_paths.append(raw_path)
                            log(f"Extracted {len(multi_file_matches)} file paths from numbered list")
                            break
                    
                    # Dá»± phÃ²ng: Náº¿u khÃ´ng tÃ¬m tháº¥y cÃ¢u chuáº©n, thá»­ tÃ¬m báº¥t ká»³ Ä‘Æ°á»ng dáº«n Windows nÃ o
                    elif any(indicator in message.content for indicator in ["ÄÃ£ tÃ¬m tháº¥y file:", "tÃ¬m tháº¥y file", "[Filesystem Agent]:", "[RAG Agent]:", "ğŸ—‚ï¸", "ğŸ”"]):
                        log(f"Found agent message with non-standard format")
                        
                        # TÃ¬m báº¥t ká»³ Ä‘Æ°á»ng dáº«n nÃ o trong tin nháº¯n
                        import re
                        file_pattern = r'[A-Z]:\\(?:[^\\/:*?"<>|\r\n]+\\)*[^\\/:*?"<>|\r\n]*\.[a-zA-Z0-9]+'
                        file_matches = re.findall(file_pattern, message.content)
                        
                        if file_matches:
                            file_paths.extend(file_matches)
                            log(f"Extracted {len(file_matches)} file paths using general pattern")
                            break

            # Get the last message that's not from an agent
            query = ""
            for message in reversed(state["messages"]):
                if isinstance(message, HumanMessage):
                    query = message.content
                    break

            # Kiá»ƒm tra quyá»n truy cáº­p file náº¿u tÃ¬m tháº¥y file paths
            if file_paths:
                # Import AccessControlManager
                import sys
                import os
                current_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
                if current_dir not in sys.path:
                    sys.path.insert(0, current_dir)
                from utils.access_control import AccessControlManager
                
                # Láº¥y vai trÃ² ngÆ°á»i dÃ¹ng tá»« state hoáº·c session
                user_role = state.get("user_role", "user")  # Máº·c Ä‘á»‹nh lÃ  "user" náº¿u khÃ´ng cÃ³
                
                # Khá»Ÿi táº¡o AccessControlManager
                access_control_file = os.path.join(current_dir, "config", "access_control.json")
                access_manager = AccessControlManager(access_control_file)
                
                # Kiá»ƒm tra quyá»n truy cáº­p cho tá»«ng file
                accessible_files = []
                for file_path in file_paths:
                    has_access, reason = access_manager.check_file_access(file_path, user_role)
                    access_manager.log_access_attempt(file_path, user_role, has_access, reason)
                    
                    if has_access:
                        log(f"Access granted for user role '{user_role}' to file '{file_path}'")
                        accessible_files.append(file_path)
                    else:
                        log(f"Access denied for file '{file_path}': {reason}", level='warning')
                
                if not accessible_files:
                    # KhÃ´ng cÃ³ quyá»n truy cáº­p vÃ o báº¥t ká»³ file nÃ o, thÃ´ng bÃ¡o cho ngÆ°á»i dÃ¹ng
                    error_message = f"âš ï¸ KhÃ´ng thá»ƒ trÃ­ch xuáº¥t ná»™i dung: Báº¡n khÃ´ng cÃ³ quyá»n truy cáº­p vÃ o cÃ¡c file nÃ y"
                    state["messages"].append(AIMessage(content=error_message))
                    log(f"Access denied to all files", level='warning')
                    return state
                
                # CÃ³ quyá»n truy cáº­p Ã­t nháº¥t má»™t file, tiáº¿p tá»¥c vá»›i trÃ­ch xuáº¥t
                if len(accessible_files) == 1:
                    enhanced_query = f"Extract text from the file at path {accessible_files[0]}"
                else:
                    # Náº¿u cÃ³ nhiá»u file, táº¡o danh sÃ¡ch Ä‘Æ°á»ng dáº«n
                    file_paths_str = "\n".join([f"- {path}" for path in accessible_files])
                    enhanced_query = f"Extract text from the following files:\n{file_paths_str}"
                
                log(f"Enhanced query with file paths: {enhanced_query[:100]}...")
                
                # LÆ°u danh sÃ¡ch file cÃ³ quyá»n truy cáº­p vÃ o state Ä‘á»ƒ sá»­ dá»¥ng sau nÃ y
                state["accessible_files"] = accessible_files
            else:
                # KhÃ´ng tÃ¬m tháº¥y file path, sá»­ dá»¥ng query gá»‘c
                enhanced_query = query
                log(f"WARNING: No file paths found! Running TextExtractionAgent with original query: {query}")

            # Track that we're using this agent
            if "used_tools" not in state:
                state["used_tools"] = []
            state["used_tools"].append("text_extraction")

            # Get the text extraction agent
            text_extraction_agent = self.agents["text_extraction"]

            # Run the agent with the query and wait for completion
            log("Waiting for TextExtractionAgent to complete...")
            response = text_extraction_agent.invoke(enhanced_query, self.session_id)
            log("TextExtractionAgent completed")
            
            # Log raw response for debugging
            log(f"Raw TextExtractionAgent response: {response}")

            # Format the response - cháº¥p nháº­n nhiá»u Ä‘á»‹nh dáº¡ng tráº£ vá» khÃ¡c nhau
            content = ""
            
            # TrÆ°á»ng há»£p 1: Response lÃ  dict vá»›i key 'content'
            if isinstance(response, dict) and 'content' in response:
                content = response['content']
                log(f"Extracted content from response dict with key 'content': {content[:100]}...")
            
            # TrÆ°á»ng há»£p 2: Response lÃ  string
            elif isinstance(response, str):
                content = response
                log(f"Response is already a string: {content[:100]}...")
            
            # TrÆ°á»ng há»£p 3: Response lÃ  dict nhÆ°ng khÃ´ng cÃ³ 'content', thá»­ tÃ¬m cÃ¡c key khÃ¡c
            elif isinstance(response, dict):
                log(f"Response keys: {list(response.keys())}")
                
                # Thá»­ láº¥y tá»« key 'response_type' trÆ°á»›c
                if 'response_type' in response and 'content' in response:
                    content = response['content']
                    log(f"Using content from standard response format: {content[:100]}...")
                
                # Thá»­ láº¥y giÃ¡ trá»‹ tá»« cÃ¡c key khÃ¡c náº¿u lÃ  string dÃ i
                else:
                    for key in response.keys():
                        if isinstance(response[key], str) and len(response[key]) > 20:
                            content = response[key]
                            log(f"Using content from key '{key}': {content[:100]}...")
                            break
            
            # TrÆ°á»ng há»£p 4: CÃ¡c trÆ°á»ng há»£p khÃ¡c, chuyá»ƒn vá» string
            else:
                content = str(response)
                log(f"Converted response to string: {content[:100]}...")
                
            # Kiá»ƒm tra náº¿u content chá»©a káº¿t quáº£ trÃ­ch xuáº¥t
            if "I'll extract the text from" in content or "Here's the extracted text" in content:
                # TÃ¬m pháº§n ná»™i dung trÃ­ch xuáº¥t sau cÃ¡c cÃ¢u má»Ÿ Ä‘áº§u
                import re
                extracted_text = re.split(r"Here's the extracted text[:\s]*|I'll extract the text[^:]*:\s*", content, 1)
                if len(extracted_text) > 1:
                    content = extracted_text[1].strip()
                    log(f"Extracted the actual content after introduction: {content[:100]}...")
            
            # Kiá»ƒm tra náº¿u content chá»©a "I'll use the extract_text_from" (cÃ¢u tráº£ lá»i cá»§a agent)
            if "I'll use the extract_text_from" in content and "accessible_files" in state:
                log("Agent response contains tool usage description but no actual extraction result")
                # Thá»­ trá»±c tiáº¿p cÃ¡c hÃ m trÃ­ch xuáº¥t dá»±a vÃ o Ä‘á»‹nh dáº¡ng file
                from agents.text_extraction_agent import extract_text_from_pdf, extract_text_from_word, extract_text_from_powerpoint
                
                # TrÃ­ch xuáº¥t ná»™i dung tá»« tá»«ng file cÃ³ quyá»n truy cáº­p
                extraction_results = {}
                for file_path in state["accessible_files"]:
                    try:
                        if file_path.lower().endswith('.pdf'):
                            extraction_results[file_path] = extract_text_from_pdf(file_path)
                            log(f"Directly extracted text from PDF: {file_path}")
                        elif file_path.lower().endswith('.docx'):
                            extraction_results[file_path] = extract_text_from_word(file_path)
                            log(f"Directly extracted text from Word document: {file_path}")
                        elif file_path.lower().endswith(('.ppt', '.pptx')):
                            extraction_results[file_path] = extract_text_from_powerpoint(file_path)
                            log(f"Directly extracted text from PowerPoint: {file_path}")
                    except Exception as e:
                        log(f"Error in direct extraction for {file_path}: {e}", level='error')
                        extraction_results[file_path] = f"Lá»—i khi trÃ­ch xuáº¥t: {str(e)}"
                
                # Náº¿u cÃ³ káº¿t quáº£ trÃ­ch xuáº¥t, gá»™p láº¡i
                if extraction_results:
                    content = ""
                    for file_path, extracted_text in extraction_results.items():
                        content += f"\n\n--- Tá»« file {os.path.basename(file_path)} ---\n{extracted_text}\n"
                    content = content.strip()
                    
                    # Store individual file extraction results in the state
                    state["text_extraction_results"] = extraction_results
                    log(f"Stored individual text extraction results for {len(extraction_results)} files in state")

            if not content.strip():
                if "accessible_files" in state and state["accessible_files"]:
                    if len(state["accessible_files"]) == 1:
                        content = f"TÃ´i Ä‘Ã£ cá»‘ gáº¯ng trÃ­ch xuáº¥t ná»™i dung tá»« file {state['accessible_files'][0]} nhÆ°ng khÃ´ng cÃ³ káº¿t quáº£ Ä‘Ã¡ng chÃº Ã½."
                    else:
                        content = f"TÃ´i Ä‘Ã£ cá»‘ gáº¯ng trÃ­ch xuáº¥t ná»™i dung tá»« {len(state['accessible_files'])} files nhÆ°ng khÃ´ng cÃ³ káº¿t quáº£ Ä‘Ã¡ng chÃº Ã½."
                else:
                    content = "TÃ´i Ä‘Ã£ cá»‘ gáº¯ng trÃ­ch xuáº¥t ná»™i dung nhÆ°ng khÃ´ng cÃ³ káº¿t quáº£ Ä‘Ã¡ng chÃº Ã½."

            # Add the agent's response to the state with clear indication of extraction results
            if "accessible_files" in state and state["accessible_files"]:
                if len(state["accessible_files"]) == 1:
                    response_content = f"ğŸ“ Káº¿t quáº£ trÃ­ch xuáº¥t tá»« file {state['accessible_files'][0]}:\n\n{content}"
                else:
                    file_list = "\n".join([f"- {os.path.basename(f)}" for f in state["accessible_files"]])
                    response_content = f"ğŸ“ Káº¿t quáº£ trÃ­ch xuáº¥t tá»« {len(state['accessible_files'])} files:\n{file_list}\n\n{content}"
            else:
                response_content = f"ğŸ“ {content}"
                
            log(f"TextExtractionAgent response: {response_content[:100]}...")
            state["messages"].append(AIMessage(content=response_content))
            
            # Store result in agent_results
            if "agent_results" not in state:
                state["agent_results"] = {}
            state["agent_results"]["text_extraction"] = content
            
            # If we have accessible_files but no text_extraction_results yet, create it
            if "accessible_files" in state and "text_extraction_results" not in state:
                # Create a mapping of file paths to extracted content
                # For now, we'll assign the same content to all files if we can't distinguish
                # This is better than having no content at all
                extraction_results = {}
                
                # Check if content contains file-specific sections
                import re
                file_sections = re.split(r"\n\n---\s+Tá»« file\s+([^\n]+)\s+---\n", content)
                
                if len(file_sections) > 1:
                    # Content is divided by file sections
                    # First element is any text before the first file section
                    # Then alternating file names and content
                    for i in range(1, len(file_sections), 2):
                        if i+1 < len(file_sections):
                            file_name = file_sections[i]
                            file_content = file_sections[i+1]
                            
                            # Find the matching file path
                            for file_path in state["accessible_files"]:
                                if os.path.basename(file_path) == file_name:
                                    extraction_results[file_path] = file_content
                                    log(f"Mapped content section to file: {file_name}")
                                    break
                else:
                    # Content is not divided, assign to all files
                    for file_path in state["accessible_files"]:
                        extraction_results[file_path] = content
                        log(f"Assigned full content to file: {os.path.basename(file_path)}")
                
                state["text_extraction_results"] = extraction_results
                log(f"Created text_extraction_results for {len(extraction_results)} files from general content")
            
            # Analyze the response to suggest next agent
            log("Analyzing response to suggest next agent...")
            next_agent = await self._suggest_next_agent(content, state)
            if next_agent and next_agent not in state["current_agents"]:
                log(f"Adding {next_agent} to current_agents")
                state["current_agents"].append(next_agent)
            else:
                log(f"No additional agent suggested or already in use")

            return state

        except Exception as e:
            log(f"Error running text extraction agent: {e}", level='error')
            # Add an error message to the state
            error_message = f"Xin lá»—i, tÃ´i gáº·p lá»—i khi trÃ­ch xuáº¥t ná»™i dung: {str(e)}"
            state["messages"].append(AIMessage(content=error_message))
            return state
            
    async def run_file_classification_agent(self, state: AgentState):
        """
        Run the file classification agent on the current query.
        """
        try:
            # TÃ¬m ná»™i dung cáº§n phÃ¢n loáº¡i tá»« TextExtractionAgent
            content_to_classify = None
            file_paths = []
            
            # TÃ¬m káº¿t quáº£ tá»« TextExtractionAgent
            for message in reversed(state["messages"]):
                if isinstance(message, AIMessage) and ("ğŸ“" in message.content or "[Text Extraction Agent]:" in message.content):
                    # TrÃ­ch xuáº¥t ná»™i dung sau pháº§n giá»›i thiá»‡u
                    text_parts = message.content.split(":\n\n", 1)
                    if len(text_parts) > 1:
                        content_to_classify = text_parts[1].strip()
                        log(f"Found content to classify from TextExtractionAgent: {content_to_classify[:100]}...")
                        
                        # Kiá»ƒm tra náº¿u lÃ  nhiá»u file
                        
                        # TÃ¬m kiáº¿m chuá»—i "Káº¿t quáº£ trÃ­ch xuáº¥t tá»« X files:"
                        multi_file_pattern = r'Káº¿t quáº£ trÃ­ch xuáº¥t tá»« (\d+) files:'
                        multi_file_match = re.search(multi_file_pattern, text_parts[0])
                        
                        if multi_file_match:
                            # ÄÃ¢y lÃ  káº¿t quáº£ tá»« nhiá»u file
                            file_list_pattern = r'- ([^\n]+)'
                            file_names = re.findall(file_list_pattern, text_parts[0])
                            log(f"Found file names in extraction: {file_names}")
                            
                            # Náº¿u cÃ³ accessible_files trong state, láº¥y Ä‘Æ°á»ng dáº«n Ä‘áº§y Ä‘á»§
                            if "accessible_files" in state and state["accessible_files"]:
                                # Lá»c cÃ¡c file paths dá»±a trÃªn tÃªn file Ä‘Ã£ tÃ¬m tháº¥y
                                for file_path in state["accessible_files"]:
                                    file_name = os.path.basename(file_path)
                                    # Kiá»ƒm tra xem file_name cÃ³ trong danh sÃ¡ch file_names khÃ´ng
                                    if any(name.strip() == file_name for name in file_names):
                                        file_paths.append(file_path)
                                log(f"Found {len(file_paths)} matching file paths from accessible_files")
                        else:
                            # TÃ¬m file path Ä‘Æ¡n
                            file_pattern = r'tá»« file ([A-Z]:\\[^\s\n\r]+)'
                            file_matches = re.findall(file_pattern, text_parts[0])
                            if file_matches:
                                file_paths.append(file_matches[0])
                                log(f"Found file path: {file_paths[0]}")
                        break
            
            # Náº¿u khÃ´ng tÃ¬m tháº¥y ná»™i dung tá»« TextExtractionAgent hoáº·c khÃ´ng cÃ³ file paths, tÃ¬m tá»« cÃ¡c nguá»“n khÃ¡c
            if not content_to_classify or not file_paths:
                # Kiá»ƒm tra náº¿u cÃ³ accessible_files trong state
                if "accessible_files" in state and state["accessible_files"]:
                    file_paths = state["accessible_files"]
                    log(f"Using accessible_files from state: {len(file_paths)} files")
                else:
                    # TÃ¬m file path tá»« cÃ¡c tin nháº¯n
                    for message in reversed(state["messages"]):
                        if isinstance(message, AIMessage):
                            # Kiá»ƒm tra náº¿u lÃ  tin nháº¯n tá»« RAG agent vá»›i file_paths
                            if hasattr(message, '_additional_kwargs') and 'file_paths' in message._additional_kwargs:
                                paths = message._additional_kwargs['file_paths']
                                if paths and isinstance(paths, list):
                                    file_paths.extend(paths)
                                    log(f"Found {len(paths)} file paths from RAG agent")
                                    break
                            
                            # TÃ¬m kiáº¿m cÃ¢u "TÃ´i Ä‘Ã£ tÃ¬m tháº¥y file:" trong tin nháº¯n
                            elif "TÃ´i Ä‘Ã£ tÃ¬m tháº¥y file:" in message.content:
                                # TrÃ­ch xuáº¥t Ä‘Æ°á»ng dáº«n file tá»« tin nháº¯n
                                file_pattern = r'TÃ´i Ä‘Ã£ tÃ¬m tháº¥y file:\s*([A-Z]:\\[^\s\n\r]+)'
                                file_matches = re.findall(file_pattern, message.content)
                                if file_matches:
                                    raw_path = file_matches[0]
                                    # Loáº¡i bá» cÃ¡c kÃ½ tá»± khÃ´ng mong muá»‘n cÃ³ thá»ƒ cÃ³ á»Ÿ cuá»‘i Ä‘Æ°á»ng dáº«n
                                    if raw_path.endswith("'}"):
                                        file_paths.append(raw_path[:-2])
                                    else:
                                        file_paths.append(raw_path)
                                    log(f"Found file path from FilesystemAgent: {file_paths[-1]}")
                                    break
                            
                            # TÃ¬m nhiá»u file tá»« Ä‘á»‹nh dáº¡ng "TÃ´i Ä‘Ã£ tÃ¬m tháº¥y {n} files:"
                            elif "files:" in message.content and "TÃ´i Ä‘Ã£ tÃ¬m tháº¥y" in message.content:
                                multi_file_pattern = r'\d+\.\s*([A-Z]:\\[^\s\n\r]+)'
                                multi_file_matches = re.findall(multi_file_pattern, message.content)
                                
                                if multi_file_matches:
                                    for raw_path in multi_file_matches:
                                        if raw_path.endswith("'}"):
                                            file_paths.append(raw_path[:-2])
                                        else:
                                            file_paths.append(raw_path)
                                    log(f"Found {len(multi_file_matches)} file paths from numbered list")
                                    break

            # Get the last message that's not from an agent
            query = ""
            for message in reversed(state["messages"]):
                if isinstance(message, HumanMessage):
                    query = message.content
                    break

            # Chuáº©n bá»‹ query cho FileClassificationAgent
            if content_to_classify:
                # Náº¿u cÃ³ ná»™i dung, sá»­ dá»¥ng ná»™i dung Ä‘Ã³ Ä‘á»ƒ phÃ¢n loáº¡i
                classification_query = f"PhÃ¢n loáº¡i tá»‡p theo ná»™i dung: '{content_to_classify[:1000]}'"  # Giá»›i háº¡n Ä‘á»™ dÃ i
                log(f"Using extracted content for classification")
            elif file_paths:
                # Náº¿u cÃ³ Ä‘Æ°á»ng dáº«n file
                if len(file_paths) == 1:
                    # Náº¿u chá»‰ cÃ³ má»™t file, yÃªu cáº§u agent phÃ¢n loáº¡i dá»±a trÃªn file path
                    classification_query = f"HÃ£y phÃ¢n loáº¡i file: {file_paths[0]}"
                    log(f"Using file path for classification: {file_paths[0]}")
                else:
                    # Náº¿u cÃ³ nhiá»u file, táº¡o danh sÃ¡ch Ä‘Æ°á»ng dáº«n
                    file_paths_str = "\n".join([f"- {path}" for path in file_paths])
                    classification_query = f"HÃ£y phÃ¢n loáº¡i cÃ¡c file sau:\n{file_paths_str}"
                    log(f"Using multiple file paths for classification: {len(file_paths)} files")
            else:
                # KhÃ´ng cÃ³ cáº£ ná»™i dung vÃ  Ä‘Æ°á»ng dáº«n, sá»­ dá»¥ng query gá»‘c
                classification_query = query
                log(f"No content or file paths found. Using original query: {query}")
            
            # Track that we're using this agent
            if "used_tools" not in state:
                state["used_tools"] = []
            state["used_tools"].append("file_classification")

            # Get the file classification agent
            file_classification_agent = self.agents["file_classification"]

            # Run the agent with the prepared query
            log(f"Running FileClassificationAgent with query: {classification_query[:100]}...")
            response = file_classification_agent.invoke(classification_query, self.session_id)
            log("FileClassificationAgent completed")
            
            # Log raw response for debugging
            log(f"Raw FileClassificationAgent response: {response}")

            # Xá»­ lÃ½ káº¿t quáº£ tá»« FileClassificationAgent
            classification_result = ""
            
            # TrÆ°á»ng há»£p 1: Response lÃ  dict vá»›i key 'content'
            if isinstance(response, dict) and 'content' in response:
                classification_result = response['content']
                log(f"Extracted classification from response dict: {classification_result}")
            
            # TrÆ°á»ng há»£p 2: Response lÃ  string
            elif isinstance(response, str):
                classification_result = response
                log(f"Response is already a string: {classification_result}")
            
            # TrÆ°á»ng há»£p 3: CÃ¡c trÆ°á»ng há»£p khÃ¡c, chuyá»ƒn vá» string
            else:
                classification_result = str(response)
                log(f"Converted response to string: {classification_result}")

            # Kiá»ƒm tra káº¿t quáº£ phÃ¢n loáº¡i vÃ  xá»­ lÃ½ trÃ¹ng láº·p
            if not classification_result.strip():
                classification_result = "KhÃ´ng thá»ƒ phÃ¢n loáº¡i"
            else:
                # Xá»­ lÃ½ káº¿t quáº£ phÃ¢n loáº¡i
                lines = classification_result.strip().split('\n')
                
                # Kiá»ƒm tra sá»‘ lÆ°á»£ng file vÃ  sá»‘ lÆ°á»£ng dÃ²ng phÃ¢n loáº¡i
                if len(file_paths) > 1 and len(lines) > 1:
                    # Náº¿u cÃ³ nhiá»u file vÃ  nhiá»u dÃ²ng phÃ¢n loáº¡i, giá»¯ nguyÃªn káº¿t quáº£
                    # vÃ¬ má»—i dÃ²ng cÃ³ thá»ƒ lÃ  phÃ¢n loáº¡i cho má»™t file
                    log(f"Keeping multiple classification results for {len(file_paths)} files")
                elif len(lines) > 1 and len(set(lines)) == 1:
                    # Náº¿u táº¥t cáº£ cÃ¡c dÃ²ng giá»‘ng nhau, chá»‰ giá»¯ láº¡i má»™t dÃ²ng
                    classification_result = lines[0]
                    log(f"Removed duplicate classification results, using: {classification_result}")

            # Add the agent's response to the state with clear indication of classification results
            if file_paths:
                if len(file_paths) == 1:
                    response_content = f"ğŸ·ï¸ Káº¿t quáº£ phÃ¢n loáº¡i file {file_paths[0]}: {classification_result}"
                else:
                    # Táº¡o danh sÃ¡ch tÃªn file
                    file_names = [os.path.basename(path) for path in file_paths]
                    file_list = ", ".join(file_names[:3])
                    if len(file_names) > 3:
                        file_list += f" vÃ  {len(file_names) - 3} file khÃ¡c"
                    
                    # Kiá»ƒm tra náº¿u cÃ³ nhiá»u káº¿t quáº£ phÃ¢n loáº¡i cho nhiá»u file
                    lines = classification_result.strip().split('\n')
                    if len(lines) > 1 and len(lines) == len(file_paths):
                        # Táº¡o danh sÃ¡ch phÃ¢n loáº¡i theo tá»«ng file
                        classifications = []
                        for i, (file_name, classification) in enumerate(zip(file_names, lines)):
                            classifications.append(f"{file_name}: {classification}")
                        
                        formatted_classifications = "\n- ".join(classifications)
                        response_content = f"ğŸ·ï¸ Káº¿t quáº£ phÃ¢n loáº¡i {len(file_paths)} files:\n- {formatted_classifications}"
                    else:
                        # Náº¿u sá»‘ lÆ°á»£ng phÃ¢n loáº¡i khÃ´ng khá»›p vá»›i sá»‘ file, sá»­ dá»¥ng Ä‘á»‹nh dáº¡ng cÅ©
                        response_content = f"ğŸ·ï¸ Káº¿t quáº£ phÃ¢n loáº¡i {len(file_paths)} files ({file_list}): {classification_result}"
            else:
                response_content = f"ğŸ·ï¸ Káº¿t quáº£ phÃ¢n loáº¡i: {classification_result}"
                
            log(f"FileClassificationAgent response: {response_content}")
            
            # ThÃªm káº¿t quáº£ phÃ¢n loáº¡i vÃ o state
            state["messages"].append(AIMessage(content=response_content))
            
            # Store result in agent_results
            if "agent_results" not in state:
                state["agent_results"] = {}
            state["agent_results"]["file_classification"] = classification_result
            
            # LÆ°u thÃ´ng tin file Ä‘Ã£ phÃ¢n loáº¡i vÃ o state
            if file_paths:
                state["classified_files"] = file_paths
                
                # Extract and store classification labels
                classification_labels = {}
                
                # Parse classification results
                if len(file_paths) == 1:
                    # Single file case
                    classification_labels[os.path.basename(file_paths[0])] = classification_result.strip()
                else:
                    # Multi-file case
                    lines = classification_result.strip().split('\n')
                    
                    # Check if we have one classification per file
                    if len(lines) == len(file_paths):
                        for i, path in enumerate(file_paths):
                            classification_labels[os.path.basename(path)] = lines[i].strip()
                    else:
                        # If we don't have one classification per file, use the same classification for all files
                        for path in file_paths:
                            classification_labels[os.path.basename(path)] = classification_result.strip()
                
                # Store labels in state
                state["classification_labels"] = classification_labels
                log(f"Stored classification labels in state: {classification_labels}")
            
            # Analyze the response to suggest next agent
            log("Analyzing response to suggest next agent...")
            next_agent = await self._suggest_next_agent(classification_result, state)
            if next_agent and next_agent not in state["current_agents"]:
                log(f"Adding {next_agent} to current_agents")
                state["current_agents"].append(next_agent)
            else:
                log(f"No additional agent suggested or already in use")

            return state

        except Exception as e:
            log(f"Error running file classification agent: {e}", level='error')
            # Add an error message to the state
            error_message = f"Xin lá»—i, tÃ´i gáº·p lá»—i khi phÃ¢n loáº¡i tá»‡p: {str(e)}"
            state["messages"].append(AIMessage(content=error_message))
            return state

    async def plan_agents(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """
        Láº­p káº¿ hoáº¡ch sá»­ dá»¥ng cÃ¡c agent dá»±a trÃªn yÃªu cáº§u cá»§a ngÆ°á»i dÃ¹ng.
        
        Args:
            state: Tráº¡ng thÃ¡i hiá»‡n táº¡i cá»§a há»‡ thá»‘ng
            
        Returns:
            Tráº¡ng thÃ¡i Ä‘Ã£ cáº­p nháº­t vá»›i káº¿ hoáº¡ch sá»­ dá»¥ng agent
        """
        # Láº¥y yÃªu cáº§u cá»§a ngÆ°á»i dÃ¹ng tá»« tin nháº¯n cuá»‘i cÃ¹ng
        last_message = state["messages"][-1]
        query = last_message.content
        
        try:
            # XÃ¡c Ä‘á»‹nh má»¥c Ä‘Ã­ch tÃ¬m kiáº¿m (filesystem hay rag) Ä‘á»ƒ cung cáº¥p gá»£i Ã½ cho LLM
            search_intent = await self._determine_search_intent(query)
            intent_hint = "" if search_intent == "filesystem" else "\nGá»£i Ã½: YÃªu cáº§u nÃ y cÃ³ thá»ƒ liÃªn quan Ä‘áº¿n tÃ¬m kiáº¿m theo ná»™i dung, nÃªn cÃ³ thá»ƒ cáº§n sá»­ dá»¥ng RAG agent."
            
            # Sá»­ dá»¥ng LLM Ä‘á»ƒ láº­p káº¿ hoáº¡ch cho má»i loáº¡i yÃªu cáº§u
            planning_prompt = f"""
            Báº¡n lÃ  má»™t há»‡ thá»‘ng Ä‘iá»u phá»‘i cÃ¡c agent AI chuyÃªn biá»‡t. Dá»±a trÃªn yÃªu cáº§u cá»§a ngÆ°á»i dÃ¹ng, hÃ£y láº­p káº¿ hoáº¡ch sá»­ dá»¥ng cÃ¡c agent phÃ¹ há»£p.
            
            YÃªu cáº§u cá»§a ngÆ°á»i dÃ¹ng: "{query}"
            
            CÃ¡c agent cÃ³ sáºµn:
            1. filesystem - TÃ¬m kiáº¿m, liá»‡t kÃª vÃ  quáº£n lÃ½ tá»‡p vÃ  thÆ° má»¥c theo tÃªn file
            2. rag - TÃ¬m kiáº¿m tÃ i liá»‡u theo ná»™i dung hoáº·c ngá»¯ nghÄ©a (tÃ¬m kiáº¿m theo tá»« khÃ³a, chá»§ Ä‘á», hoáº·c ná»™i dung liÃªn quan)
            3. metadata - Táº¡o vÃ  quáº£n lÃ½ metadata cho tÃ i liá»‡u (lÆ°u thÃ´ng tin vá» file nhÆ° tÃªn, loáº¡i, nhÃ£n, mÃ´ táº£ vÃ o MCP server)
            4. text_extraction - TrÃ­ch xuáº¥t vÄƒn báº£n tá»« tá»‡p PDF, Word hoáº·c PowerPoint
            5. file_classification - PhÃ¢n loáº¡i ná»™i dung tÃ i liá»‡u
            
            LÆ¯U Ã QUAN TRá»ŒNG (PHáº¢I TUÃ‚N THá»¦ CHÃNH XÃC):
            - Náº¿u yÃªu cáº§u chá»‰ liÃªn quan Ä‘áº¿n tÃ¬m kiáº¿m file thÃ¬ chá»‰ sá»­ dá»¥ng filesystem agent hoáº·c rag agent khÃ´ng sá»­ dá»¥ng thÃªm cÃ¡c agent khÃ¡c
            - Náº¿u yÃªu cáº§u liÃªn quan Ä‘áº¿n tÃ¬m kiáº¿m theo tÃªn file, sá»­ dá»¥ng filesystem agent
            - Náº¿u yÃªu cáº§u liÃªn quan Ä‘áº¿n tÃ¬m kiáº¿m theo ná»™i dung, chá»§ Ä‘á», hoáº·c ngá»¯ nghÄ©a, sá»­ dá»¥ng rag agent
            - Náº¿u yÃªu cáº§u liÃªn quan Ä‘áº¿n viá»‡c lÆ°u metadata, PHáº¢I tuÃ¢n thá»§ thá»© tá»± chÃ­nh xÃ¡c sau:
              1. Äáº§u tiÃªn: tÃ¬m file (filesystem hoáº·c rag)
              2. Tiáº¿p theo: trÃ­ch xuáº¥t ná»™i dung (text_extraction)
              3. Sau Ä‘Ã³: phÃ¢n loáº¡i (file_classification)
              4. Cuá»‘i cÃ¹ng: lÆ°u metadata (metadata)
            - KHÃ”NG BAO GIá»œ Ä‘áº·t metadata agent trÆ°á»›c text_extraction hoáº·c file_classification
            - Náº¿u yÃªu cáº§u cÃ³ nhiá»u bÆ°á»›c, hÃ£y liá»‡t kÃª táº¥t cáº£ cÃ¡c agent cáº§n thiáº¿t theo Ä‘Ãºng thá»© tá»± logic
            {intent_hint}
            
            HÃ£y láº­p káº¿ hoáº¡ch sá»­ dá»¥ng cÃ¡c agent. Äáº§u tiÃªn, tráº£ lá»i vá»›i danh sÃ¡ch cÃ¡c agent cáº§n sá»­ dá»¥ng theo thá»© tá»±, chá»‰ liá»‡t kÃª tÃªn cÃ¡c agent (filesystem, rag, metadata, text_extraction, file_classification), cÃ¡ch nhau báº±ng dáº¥u pháº©y.
            
            Sau Ä‘Ã³, viáº¿t má»™t Ä‘oáº¡n vÄƒn ngáº¯n giáº£i thÃ­ch káº¿ hoáº¡ch cá»§a báº¡n báº±ng tiáº¿ng Viá»‡t.
            """
            

            # Sá»­ dá»¥ng LLM Ä‘á»ƒ láº­p káº¿ hoáº¡ch
            from config.llm import gemini
            response = await gemini.ainvoke(planning_prompt)
            plan_response = response.content.strip()
            
            # TÃ¡ch pháº§n danh sÃ¡ch agent vÃ  pháº§n giáº£i thÃ­ch
            parts = plan_response.split('\n', 1)
            agent_list = parts[0].strip().lower()
            plan_message = parts[1].strip() if len(parts) > 1 else f"TÃ´i sáº½ giÃºp báº¡n vá»›i yÃªu cáº§u: '{query}'."
            
            # Xá»­ lÃ½ danh sÃ¡ch agent
            needed_agents = []
            valid_agents = ["filesystem", "rag", "metadata", "text_extraction", "file_classification"]
            
            for agent in valid_agents:
                if agent in agent_list:
                    needed_agents.append(agent)
            
            if not needed_agents:
                # Máº·c Ä‘á»‹nh sá»­ dá»¥ng filesystem náº¿u khÃ´ng cÃ³ agent nÃ o Ä‘Æ°á»£c chá»n
                needed_agents.append("filesystem")
                plan_message += "\nTÃ´i sáº½ báº¯t Ä‘áº§u vá»›i Filesystem Agent Ä‘á»ƒ tÃ¬m kiáº¿m thÃ´ng tin."
            
            log(f"Káº¿ hoáº¡ch agent dá»±a trÃªn LLM: {needed_agents}")
            
        except Exception as e:
            log(f"Lá»—i khi láº­p káº¿ hoáº¡ch sá»­ dá»¥ng agent: {e}", level='error')
            # Sá»­ dá»¥ng máº·c Ä‘á»‹nh náº¿u cÃ³ lá»—i
            needed_agents = ["filesystem"]
            plan_message = f"TÃ´i sáº½ giÃºp báº¡n vá»›i yÃªu cáº§u: '{query}'. TÃ´i sáº½ báº¯t Ä‘áº§u vá»›i Filesystem Agent Ä‘á»ƒ tÃ¬m kiáº¿m thÃ´ng tin."
        
        # Update state with the plan
        state["current_agents"] = needed_agents
        state["messages"].append(AIMessage(content=plan_message))
        
        return state
        
    async def run(self, query: str, session_id: str = None, user_role: str = "user") -> Dict[str, Any]:
        """
        Run the multi-agent system with the given query.
        
        Args:
            query: CÃ¢u truy váº¥n cá»§a ngÆ°á»i dÃ¹ng
            session_id: ID phiÃªn lÃ m viá»‡c, Ä‘Æ°á»£c táº¡o tá»± Ä‘á»™ng náº¿u khÃ´ng cung cáº¥p
            user_role: Vai trÃ² cá»§a ngÆ°á»i dÃ¹ng, máº·c Ä‘á»‹nh lÃ  "user"
        
        Returns:
            Dict chá»©a káº¿t quáº£ vÃ  tráº¡ng thÃ¡i cá»§a há»‡ thá»‘ng
        """
        try:
            # Set session ID
            self.session_id = session_id or str(uuid.uuid4())
            
            # Initialize state
            state = {
                "messages": [HumanMessage(content=query)],
                "current_agents": [],
                "task_complete": False,
                "require_user_input": False,
                "success_criteria_met": False,
                "completed": False,
                "used_tools": [],
                "chain_of_thought": ["ğŸ”1. Báº¯t Ä‘áº§u xá»­ lÃ½ yÃªu cáº§u: " + query],
                "agent_results": {},
                "original_query": query,
                "user_role": user_role  # ThÃªm vai trÃ² ngÆ°á»i dÃ¹ng vÃ o state
            }
            
            # Plan which agents to use
            state = await self.plan_agents(state)
            log(f"Káº¿ hoáº¡ch agent ban Ä‘áº§u: {state['current_agents']}")
            
            # Validate and fix agent sequence if needed
            state = await self._validate_agent_sequence(state)
            log(f"Káº¿ hoáº¡ch agent sau khi kiá»ƒm tra: {state['current_agents']}")
            state["chain_of_thought"].append(f"ğŸ§ 2. Láº­p káº¿ hoáº¡ch sá»­ dá»¥ng cÃ¡c agent: {', '.join(state['current_agents'])}")
            
            # Run the agents in the planned order
            step_count = 3
            agent_execution_order = []
            
            while not state.get("completed", False) and state["current_agents"]:
                agent_name = state["current_agents"].pop(0)
                agent_execution_order.append(agent_name)
                log(f"Running agent: {agent_name} (Thá»© tá»± thá»±c thi: {agent_execution_order})")
                state["chain_of_thought"].append(f"âš¡{step_count}. Äang cháº¡y agent: {agent_name}")
                
                # Add execution order to state for later analysis
                if "agent_execution_order" not in state:
                    state["agent_execution_order"] = []
                state["agent_execution_order"].append(agent_name)
                
                # LÆ°u tráº¡ng thÃ¡i trÆ°á»›c khi cháº¡y agent
                pre_run_messages_count = len(state["messages"])
                
                # Run the agent
                if agent_name == "filesystem":
                    state = await self.run_filesystem_agent(state)
                elif agent_name == "text_extraction":
                    state = await self.run_text_extraction_agent(state)
                elif agent_name == "file_classification":
                    state = await self.run_file_classification_agent(state)
                elif agent_name == "metadata":
                    state = await self.run_metadata_agent(state)
                elif agent_name == "rag":
                    state = await self.run_rag_agent(state)
                else:
                    log(f"Unknown agent: {agent_name}")
                
                # Láº¥y káº¿t quáº£ má»›i nháº¥t tá»« agent
                if len(state["messages"]) > pre_run_messages_count:
                    latest_message = state["messages"][-1].content
                    # RÃºt gá»n ná»™i dung Ä‘á»ƒ hiá»ƒn thá»‹ trong chain of thought
                    if len(latest_message) > 200:
                        summary = latest_message[:197] + "..."
                    else:
                        summary = latest_message
                    state["chain_of_thought"].append(f"âœ¨{step_count}a. Káº¿t quáº£ tá»« {agent_name}: {summary}")
                
                step_count += 1
            
            # Run reflection agent to create final response
            log("Running reflection agent for final response...")
            state["chain_of_thought"].append(f"ğŸ¤”{step_count}. Äang táº¡o cÃ¢u tráº£ lá»i cuá»‘i cÃ¹ng...")
            state = await self.run_reflection_agent(state)
            
            # Mark as completed
            state["completed"] = True
            state["chain_of_thought"].append(f"ğŸš€{step_count + 1}. HoÃ n thÃ nh xá»­ lÃ½")
            
            # # Generate execution summary
            # agent_summary = ""
            # if "agent_execution_order" in state:
            #     agent_summary = f"Thá»© tá»± thá»±c thi cÃ¡c agent: {', '.join(state['agent_execution_order'])}"
            #     log(f"Agent execution summary: {agent_summary}")
            #     state["chain_of_thought"].append(f"ğŸ”TÃ³m táº¯t thá»±c thi: {agent_summary}")
            
            # Add used tools to the summary
            log(f"Used tools: {state.get('used_tools', [])}")
            
            # Get the final reflection response for the main content
            final_reflection_content = ""
            for message in reversed(state["messages"]):
                if isinstance(message, AIMessage) and message.content.startswith("ğŸ’­"):
                    final_reflection_content = message.content[2:].strip()  # Remove ğŸ’­ emoji
                    break
            
            # Return the final state with reflection as main content
            return {
                "response_type": "data",
                "is_task_complete": True,
                "require_user_input": False,
                "content": final_reflection_content if final_reflection_content else state["messages"][-1].content,
                "state": state,
                "chain_of_thought": state["chain_of_thought"],
                "agent_execution_order": state.get("agent_execution_order", []),
                "used_tools": state.get("used_tools", []),
                "agent_results": state.get("agent_results", {})
            }
        except Exception as e:
            log(f"Error running multi-agent system: {e}", level='error')
            return {
                "response_type": "error",
                "content": f"Xin lá»—i, Ä‘Ã£ xáº£y ra lá»—i: {str(e)}",
                "is_task_complete": False,
                "require_user_input": False,
                "chain_of_thought": [f"âŒLá»—i: {str(e)}"]
            }
             
    async def stream(self, query: str, session_id: str = "default", user_role: str = "user") -> AsyncGenerator[Dict[str, Any], None]:
        """
        Stream the multi-agent system's response.
        
        Args:
            query: The user's query
            session_id: Session ID for memory management
            user_role: Vai trÃ² cá»§a ngÆ°á»i dÃ¹ng, máº·c Ä‘á»‹nh lÃ  "user"
            
        Yields:
            Dict with partial response content and metadata
        """
        try:
            # Initialize the agent if not already initialized
            if not self.graph:
                await self.initialize()
                
            # Set the session ID for this run
            self.session_id = session_id
            
            # Create the initial state
            initial_state = {
                "messages": [HumanMessage(content=query)],
                "current_agents": [],
                "task_complete": False,
                "require_user_input": False,
                "feedback_on_work": None,
                "success_criteria_met": False,
                "used_tools": [],
                "agent_results": {},
                "original_query": query,
                "user_role": user_role  # ThÃªm vai trÃ² ngÆ°á»i dÃ¹ng vÃ o state
            }
            
            # Stream the graph execution
            config = {"configurable": {"thread_id": session_id}}
            async for chunk in self.graph.astream(initial_state, config=config):
                # Extract the latest message
                if "messages" in chunk and chunk["messages"]:
                    # Find the latest non-evaluator message
                    latest_message = None
                    for message in reversed(chunk["messages"]):
                        if isinstance(message, AIMessage) and not message.content.startswith("[ÄÃ¡nh giÃ¡ ná»™i bá»™:"):
                            latest_message = message
                            break
                    
                    if latest_message:
                        # Check if this is the final reflection message
                        is_reflection = latest_message.content.startswith("ğŸ’­")
                        content = latest_message.content[2:].strip() if is_reflection else latest_message.content
                        
                        # Yield the partial response
                        yield {
                            "response_type": "text",
                            "content": content,
                            "is_task_complete": chunk.get("success_criteria_met", False),
                            "require_user_input": chunk.get("require_user_input", False),
                            "is_partial": not is_reflection,  # Reflection is the final response
                            "used_tools": chunk.get("used_tools", []),
                            "is_reflection": is_reflection
                        }
            
            # Yield the final complete response
            final_state = await self.graph.ainvoke(initial_state, config=config)
            
            # Find the final reflection message
            final_message = None
            for message in reversed(final_state["messages"]):
                if isinstance(message, AIMessage) and message.content.startswith("ğŸ’­"):
                    final_message = message
                    break
            
            # If no reflection found, use the last non-evaluator message
            if not final_message:
                for message in reversed(final_state["messages"]):
                    if isinstance(message, AIMessage) and not message.content.startswith("[ÄÃ¡nh giÃ¡ ná»™i bá»™:"):
                        final_message = message
                        break
            
            if not final_message:
                final_message = final_state["messages"][-1] if final_state["messages"] else AIMessage(content="KhÃ´ng cÃ³ pháº£n há»“i tá»« há»‡ thá»‘ng.")
            
            # Extract content, removing emoji if it's a reflection
            content = final_message.content
            if content.startswith("ğŸ’­"):
                content = content[2:].strip()
            
            yield {
                "response_type": "text",
                "content": content,
                "is_task_complete": final_state.get("success_criteria_met", False),
                "require_user_input": final_state.get("require_user_input", False),
                "is_partial": False,
                "used_tools": final_state.get("used_tools", []),
                "is_reflection": True
            }
            
        except Exception as e:
            print(f"Error streaming multi-agent system: {e}")
            yield {
                "response_type": "error",
                "content": f"Xin lá»—i, Ä‘Ã£ xáº£y ra lá»—i: {str(e)}",
                "is_task_complete": False,
                "require_user_input": False,
                "is_partial": False
            }

# Business domain-specific agents (placeholders for future implementation)
class BusinessAnalysisAgent:
    """Agent specialized in business analysis tasks."""
    pass

class FinanceAgent:
    """Agent specialized in finance and accounting tasks."""
    pass

class HRAgent:
    """Agent specialized in HR and personnel management tasks."""
    pass


async def main():
    """
    Test the enhanced worker-evaluator multi-agent system with reflection.
    """
    try:
        # Initialize the multi-agent system
        multi_agent = await MultiAgentSystem().initialize()
        session_id = "test_session_reflection_123"
        
        # Test vá»›i cÃ¢u truy váº¥n metadata vÃ  vai trÃ² ngÆ°á»i dÃ¹ng
        query1 = "TÃ¬m file cÃ³ ná»™i dung liÃªn quan Ä‘áº¿n trá»±c quan hÃ³a dá»¯ liá»‡u sau Ä‘Ã³ save metadata"
        print(f"\nTest Query 1: {query1}")
        print("Running with reflection agent...")
        
        # Test vá»›i vai trÃ² admin
        result1 = await multi_agent.run(query1, session_id=f"{session_id}_admin", user_role="admin")
        print(f"\nMain Response: {result1.get('content', 'No content')}")
        print(f"Used tools: {result1.get('used_tools', [])}")
        print(f"Agent execution order: {result1.get('agent_execution_order', [])}")
        
        if result1.get('chain_of_thought'):
            print("\nChain of Thought:")
            for i, thought in enumerate(result1['chain_of_thought'], 1):
                print(f"{i}. {thought}")
        
        # Test cÃ¢u truy váº¥n Ä‘Æ¡n giáº£n hÆ¡n
        query2 = "TÃ¬m file cÃ³ tÃªn project-final"
        print(f"\n\nTest Query 2: {query2}")
        print("Running simple search query...")
        
        result2 = await multi_agent.run(query2, session_id=f"{session_id}_simple", user_role="user")
        print(f"\nMain Response: {result2.get('content', 'No content')}")
        print(f"Used tools: {result2.get('used_tools', [])}")
        
        print("\nMulti-agent tests with reflection completed successfully!")
        
    except Exception as e:
        print(f"Error in main: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    import uuid
    asyncio.run(main())